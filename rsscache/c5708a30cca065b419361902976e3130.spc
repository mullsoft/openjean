a:4:{s:5:"child";a:1:{s:0:"";a:1:{s:3:"rss";a:1:{i:0;a:6:{s:4:"data";s:3:"


";s:7:"attribs";a:1:{s:0:"";a:1:{s:7:"version";s:3:"2.0";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:0:"";a:1:{s:7:"channel";a:1:{i:0;a:6:{s:4:"data";s:171:"
	
	
	
	
	
		
	
	
	
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
	";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:3:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:10:"KurzweilAI";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:25:"http://www.kurzweilai.net";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:25:"Accelerating Intelligence";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:13:"lastBuildDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Tue, 11 Jul 2017 06:15:41 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"language";a:1:{i:0;a:5:{s:4:"data";s:5:"en-US";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:9:"generator";a:1:{i:0;a:5:{s:4:"data";s:29:"http://wordpress.org/?v=3.4.1";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"item";a:50:{i:0;a:6:{s:4:"data";s:59:"
		
		
		
		
		
								
		
				
		
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:9:"CVPR 2017";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/cvpr-2017";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:44:"http://www.kurzweilai.net/cvpr-2017#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Tue, 11 Jul 2017 06:15:41 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:3:{i:0;a:5:{s:4:"data";s:11:"AI/Robotics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:38:"VR/Augmented Reality/Computer Graphics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=303104";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:376:"CVPR is the premier annual computer vision event comprising the main conference and several co-located workshops and short courses. With its high quality and low cost, it provides an exceptional value for students, academics and industry researchers. Plenary Speakers James J. DiCarlo, M.D., Ph.D. Peter de Florez Professor of Neuroscience, Head, Department of Brain and [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:53:"http://www.kurzweilai.net/images/CVPRLogo3-140x37.jpg";s:5:"width";s:3:"140";s:6:"height";s:2:"37";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:2115:"<p><img style=' display: block; margin-right: auto; margin-left: auto;'  class="aligncenter noshadow size-full wp-image-303105" title="CVPRLogo3" src="http://www.kurzweilai.net/images/CVPRLogo3.jpg" alt="" width="638" /></p>
<p>CVPR is the premier annual computer vision event comprising the main conference and several co-located workshops and short courses. With its high quality and low cost, it provides an exceptional value for students, academics and industry researchers.</p>
<h4>Plenary Speakers</h4>
<p><a href="http://dicarlolab.mit.edu/node/1" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=http://dicarlolab.mit.edu/node/1&amp;source=gmail&amp;ust=1499835979095000&amp;usg=AFQjCNEMRz3bbTHIR8kLDSrydTFypeVM4w">James J. DiCarlo</a>, M.D., Ph.D.<br />
Peter de Florez Professor of Neuroscience, Head, Department of Brain and Cognitive Sciences,Investigator, McGovern Institute for Brain Research, MIT.</p>
<p><strong>The Science of Natural intelligence (NI): Reverse Engineering Primate Visual Perception</strong></p>
<p><a href="https://news.microsoft.com/exec/harry-shum/#sm.0000d0qg5i8vidv8pij1rh60d7qw9%23UloOoel32F0WQxK8.97" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://news.microsoft.com/exec/harry-shum/%23sm.0000d0qg5i8vidv8pij1rh60d7qw9%2523UloOoel32F0WQxK8.97&amp;source=gmail&amp;ust=1499835979095000&amp;usg=AFQjCNG63duTWzW7nXSJBENErRxLBuEgvw">Harry Shum</a>, Ph.D.<br />
Executive Vice President, Artificial Intelligence and Research Group, Microsoft.</p>
<p><strong>Commercializing computer vision: Success stories and lessons learned</strong></p>
<p><a href="http://web.stanford.edu/~jurafsky/" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=http://web.stanford.edu/%257Ejurafsky/&amp;source=gmail&amp;ust=1499835979095000&amp;usg=AFQjCNGUKLr7zVFibpwWS3-mrCrUQih4Ig">Dan Jurafsky</a>, Ph.D.<br />
Professor and Chair of Linguistics, Professor of Computer Science, Stanford University.</p>
<p><strong>Extracting Social Meaning from Language</strong></p>
<p><em>&#8212;Event Producer</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:40:"http://www.kurzweilai.net/cvpr-2017/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:1;a:6:{s:4:"data";s:62:"
		
		
		
		
		
								
		
				
		
		
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:65:"How to ‘talk’ to your computer or car with hand or body poses";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:85:"http://www.kurzweilai.net/how-to-talk-to-your-computer-or-car-with-hand-or-body-poses";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:94:"http://www.kurzweilai.net/how-to-talk-to-your-computer-or-car-with-hand-or-body-poses#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Tue, 11 Jul 2017 02:33:20 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:4:{i:0;a:5:{s:4:"data";s:11:"AI/Robotics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:21:"Computers/Infotech/UI";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:11:"Electronics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=302990";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:363:"Researchers at Carnegie Mellon University’s Robotics Institute have developed a system that can detect and understand body poses and movements of multiple people from a video in real time &#8212; including, for the first time, the pose of each individual’s fingers. The ability to recognize finger or hand poses, for instance, will make it possible for [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:72:"http://www.kurzweilai.net/images/Tracking-multiple-people-ft-140x100.png";s:5:"width";s:3:"140";s:6:"height";s:3:"100";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:2777:"<p><iframe frameborder="0" height="315" src="https://www.youtube.com/embed/cPiN2ncuK0Y?rel=0" width="560"></iframe></p>
<p>Researchers at Carnegie Mellon University’s Robotics Institute have developed a system that can detect and understand <a href="https://www.youtube.com/watch?v=cPiN2ncuK0Y" target="_blank">body poses and movements of multiple people</a> from a video in real time &#8212; including, for the first time, the pose of each individual’s fingers.</p>
<p>The ability to recognize finger or hand poses, for instance, will make it possible for people to interact with computers in new and more natural ways, such as simply pointing at things.</p>
<p>That will also allow robots to perceive you&#8217;re doing, what moods you&#8217;re in, and whether you can be interrupted, for example. Your self-driving car could get an early warning that a pedestrian is about to step into the street by monitoring your body language. The technology could also be used for behavioral diagnosis and rehabilitation for conditions such as autism, dyslexia, and depression, the researchers say.</p>
<p>This new method was developed at CMU&#8217;s NSF-funded <a href="http://www.cs.cmu.edu/~hanbyulj/panoptic-studio/" target="_blank">Panoptic Studio</a>, a two-story dome embedded with 500 video cameras, but the researchers can now do the same thing with a single camera and laptop computer.</p>
<p><iframe frameborder="0" height="315" src="https://www.youtube.com/embed/zQt6g-Jel7M" width="560"></iframe></p>
<p>The researchers have <a href="https://github.com/CMU-Perceptual-Computing-Lab/openpose" target="_blank">released their computer code</a>. It&#8217;s already being <a href="https://twitter.com/search?q=openpose&amp;src=typd" target="_blank">widely used by research groups</a>, and more than 20 commercial groups, including automotive companies, have expressed interest in licensing the technology, according to <a href="http://www.cs.cmu.edu/~yaser/" target="_blank">Yaser Sheikh</a>, associate professor of robotics.</p>
<p>Tracking multiple people in real time, particularly in social situations where they may be in contact with each other, presents a number of challenges. Sheikh and his colleagues took a bottom-up approach, which first localizes all the body parts in a scene &#8212; arms, legs, faces, etc. &#8212; and then associates those parts with particular individuals.</p>
<p>Sheikh and his colleagues will present reports on their multiperson and hand-pose detection methods at <a href="http://cvpr2017.thecvf.com/" target="_blank">CVPR 2017</a>, the Computer Vision and Pattern Recognition Conference, July 21–26 in Honolulu.</p>
<p><iframe frameborder="0" height="315" src="https://www.youtube.com/embed/LrCO8QcXfAY" width="560"></iframe></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:90:"http://www.kurzweilai.net/how-to-talk-to-your-computer-or-car-with-hand-or-body-poses/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:2;a:6:{s:4:"data";s:59:"
		
		
		
		
		
								
		
				
		
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:55:"Machine, Platform, Crowd: Harnessing Our Digital Future";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:78:"http://www.kurzweilai.net/machine-platform-crowd-harnessing-our-digital-future";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:87:"http://www.kurzweilai.net/machine-platform-crowd-harnessing-our-digital-future#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Mon, 10 Jul 2017 06:24:39 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:3:{i:0;a:5:{s:4:"data";s:11:"AI/Robotics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:5:"Books";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:19:"Singularity/Futures";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=303048";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:344:"From the authors of the best-selling The Second Machine Age, a leader’s guide to success in a rapidly changing economy. We live in strange times. A machine plays the strategy game Go better than any human; upstarts like Apple and Google destroy industry stalwarts such as Nokia; ideas from the crowd are repeatedly more innovative than [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:73:"http://www.kurzweilai.net/images/machine-platform-crowd-cover-140x212.jpg";s:5:"width";s:3:"140";s:6:"height";s:3:"212";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:1502:"<p><strong><a href="http://www.kurzweilai.net/images/machine-platform-crowd-cover.jpg"><img style=' float: left; padding: 4px; margin: 0 7px 2px 0;'  class="alignleft  wp-image-303049" title="machine-platform-crowd-cover" src="http://www.kurzweilai.net/images/machine-platform-crowd-cover.jpg" alt="" width="223" height="337" /></a>From the authors of the best-selling <em>The Second Machine Age</em>, a leader’s guide to success in a rapidly changing economy.</strong></p>
<p>We live in strange times. A machine plays the strategy game Go better than any human; upstarts like Apple and Google destroy industry stalwarts such as Nokia; ideas from the crowd are repeatedly more innovative than corporate research labs.</p>
<p>MIT’s Andrew McAfee and Erik Brynjolfsson know what it takes to master this digital-powered shift: we must rethink the integration of minds and machines, of products and platforms, and of the core and the crowd. In all three cases, the balance now favors the second element of the pair, with massive implications for how we run our companies and live our lives.</p>
<p>In the tradition of agenda-setting classics like Clay Christensen’s <em>The Innovator’s Dilemma</em>, McAfee and Brynjolfsson deliver both a penetrating analysis of a new world and a toolkit for thriving in it. For startups and established businesses, or for anyone interested in what the future holds, <em>Machine, Platform, Crowd</em> is essential reading.</p>
<p><em>&#8212;Publisher</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:83:"http://www.kurzweilai.net/machine-platform-crowd-harnessing-our-digital-future/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:3;a:6:{s:4:"data";s:62:"
		
		
		
		
		
								
		
				
		
		
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:84:"Radical new vertically integrated 3D chip design combines computing and data storage";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:110:"http://www.kurzweilai.net/radical-new-vertically-integrated-3d-chip-design-combines-computing-and-data-storage";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:119:"http://www.kurzweilai.net/radical-new-vertically-integrated-3d-chip-design-combines-computing-and-data-storage#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Sat, 08 Jul 2017 03:30:41 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:4:{i:0;a:5:{s:4:"data";s:21:"Computers/Infotech/UI";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:11:"Electronics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:26:"Nanotech/Materials Science";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=302949";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:369:"A radical new 3D chip that combines computation and data storage in vertically stacked layers &#8212; allowing for processing and storing massive amounts of data at high speed in future transformative nanosystems &#8212; has been designed by researchers at Stanford University and MIT. The new 3D-chip design* replaces silicon with carbon nanotubes (sheets of 2-D [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:61:"http://www.kurzweilai.net/images/3D-nanosystem-ft-140x108.png";s:5:"width";s:3:"140";s:6:"height";s:3:"108";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:11161:"<div id="attachment_303001" class="wp-caption aligncenter" style="width: 647px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-303001" title="3D nanosystem" src="http://www.kurzweilai.net/images/3D-nanosystem.png" alt="" width="637" height="350" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Four vertical layers in new 3D nanosystem chip. Top (fourth layer): sensors and more than one million carbon-nanotube field-effect transistor (CNFET) logic inverters; third layer, on-chip non-volatile RRAM (1 Mbit memory); second layer, CNFET logic with classification accelerator (to identify sensor inputs); first (bottom) layer, silicon FET logic. (credit: Max M. Shulaker et al./Nature)</p></div>
<p>A radical new 3D chip that combines computation and data storage in vertically stacked layers &#8212; allowing for processing and storing massive amounts of data at high speed in future transformative nanosystems &#8212; has been designed by researchers at <a href="https://www.stanford.edu/" target="_blank">Stanford University</a> and <a href="http://mit.edu/" target="_blank">MIT</a>.</p>
<p>The new 3D-chip design* replaces silicon with carbon nanotubes (sheets of 2-D graphene formed into nanocylinders) and integrates <a href="https://en.wikipedia.org/wiki/Resistive_random-access_memory" target="_blank">resistive random-access memory</a> (RRAM) cells.</p>
<p>Carbon-nanotube field-effect transistors (CNFETs) are an emerging transistor technology that can scale beyond the limits of silicon MOSFETs (conventional chips), and promise an order-of-magnitude improvement in energy-efficient computation. However, experimental demonstrations of CNFETs so far have been small-scale and limited to integrating only tens or hundreds of devices (see earlier 2015 Stanford research, &#8220;<a href="http://www.kurzweilai.net/skyscraper-style-carbon-nanotube-chip-design-boosts-electronic-performance-by-factor-of-a-thousand" target="_blank">Skyscraper-style carbon-nanotube chip design&#8230;&#8221;</a>).</p>
<p>The researchers integrated more than 1 million RRAM cells and 2 million carbon-nanotube field-effect transistors in the chip, making it the most complex nanoelectronic system ever made with emerging nanotechnologies, according to the researchers. RRAM is an emerging memory technology that promises high-capacity, non-volatile data storage, with improved speed, energy efficiency, and density, compared to dynamic random-access memory (DRAM).</p>
<p>Instead of requiring separate components, the RRAM cells and carbon nanotubes are built vertically over one another, creating a dense new 3D computer architecture** with interleaving layers of logic and memory. By using ultradense through-chip <a href="https://en.wikipedia.org/wiki/Through-silicon_via" target="_blank">vias</a> (electrical interconnecting wires passing between layers), the high delay with conventional wiring between computer components is eliminated.</p>
<p>The new 3D nanosystem can capture massive amounts of data every second, store it directly on-chip, perform <em>in situ</em> processing of the captured data, and produce &#8220;highly processed&#8221; information. &#8220;Such complex nanoelectronic systems will be essential for future high-performance, highly energy-efficient electronic systems,&#8221; the researchers say.</p>
<p><strong>How to combine computation and storage</strong></p>
<div id="attachment_303002" class="wp-caption aligncenter" style="width: 323px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-303002" title="separate CPU &amp; memory" src="http://www.kurzweilai.net/images/separate-CPU-memory.png" alt="" width="313" height="259" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Illustration of separate CPU (bottom) and RAM memory (top) in current computer architecture (images credit: iStock)</p></div>
<p>The new chip design aims to replace current chip designs, which separate computing and data storage, resulting in limited-speed connections.</p>
<p>Separate 2D chips have been required because &#8220;building conventional silicon transistors involves extremely high temperatures of over 1,000 degrees Celsius,” explains lead author <a href="https://www.eecs.mit.edu/people/faculty/max-shulaker" target="_blank">Max Shulaker</a>, an assistant professor of electrical engineering and computer science at MIT and lead author of a paper published July 5, 2017 in the journal <em>Nature</em>. “If you then build a second layer of silicon circuits on top, that high temperature will damage the bottom layer of circuits.”</p>
<p>Instead, carbon nanotube circuits and RRAM memory can be fabricated at much lower temperatures: below 200 C. “This means they can be built up in layers without harming the circuits beneath,” says Shulaker.</p>
<p><strong>Overcoming communication and computing bottlenecks</strong></p>
<p>As applications analyze increasingly massive volumes of data, the limited rate at which data can be moved between different chips is creating a critical communication “bottleneck.” And with limited real estate on increasingly miniaturized chips, there is not enough room to place chips side-by-side.</p>
<p>At the same time, embedded intelligence in areas ranging from autonomous driving to personalized medicine is now generating huge amounts of data, but silicon transistors are no longer improving at the historic rate that they have for decades.</p>
<p>Instead, three-dimensional integration is the most promising approach to continue the technology-scaling path set forth by Moore’s law, allowing an increasing number of devices to be integrated per unit volume, according to Jan Rabaey, a professor of electrical engineering and computer science at the University of California at Berkeley, who was not involved in the research.</p>
<p>Three-dimensional integration “leads to a fundamentally different perspective on computing architectures, enabling an intimate interweaving of memory and logic,” he says. “These structures may be particularly suited for alternative learning-based computational paradigms such as brain-inspired systems and deep neural nets, and the approach presented by the authors is definitely a great first step in that direction.”</p>
<p>The new 3D design provides several benefits for future computing systems, including:</p>
<ul>
<li>Logic circuits made from carbon nanotubes can be an order of magnitude more energy-efficient compared to today’s logic made from silicon.</li>
<li>RRAM memory is denser, faster, and more energy-efficient compared to conventional DRAM (<a href="https://en.wikipedia.org/wiki/Dynamic_random-access_memory" target="_blank">dynamic random-access memory</a>) devices.</li>
<li>The dense through-chip vias (wires) can enable vertical connectivity that is 1,000 times more dense than conventional packaging and chip-stacking solutions allow, which greatly improves the data communication bandwidth between vertically stacked functional layers. For example, each sensor in the top layer can connect directly to its respective underlying memory cell with an inter-layer via. This enables the sensors to write their data in parallel directly into memory and at high speed.</li>
<li>The design is compatible in both fabrication and design with today’s CMOS silicon infrastructure.</li>
</ul>
<p>Shulaker next plans to work with Massachusetts-based semiconductor company Analog Devices to develop new versions of the system.</p>
<p><em>This work was funded by the Defense Advanced Research Projects Agency, the National Science Foundation, Semiconductor Research Corporation, STARnet SONIC, and member companies of the Stanford SystemX Alliance.</em></p>
<p><em>* As a working-prototype demonstration of the potential of the technology, the researchers took advantage of the ability of carbon nanotubes to also act as sensors. On the top layer of the chip, they placed more than 1 million carbon nanotube-based sensors, which they used to detect and classify ambient gases for detecting signs of disease by sensing particular compounds in a patient’s breath, says Shulaker. By layering sensing, data storage, and computing, the chip was able to measure each of the sensors in parallel, and then write directly into its memory, generating huge bandwidth in just one device, according to Shulaker. The top layer could be replaced with additional computation or data storage subsystems, or with other forms of input/output, he explains.</em></p>
<p><em>** Previous R&amp;D in 3D chip technologies and their limitations are covered <a href="https://en.wikipedia.org/wiki/Three-dimensional_integrated_circuit" target="_blank">here</a>, noting that &#8220;in general, 3D integration is a broad term that includes such technologies as 3D wafer-level packaging (3DWLP); 2.5D and 3D interposer-based integration; 3D stacked ICs (3D-SICs), monolithic 3D ICs; 3D heterogeneous integration; and 3D systems integration.&#8221; The new Stanford-MIT nanosystem design significantly expands this definition.<br />
</em></p>
<hr />
<h4>Abstract of <em>Three-dimensional integration of nanotechnologies for computing and data storage on a single chip</em></h4>
<p>The computing demands of future data-intensive applications will greatly exceed the capabilities of current electronics, and are unlikely to be met by isolated improvements in transistors, data storage technologies or integrated circuit architectures alone. Instead, transformative nanosystems, which use new nanotechnologies to simultaneously realize improved devices and new integrated circuit architectures, are required. Here we present a prototype of such a transformative nanosystem. It consists of more than one million resistive random-access memory cells and more than two million carbon-nanotube field-effect transistors—promising new nanotechnologies for use in energy-efficient digital logic circuits and for dense data storage—fabricated on vertically stacked layers in a single chip. Unlike conventional integrated circuit architectures, the layered fabrication realizes a three-dimensional integrated circuit architecture with fine-grained and dense vertical connectivity between layers of computing, data storage, and input and output (in this instance, sensing). As a result, our nanosystem can capture massive amounts of data every second, store it directly on-chip, perform <em>in situ</em> processing of the captured data, and produce ‘highly processed’ information. As a working prototype, our nanosystem senses and classifies ambient gases. Furthermore, because the layers are fabricated on top of silicon logic circuitry, our nanosystem is compatible with existing infrastructure for silicon-based technologies. Such complex nano-electronic systems will be essential for future high-performance and highly energy-efficient electronic systems.</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:115:"http://www.kurzweilai.net/radical-new-vertically-integrated-3d-chip-design-combines-computing-and-data-storage/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:2:"12";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:4;a:6:{s:4:"data";s:59:"
		
		
		
		
		
								
		
				
		
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:60:"Carbon nanotubes found safe for reconnecting damaged neurons";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:85:"http://www.kurzweilai.net/carbon-nanotubes-looking-good-for-repairing-damaged-neurons";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:94:"http://www.kurzweilai.net/carbon-nanotubes-looking-good-for-repairing-damaged-neurons#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Thu, 06 Jul 2017 02:39:39 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:3:{i:0;a:5:{s:4:"data";s:30:"Cognitive Science/Neuroscience";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:26:"Nanotech/Materials Science";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=302686";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:393:"Multiwall carbon nanotubes (MWCNTs) could safely help repair damaged connections between neurons by serving as supporting scaffolds for growth or as connections between neurons. That&#8217;s the conclusion of an in-vitro (lab) open-access study with cultured neurons (taken from the hippcampus of neonatal rats) by a multi-disciplinary team of scientists in Italy and Spain, published in [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:61:"http://www.kurzweilai.net/images/connected-neurons-140x78.png";s:5:"width";s:3:"140";s:6:"height";s:2:"78";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:4595:"<div id="attachment_302935" class="wp-caption aligncenter" style="width: 599px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-302935" title="connected neurons" src="http://www.kurzweilai.net/images/connected-neurons.png" alt="" width="589" height="329" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">(credit: Polina Shuvaeva/iStock)</p></div>
<p>Multiwall carbon nanotubes (MWCNTs) could safely help repair damaged connections between neurons by serving as supporting scaffolds for growth or as connections between neurons.</p>
<p>That&#8217;s the conclusion of an in-vitro (lab) open-access <a href="http://www.nanomedjournal.com/article/S1549-9634(17)30082-5/fulltext" target="_blank">study</a> with cultured neurons (taken from the hippcampus of neonatal rats) by a multi-disciplinary team of scientists in Italy and Spain, published in the journal <em>Nanomedicine: Nanotechnology, Biology, and Medicine.</em></p>
<div id="attachment_302932" class="wp-caption aligncenter" style="width: 600px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-302932" title="MWCNT" src="http://www.kurzweilai.net/images/MWCNT.png" alt="" width="590" height="401" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">A multi-walled carbon nanotube (credit: Eric Wieser/CC)</p></div>
<p>The study addressed whether MWCNTs that are interfaced to neurons affect synaptic transmission by modifying the lipid (fatty) cholesterol structure in artificial neural membranes.</p>
<p>Significantly, they found that MWCNTs:</p>
<ul>
<li><em></em>Facilitate the full growth of neurons and the formation of new synapses. &#8220;This growth, however, is not indiscriminate and unlimited since, as we proved, after a few weeks, a physiological balance is attained.&#8221;</li>
<li>Do not interfere with the composition of lipids (cholesterol in particular), which make up the cellular membrane in neurons.</li>
<li>Do not interfere in the transmission of signals through synapses.</li>
</ul>
<p>The researchers also noted that they recently <a href="http://advances.sciencemag.org/content/advances/2/7/e1600087.full.pdf" target="_blank">reported</a> (in an open access paper) low tissue reaction when multiwall carbon nanotubes were implanted <em>in vivo</em> (in live animals) to reconnect damaged spinal neurons.</p>
<p>The researchers say they proved that carbon nanotubes &#8220;perform excellently in terms of duration, adaptability and mechanical compatibility with tissue&#8221; and that &#8220;now we know that their interaction with biological material, too, is efficient. Based on this evidence, we are already studying an <em>in vivo</em> application, and preliminary results appear to be quite promising in terms of recovery of lost neurological functions.&#8221;</p>
<p>The research team comprised scientists from <a href="http://www.sissa.it" target="_blank">SISSA (International School for Advanced Studies)</a>, the University of Trieste, ELETTRA Sincrotrone, and two Spanish institutions, Basque Foundation for Science and CIC BiomaGUNE.</p>
<hr />
<h4>Abstract of <em>Sculpting neurotransmission during synaptic development by 2D nanostructured interfaces</em></h4>
<p>Carbon nanotube-based biomaterials critically contribute to the design of many prosthetic devices, with a particular impact in the development of bioelectronics components for novel neural interfaces. These nanomaterials combine excellent physical and chemical properties with peculiar nanostructured topography, thought to be crucial to their integration with neural tissue as long-term implants. The junction between carbon nanotubes and neural tissue can be particularly worthy of scientific attention and has been reported to significantly impact synapse construction in cultured neuronal networks. In this framework, the interaction of 2D carbon nanotube platforms with biological membranes is of paramount importance. Here we study carbon nanotube ability to interfere with lipid membrane structure and dynamics in cultured hippocampal neurons. While excluding that carbon nanotubes alter the homeostasis of neuronal membrane lipids, in particular cholesterol, we document in aged cultures an unprecedented functional integration between carbon nanotubes and the physiological maturation of the synaptic circuits.</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:90:"http://www.kurzweilai.net/carbon-nanotubes-looking-good-for-repairing-damaged-neurons/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"7";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:5;a:6:{s:4:"data";s:56:"
		
		
		
		
		
								
		
				
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:80:"A Crack in Creation: Gene Editing and the Unthinkable Power to Control Evolution";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:105:"http://www.kurzweilai.net/a-crack-in-creation-gene-editing-and-the-unthinkable-power-to-control-evolution";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:114:"http://www.kurzweilai.net/a-crack-in-creation-gene-editing-and-the-unthinkable-power-to-control-evolution#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Tue, 04 Jul 2017 06:32:14 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:2:{i:0;a:5:{s:4:"data";s:7:"Biotech";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:5:"Books";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=302909";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:398:"Doudna, professor of biology at UC-Berkeley, and Sternberg, her former graduate student and current collaborator, explain the basics of the potentially revolutionary CRISPR technology, the events leading up to Doudna’s discovery of that technology, and the ethical dilemmas posed by the newfound ability to alter any living being’s genetic composition. The authors describe the biological [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:70:"http://www.kurzweilai.net/images/a-crack-in-creation-cover-140x210.jpg";s:5:"width";s:3:"140";s:6:"height";s:3:"210";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:1718:"<p><a href="http://www.kurzweilai.net/images/a-crack-in-creation-cover.jpg"><img style=' float: left; padding: 4px; margin: 0 7px 2px 0;'  class="alignleft  wp-image-302910" title="a-crack-in-creation-cover" src="http://www.kurzweilai.net/images/a-crack-in-creation-cover.jpg" alt="" width="216" height="324" /></a>Doudna, professor of biology at UC-Berkeley, and Sternberg, her former graduate student and current collaborator, explain the basics of the potentially revolutionary CRISPR technology, the events leading up to Doudna’s discovery of that technology, and the ethical dilemmas posed by the newfound ability to alter any living being’s genetic composition. The authors describe the biological mechanisms in a way that nonspecialists can appreciate, though the simplistic diagrams scattered throughout add little to the text. They also enthusiastically survey many of the uses to which CRISPR technology has already been applied, noting the great interest by venture capitalists who have already invested well over $1 billion in this technology. Doudna and Sternberg make a clear distinction between manipulating reproductive and non-reproductive cells, since the former can cause permanent evolutionary shifts. The second half of the book delves into the ethical implications arising from this difference, thoughtfully covering effects on both human and non-human species. Though the authors note that science involves both “competition and collaboration,” they avoid discussion of the myriad conflicts that exist in this exciting new field—an absence that makes the rosy picture presented in this otherwise excellent book just a bit too unbelievable.</p>
<p><em>&#8212;Publishers Weekly</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:110:"http://www.kurzweilai.net/a-crack-in-creation-gene-editing-and-the-unthinkable-power-to-control-evolution/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"1";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:6;a:6:{s:4:"data";s:56:"
		
		
		
		
		
								
		
				
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:88:"Meditation, yoga, and tai chi can reverse damaging effects of stress, new study suggests";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:111:"http://www.kurzweilai.net/meditation-yoga-and-tai-chi-can-reverse-damaging-effects-of-stress-new-study-suggests";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:120:"http://www.kurzweilai.net/meditation-yoga-and-tai-chi-can-reverse-damaging-effects-of-stress-new-study-suggests#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Tue, 04 Jul 2017 02:31:47 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:2:{i:0;a:5:{s:4:"data";s:16:"Biomed/Longevity";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=302870";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:388:"Mind-body interventions such as meditation, yoga*, and tai chi can reverse the molecular reactions in our DNA that cause ill-health and depression, according to a study by scientists at the universities of Coventry and Radboud. When a person is exposed to a stressful event, their sympathetic nervous system (responsible for the &#8220;fight-or-flight&#8221; response) is triggered, [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:61:"http://www.kurzweilai.net/images/tai-chi-exercise-140x118.png";s:5:"width";s:3:"140";s:6:"height";s:3:"118";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:6679:"<div id="attachment_302876" class="wp-caption aligncenter" style="width: 478px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-302876" title="tai chi exercise" src="http://www.kurzweilai.net/images/tai-chi-exercise.png" alt="" width="468" height="396" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Gentle exercise like tai chi can reduce the risk of inflammation-related diseases like cancer and accelerated aging. (credit: iStock)</p></div>
<p>Mind-body interventions such as meditation, yoga*, and tai chi can reverse the molecular reactions in our DNA that cause ill-health and depression, according to a study by scientists at the universities of Coventry and Radboud.</p>
<p>When a person is exposed to a stressful event, their sympathetic nervous system (responsible for the &#8220;fight-or-flight&#8221; response) is triggered, which increases production of a molecule called nuclear factor kappa B (NF-kB). That molecule then activates genes to produce proteins called cytokines that cause inflammation at the cellular level, affecting the body, brain, and immune system.</p>
<p>That&#8217;s useful as a short-lived fight-or-flight reaction. However, if persistent, it leads to a higher risk of cancer, accelerated aging, and psychiatric disorders like depression.</p>
<p>But in a <a href="http://journal.frontiersin.org/article/10.3389/fimmu.2017.00670/full" target="_blank">paper</a> published June 16, 2017 in the open-access journal <em>Frontiers in Immunology</em>, the researchers reveal findings of 18 studies (featuring 846 participants over 11 years) indicating that people who practice mind-body interventions exhibit the opposite effect. They showed a <em>decrease</em> in production of NF-kB and cytokines &#8212; reducing the pro-inflammatory gene expression pattern and the risk of inflammation-related diseases and conditions.</p>
<p>David Gorski, MD, PhD, has published a critique of this study here. (Lead author Ivana Burić has replied in the comments below.)</p>
<p><strong>Lowering risks from sitting</strong></p>
<div id="attachment_302877" class="wp-caption aligncenter" style="width: 478px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-302877" title="walking" src="http://www.kurzweilai.net/images/walking.png" alt="" width="468" height="367" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Brisk walks can offset health hazards of sitting (credit: iStock)</p></div>
<p>In addition to stress effects, increased sitting is known to be associated with an increased risk of cardiovascular disease, diabetes, and death from all causes.</p>
<p>But regular two-minute brisk walks every 30 minutes (in addition to daily 30-minute walks) significantly reduce levels of triglyceride (lipid, or fatty acid) levels that lead to clogged arteries, researchers from New Zealand&#8217;s University of Otago report in a <a href="http://www.lipidjournal.com/article/S1933-2874(17)30351-3/fulltext" target="_blank">paper</a> published June 19, 2017 in the <em>Journal of Clinical Lipidology</em>.**</p>
<p>The lipid levels were measured in response to a meal consumed around 24 hours after starting the activity. High levels of triglycerides are linked to hardening of the arteries and other cardiovascular conditions.</p>
<p>They previously found that brisk walks for two minutes every 30 minutes also lower blood glucose and insulin levels.</p>
<p>OK, it&#8217;s time for that two-minute brisk walk. &#8230; So, you&#8217;re still sitting there, aren&#8217;t you? :)</p>
<p><em>* However, yoga causes musculoskeletal pain in more than 10 per cent of practitioners per year, according to recent research at the University of Sydney <a href="http://www.bodyworkmovementtherapies.com/article/S1360-8592(17)30122-5/fulltext" target="_blank">published</a> in the </em>Journal of Bodywork and Movement Therapies<em>. &#8220;We also found that yoga can exacerbate existing pain, with 21 per cent of existing injuries made worse by doing yoga, particularly pre-existing musculoskeletal pain in the upper limbs,&#8221; said lead researcher Associate Professor Evangelos Pappas from the University&#8217;s Faculty of Health Sciences. </em></p>
<p><em>&#8220;In terms of severity, more than one-third of cases of pain caused by yoga were serious enough to prevent yoga participation and lasted more than 3 months.&#8221; The study found that most &#8220;new&#8221; yoga pain was in the upper extremities (shoulder, elbow, wrist, hand), possibly due to downward dog and similar postures that put weight on the upper limbs. However, 74 per cent of participants in the study reported that existing pain was actually </em>improved<em> by yoga, highlighting the complex relationship between musculoskeletal pain and yoga practice.</em></p>
<p><em>** Scientists at the University of Utah School of Medicine previously came to a similar conclusion in a 2015 <a href="http://m.cjasn.asnjournals.org/content/early/2015/04/29/CJN.08410814" target="_blank">paper</a> published in the <a href="http://m.cjasn.asnjournals.org/content/early/2015/04/29/CJN.08410814" target="_blank">Clinical Journal of the American Society of Nephrology (CJASN)</a>.</em></p>
<p><em>They used observational data from the <a href="https://www.cdc.gov/nchs/nhanes/index.htm" target="_blank">National Health and Nutrition Examination Survey</a> (NHANES) to examine whether longer durations of low-intensity activities (e.g., standing) vs. light-intensity activities (e.g., casual walking, light gardening, cleaning) extend the lifespan of people who are sedentary for more than half of their waking hours.</em></p>
<p><em>They found that adding two minutes of low-intensity activities every hour (plus 2.5 hours of moderate exercise each week, which strengthens the heart, muscles, and bones) was associated with a 33 percent lower risk of dying. “It was fascinating to see the results because the current national focus is on moderate or vigorous activity,&#8221; says lead author <a href="http://healthcare.utah.edu/fad/mddetail.php?physicianID=u0173821#tab1" target="_blank">Srinivasan Beddhu, M.D.</a>, professor of internal medicine. &#8220;To see that light activity had an association with lower mortality is intriguing.”</em></p>
<p><em>UPDATE July 5, 2017 &#8212; Added mention of a critique to the Coventry&#8211;Radboud study.</em></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:116:"http://www.kurzweilai.net/meditation-yoga-and-tai-chi-can-reverse-damaging-effects-of-stress-new-study-suggests/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"7";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:7;a:6:{s:4:"data";s:59:"
		
		
		
		
		
								
		
				
		
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:90:"‘Mind reading’ technology identifies complex thoughts, using machine learning and fMRI";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:109:"http://www.kurzweilai.net/mind-reading-technology-identifies-complex-thoughts-using-machine-learning-and-fmri";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:118:"http://www.kurzweilai.net/mind-reading-technology-identifies-complex-thoughts-using-machine-learning-and-fmri#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Fri, 30 Jun 2017 14:27:08 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:3:{i:0;a:5:{s:4:"data";s:11:"AI/Robotics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:30:"Cognitive Science/Neuroscience";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=302682";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:431:"By combining machine-learning algorithms with fMRI brain imaging technology, Carnegie Mellon University (CMU) scientists have discovered, in essense, how to &#8220;read minds.&#8221; The researchers used functional magnetic resonance imaging (fMRI) to view how the brain encodes various thoughts (based on blood-flow patterns in the brain). They discovered that the mind’s building blocks for constructing complex thoughts [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:68:"http://www.kurzweilai.net/images/brain-semantic-patterns-140x172.png";s:5:"width";s:3:"140";s:6:"height";s:3:"172";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:9545:"<div id="attachment_302778" class="wp-caption aligncenter" style="width: 647px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-302778" title="predicted vs. observed" src="http://www.kurzweilai.net/images/predicted-vs.-observed.png" alt="" width="637" height="262" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">(Top) Predicted brain activation patterns and semantic features (colors) for two pairs of sentences. (Left: “The flood damaged the hospital”; (Right): “The storm destroyed the theater.” (Bottom) observed similar activation patterns and semantic features. (credit: Jing Wang et al./Human Brain Mapping)</p></div>
<p>By combining machine-learning algorithms with fMRI brain imaging technology, Carnegie Mellon University (CMU) scientists have discovered, in essense, how to &#8220;read minds.&#8221;</p>
<p>The researchers used functional magnetic resonance imaging (fMRI) to view how the brain encodes various thoughts (based on blood-flow patterns in the brain). They discovered that the mind’s building blocks for constructing complex thoughts are formed, not by words, but by specific combinations of the brain’s various sub-systems.</p>
<p>Following up on previous research, the findings, published in <em>Human Brain Mapping</em> (<a href="http://www.ccbi.cmu.edu/reprints/Wang_Just_HBM-2017_Journal-preprint.pdf" target="_blank">open-access preprint here</a>) and funded by the U.S. <a href="https://www.iarpa.gov/" target="_blank">Intelligence Advanced Research Projects Activity</a> (IARPA), provide new evidence that the neural dimensions of concept representation are universal across people and languages.</p>
<p>&#8220;One of the big advances of the human brain was the ability to combine individual concepts into complex thoughts, to think not just of &#8216;bananas,&#8217; but &#8216;I like to eat bananas in evening with my friends,&#8217;&#8221; said CMU’s <a href="https://www.cmu.edu/dietrich/psychology/people/core-training-faculty/just-marcel.html" target="_blank">Marcel Just</a>, the D.O. Hebb University Professor of <a href="https://www.cmu.edu/dietrich/psychology/index.html" target="_blank">Psychology</a> in the Dietrich College of Humanities and Social Sciences. &#8220;We have finally developed a way to see thoughts of that complexity in the fMRI signal. The discovery of this correspondence between thoughts and brain activation patterns tells us what the thoughts are built of.&#8221;</p>
<p><strong>Goal: A brain map of all types of knowledge</strong></p>
<div id="attachment_302779" class="wp-caption aligncenter" style="width: 647px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-302779" title="brain locations and semantic factors" src="http://www.kurzweilai.net/images/brain-locations-and-semantic-factors.png" alt="" width="637" height="432" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">(Top) Specific brain regions associated with the four large-scale semantic factors: people (yellow), places (red), actions and their consequences (blue), and feelings (green). (Bottom) Word clouds associated with each large-scale semantic factor underlying sentence representations. These word clouds comprise the seven &#8220;neurally plausible semantic features&#8221; (such as &#8220;high-arousal&#8221;) most associated with each of the four semantic factors. (credit: Jing Wang et al./Human Brain Mapping)</p></div>
<p>The researchers used 240 specific events (described by sentences such as &#8220;The storm destroyed the theater&#8221;) in the study, with seven adult participants. They measured the brain’s coding of these events using 42 &#8220;neurally plausible semantic features&#8221; &#8212; such as person, setting, size, social interaction, and physical action (as shown in the word clouds in the illustration above). By measuring the specific activation of each of these 42 features in a person&#8217;s brain system, the program could tell what types of thoughts that person was focused on.</p>
<p>The researchers used a computational model to assess how the detected brain activation patterns (shown in the top illustration, for example) for 239 of the event sentences corresponded to the detected neurally plausible semantic features that characterized each sentence. The program was then able to decode the features of the 240th left-out sentence. (For &#8220;cross-validation,&#8221; they did the same for the other 239 sentences.)</p>
<p>The model was able to predict the features of the left-out sentence with 87 percent accuracy, despite never being exposed to its activation before. It was also able to work in the other direction: to predict the activation pattern of a previously unseen sentence, knowing only its semantic features.</p>
<p>&#8220;Our method overcomes the unfortunate property of fMRI to smear together the signals emanating from brain events that occur close together in time, like the reading of two successive words in a sentence,&#8221; Just explained. &#8220;This advance makes it possible for the first time to decode thoughts containing several concepts. That’s what most human thoughts are composed of.&#8221;</p>
<p>&#8220;A next step might be to decode the general type of topic a person is thinking about, such as geology or skateboarding,&#8221; he added. &#8220;We are on the way to making a map of all the types of knowledge in the brain.&#8221;</p>
<p><strong>Future possibilities</strong></p>
<p>It&#8217;s conceivable that the CMU brain-mapping method might be combined one day with other &#8220;mind reading&#8221; methods, such as UC Berkeley&#8217;s method for using fMRI and computational models to <a href="http://www.kurzweilai.net/how-to-make-movies-of-the-brains-thoughts" target="_blank">decode and reconstruct people’s imagined visual experiences</a>. Plus whatever Neuralink discovers.</p>
<p>Or if the CMU method could be replaced by noninvasive functional near-infrared spectroscopy (fNIRS), <a href="http://www.kurzweilai.net/what-if-you-could-type-directly-from-your-brain-at-100-words-per-minute" target="_blank">Facebook&#8217;s Building8 research concept</a> (proposed by former DARPA head Regina Dugan) might be incorporated (a filter for creating quasi ballistic photons, avoiding diffusion and creating a narrow beam for precise targeting of brain areas, combined with a new method of detecting blood-oxygen levels).</p>
<p>Using fNIRS might also allow for adapting the method to infer thoughts of locked-in paralyzed patients, as in the <a href="http://www.kurzweilai.net/brain-computer-interface-enables-completely-locked-in-patients-to-communicate-for-the-first-time" target="_blank"> Wyss Center for Bio and Neuroengineering research</a>. It might even lead to ways to generally enhance human communication.</p>
<p><em>The CMU research is supported by the Office of the Director of National Intelligence (ODNI) via the Intelligence Advanced Research Projects Activity (IARPA) and the Air Force Research Laboratory (AFRL).</em></p>
<p><em>CMU has created some of the first cognitive tutors, helped to develop the Jeopardy-winning Watson, founded a groundbreaking doctoral program in neural computation, and is the birthplace of artificial intelligence and cognitive psychology. CMU also launched <a href="http://www.cmu.edu/research/brain/" target="_blank">BrainHub</a>, an initiative that focuses on how the structure and activity of the brain give rise to complex behaviors.</em></p>
<hr />
<h4>Abstract of <em>Predicting the Brain Activation Pattern Associated With the Propositional Content of a Sentence: Modeling Neural Representations of Events and States</em></h4>
<p>Even though much has recently been learned about the neural representation of individual concepts and categories, neuroimaging research is only beginning to reveal how more complex thoughts, such as event and state descriptions, are neurally represented. We present a predictive computational theory of the neural representations of individual events and states as they are described in 240 sentences. Regression models were trained to determine the mapping between 42 neurally plausible semantic features (NPSFs) and thematic roles of the concepts of a proposition and the fMRI activation patterns of various cortical regions that process different types of information. Given a semantic characterization of the content of a sentence that is new to the model, the model can reliably predict the resulting neural signature, or, given an observed neural signature of a new sentence, the model can predict its semantic content. The models were also reliably generalizable across participants. This computational model provides an account of the brain representation of a complex yet fundamental unit of thought, namely, the conceptual content of a proposition. In addition to characterizing a sentence representation at the level of the semantic and thematic features of its component concepts, factor analysis was used to develop a higher level characterization of a sentence, specifying the general type of event representation that the sentence evokes (e.g., a social interaction versus a change of physical state) and the voxel locations most strongly associated with each of the factors.</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:114:"http://www.kurzweilai.net/mind-reading-technology-identifies-complex-thoughts-using-machine-learning-and-fmri/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"4";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:8;a:6:{s:4:"data";s:56:"
		
		
		
		
		
								
		
				
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:44:"How to capture videos of brains in real time";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:70:"http://www.kurzweilai.net/how-to-capture-videos-of-brains-in-real-time";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:79:"http://www.kurzweilai.net/how-to-capture-videos-of-brains-in-real-time#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Thu, 29 Jun 2017 02:27:11 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:2:{i:0;a:5:{s:4:"data";s:30:"Cognitive Science/Neuroscience";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=302678";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:313:"A team of scientists has peered into a mouse brain with light, capturing live neural activity of hundreds of individual neurons in a 3D section of tissue at video speed (30 Hz) in a single recording for the first time. Besides serving as a powerful research tool, this discovery means it may now be possible [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:73:"http://www.kurzweilai.net/images/individual-neurons-signaling-140x105.gif";s:5:"width";s:3:"140";s:6:"height";s:3:"105";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:7473:"<div id="attachment_302679" class="wp-caption aligncenter" style="width: 606px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><a href="http://www.kurzweilai.net/images/individual-neurons-signaling.gif"><img class=" wp-image-302679" title="individual-neurons-signaling" src="http://www.kurzweilai.net/images/individual-neurons-signaling.gif" alt="" width="596" height="446" /></a><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Individual neurons firing within a volume of brain tissue (credit: The Rockefeller University)</p></div>
<p>A team of scientists has peered into a mouse brain with light, capturing live neural activity of hundreds of individual neurons in a 3D section of tissue at video speed (30 Hz) in a single recording for the first time.</p>
<p>Besides serving as a powerful research tool, this discovery means it may now be possible to &#8220;alter stimuli in real time based on what we see going on in the animal’s brain,” said Rockefeller University&#8217;s <a href="https://www.rockefeller.edu/our-scientists/heads-of-laboratories/1132-alipasha-vaziri/" target="_blank">Alipasha Vaziri</a>, senior author of an open-access <a href="https://www.nature.com/nmeth/journal/vaop/ncurrent/full/nmeth.4341.html" target="_blank">paper</a> published June 26, 2017 in <em>Nature Methods</em>.</p>
<p>By dramatically reducing the time and computational resources required to generate such an image, the algorithm opens the door to more sophisticated experiments, says Vaziri, head of the Rockefeller <a href="http://vaziri.rockefeller.edu/" target="_blank">Laboratory of Neurotechnology and Biophysics</a>. “Our goal is to better understand brain function by monitoring the dynamics within densely interconnected, three-dimensional networks of neurons,” Vaziri explained.</p>
<p>The research &#8220;may open the door to a range of applications, including real-time whole-brain recording and closed-loop interrogation of neuronal population activity in combination with optogenetics and behavior,&#8221; the paper authors suggest.</p>
<p><strong>Watching mice think in real time</strong></p>
<p>The scientists first engineered the animals’ neurons to fluoresce (glow), using a method called <a href="https://en.wikipedia.org/wiki/Optogenetics">optogenetics</a>. The stronger the neural signal, the brighter the cells shine. To capture this activity, they used a technique known as &#8220;<a href="https://en.wikipedia.org/wiki/Light_field" target="_blank">light-field microscopy</a>,&#8221; in which an array of lenses generates views from a variety of perspectives. These images are then combined to create a three-dimensional rendering, using a new algorithm called &#8220;seeded iterative demixing&#8221; (SID) developed by the team.</p>
<div id="attachment_302680" class="wp-caption aligncenter" style="width: 446px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-302680" title="individual-neurons-without-the-algorithm" src="http://www.kurzweilai.net/images/individual-neurons-without-the-algorithm.gif" alt="" width="436" height="436" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Without the new algorithm, the individual neurons are difficult to distinguish. (credit: The Rockefeller University)</p></div>
<p>To record the activity of all neurons at the same time, their images have to be captured on a camera simultaneously. In earlier research, this has made it difficult to distinguish the signals emitted by all cells as the light from the mouse’s neurons bounces off the surrounding, opaque tissue. The neurons typically show up as an indistinct, flickering mass.</p>
<p>The SID algorithm now makes it possible to simultaneously capture both the location of the individual neurons and the timing of their signals within a three-dimensional section of brain containing multiple layers of neurons, down to a depth of 0.38 millimeters.* Vaziri and his colleagues were able to track the precise coordinates of hundreds of active neurons over an extended period of time in mice that were awake and had the option of walking on a customized treadmill.</p>
<div id="attachment_188204" class="wp-caption aligncenter" style="width: 446px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-188204" title="CLARITY_stained" src="http://www.kurzweilai.net/images/CLARITY_stained.jpg" alt="CLARITY_stained" width="436" height="272" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Three-dimensional view of stained hippocampus with Stanford University&#8217;s CLARITY system, showing fluorescent-expressing neurons (green), connecting interneurons (red) and supporting glia (blue). (Credit: Deisseroth lab)</p></div>
<p>Researchers were previously only able to <a href="http://www.kurzweilai.net/watching-fish-thinking" target="_blank">look into brains of transparent organisms</a>, such as the larvae of <a href="http://www.kurzweilai.net/see-through-mitofish-opens-a-new-window-on-brain-diseases" target="_blank">zebrafish</a>. Stanford University scientists were able to image mouse brains in 3D (with the <a href="http://www.kurzweilai.net/creating-a-transparent-brain" target="_blank">CLARITY</a> system), but only for static images.</p>
<p><em>* &#8220;SID can capture neuronal dynamics in vivo within a volume of 900 × 900 × 260 μm located as deep as 380 μm in the mouse cortex or hippocampus at a 30-Hz volume rate while discriminating signals from neurons as close as 20 μm apart, at a computational cost three orders of magnitude less than that of frame-by-frame image reconstruction.&#8221; &#8211; Tobias Nöbauer et al./</em>Nature Methods</p>
<p><strong>UPDATE June 29, 2017</strong> &#8212; Added: &#8220;The research &#8216;may open the door to a range of applications, including real-time whole-brain recording and closed-loop interrogation of neuronal population activity in combination with optogenetics and behavior,&#8217; the paper authors suggest.&#8221;</p>
<hr />
<h4>Abstract of <em>Video rate volumetric Ca<sup>2+</sup> imaging across cortex using seeded iterative demixing (SID) microscopy</em></h4>
<p>Light-field microscopy (LFM) is a scalable approach for volumetric Ca<sup>2+</sup> imaging with high volumetric acquisition rates (up to 100 Hz). Although the technology has enabled whole-brain Ca<sup>2+</sup> imaging in semi-transparent specimens, tissue scattering has limited its application in the rodent brain. We introduce seeded iterative demixing (SID), a computational source-extraction technique that extends LFM to the mammalian cortex. SID can capture neuronal dynamics <em>in vivo</em> within a volume of 900 × 900 × 260 μm located as deep as 380 μm in the mouse cortex or hippocampus at a 30-Hz volume rate while discriminating signals from neurons as close as 20 μm apart, at a computational cost three orders of magnitude less than that of frame-by-frame image reconstruction. We expect that the simplicity and scalability of LFM, coupled with the performance of SID, will open up a range of applications including closed-loop experiments.</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:75:"http://www.kurzweilai.net/how-to-capture-videos-of-brains-in-real-time/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"4";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:9;a:6:{s:4:"data";s:59:"
		
		
		
		
		
								
		
				
		
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:79:"Smart algorithm automatically adjusts exoskeletons for best walking performance";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:105:"http://www.kurzweilai.net/smart-algorithm-automatically-adjusts-exoskeletons-for-best-walking-performance";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:114:"http://www.kurzweilai.net/smart-algorithm-automatically-adjusts-exoskeletons-for-best-walking-performance#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Sun, 25 Jun 2017 20:38:21 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:3:{i:0;a:5:{s:4:"data";s:11:"Electronics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:17:"Human Enhancement";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=302598";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:386:"Researchers at the College of Engineering at Carnegie Mellon University (CMU) have developed a new automated feedback system for personalizing exoskeletons to achieve optimal performance. Exoskeletons can be used to augment human abilities. For example, they can provide more endurance while walking, help lift a heavy load, improve athletic performance, and help a stroke patient [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:63:"http://www.kurzweilai.net/images/exoskeleton-leg-ft-140x175.png";s:5:"width";s:3:"140";s:6:"height";s:3:"175";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:5183:"<div id="attachment_302601" class="wp-caption aligncenter" style="width: 371px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-302601" title="exoskeleton and prosthetic limb with feedback" src="http://www.kurzweilai.net/images/exoskeleton-and-prosthetic-limb-with-feedback.png" alt="" width="361" height="337" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Walk this way: Metabolic feedback and optimization algorithm automatically tweaks exoskeleton for optimal performance. (credit: Kirby Witte, Katie Poggensee, Pieter Fiers, Patrick Franks &amp; Steve Collins)</p></div>
<p>Researchers at the College of Engineering at Carnegie Mellon University (CMU) have developed a new automated feedback system for personalizing exoskeletons to achieve optimal performance.</p>
<p>Exoskeletons can be used to augment human abilities. For example, they can provide more endurance while walking, help lift a heavy load, improve athletic performance, and help a stroke patient walk again.</p>
<p>But current one-size-fits-all exoskeleton devices, despite their potential, &#8220;have not improved walking performance as much as we think they should,” said Steven Collins, a professor of <a href="http://www.cmu.edu/me/" rel="noopener noreferrer" target="_blank">Mechanical Engineering</a> and senior author of a paper published published Friday June 23, 2017 in <a href="http://science.sciencemag.org/content/356/6344/1280.full" rel="noopener noreferrer" target="_blank"><em>Science</em></a>.</p>
<p>The problem: An exoskeleton needs to be adjusted (and re-adjusted) to work effectively for each user &#8212; currently, a time-consuming, iffy manual process.</p>
<p>So the CMU engineers developed a more effective &#8220;human-in-the-loop optimization&#8221; technique that measures the amount of energy the walker expends by monitoring their breathing* &#8212; automatically adjusting the exoskeleton&#8217;s ankle dynamics to minimize required human energy expenditure.**</p>
<div id="attachment_302609" class="wp-caption aligncenter" style="width: 563px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-302609" title="human-in-the-loop exoskeleton optimization" src="http://www.kurzweilai.net/images/human-in-the-loop-exoskeleton-optimization.png" alt="" width="553" height="295" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Using real-time metabolic cost estimation for each individual, the CMU software algorithm, combined with versatile emulator hardware, optimized the exoskeleton torque pattern for one ankle while walking, running, and carrying a load on a treadmill. The algorithm automatically made optimized adjustments for each pattern, based on measurements of a person&#8217;s energy use for 32 different walking patterns over the course of an hour. (credit: Juanjuan Zhang et al./Science, adapted by KurzweilAI)</p></div>
<p>In a lab study with 11 healthy volunteers, the new technique resulted in an average reduction in effort of 24% compared to participants walking with the exoskeleton powered off. The technique yielded higher user benefits than in any exoskeleton study to date, including devices acting at all joints on both legs, according to the researchers.</p>
<p><em>* &#8220;In daily life, a proxy measure such as heart rate or muscle activity could be used for optimization, providing noisier but more abundant performance data.&#8221; &#8212; Juanjuan Zhang et al./</em>Science</p>
<p><em>** Ankle torque in the lab study was determined by four parameters: peak torque, timing of peak torque, and rise and fall times. This method was chosen to allow comparisons to a prior study that used the same hardware.<br />
</em></p>
<div>
<p><iframe frameborder="0" height="315" src="https://www.youtube.com/embed/OhvPBmQk580" width="560"></iframe><br />
<em>Science/AAAS | Personalized Exoskeletons Are Taking Support One Step Farther</em></p>
<hr />
<h4>Abstract of <em>Human-in-the-loop optimization of exoskeleton assistance during walking</em></h4>
<p>Exoskeletons and active prostheses promise to enhance human mobility, but few have succeeded. Optimizing device characteristics on the basis of measured human performance could lead to improved designs. We have developed a method for identifying the exoskeleton assistance that minimizes human energy cost during walking. Optimized torque patterns from an exoskeleton worn on one ankle reduced metabolic energy consumption by 24.2 ± 7.4% compared to no torque. The approach was effective with exoskeletons worn on one or both ankles, during a variety of walking conditions, during running, and when optimizing muscle activity. Finding a good generic assistance pattern, customizing it to individual needs, and helping users learn to take advantage of the device all contributed to improved economy. Optimization methods with these features can substantially improve performance.</p>
</div>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:110:"http://www.kurzweilai.net/smart-algorithm-automatically-adjusts-exoskeletons-for-best-walking-performance/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"2";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:10;a:6:{s:4:"data";s:56:"
		
		
		
		
		
								
		
				
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:79:"Tactile sensor lets robots gauge objects’ hardness and manipulate small tools";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:102:"http://www.kurzweilai.net/tactile-sensor-lets-robots-gauge-objects-hardness-and-manipulate-small-tools";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:111:"http://www.kurzweilai.net/tactile-sensor-lets-robots-gauge-objects-hardness-and-manipulate-small-tools#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Sat, 24 Jun 2017 01:05:09 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:2:{i:0;a:5:{s:4:"data";s:11:"AI/Robotics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=302026";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:391:"Researchers at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) have added sensors to grippers on robot arms to give robots greater sensitivity and dexterity. The sensor can judge the hardness of surfaces it touches, enabling a robot to manipulate smaller objects than was previously possible. The &#8220;GelSight&#8221; sensor consists of a block of transparent [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:73:"http://www.kurzweilai.net/images/Gelsight-sensor-on-robot-arm-140x183.png";s:5:"width";s:3:"140";s:6:"height";s:3:"183";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:4473:"<div id="attachment_302592" class="wp-caption aligncenter" style="width: 368px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-302592" title="Gelsight sensor on robot arm" src="http://www.kurzweilai.net/images/Gelsight-sensor-on-robot-arm.png" alt="" width="358" height="468" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">A GelSight sensor attached to a robot’s gripper enables the robot to determine precisely where it has grasped a small screwdriver, removing it from and inserting it back into a slot, even when the gripper screens the screwdriver from the robot’s camera. (credit: Robot Locomotion Group at MIT)</p></div>
<p>Researchers at <a href="https://www.csail.mit.edu/" target="_blank">MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL)</a> have added sensors to grippers on robot arms to give robots greater sensitivity and dexterity. The sensor can judge the hardness of surfaces it touches, enabling a robot to manipulate smaller objects than was previously possible.</p>
<p>The &#8220;GelSight&#8221; sensor consists of a block of transparent soft rubber &#8212; the “gel” of its name &#8212; with one face coated with metallic paint. It is mounted on one side of a robotic gripper. When the paint-coated face is pressed against an object, the face conforms to the object’s shape and the metallic paint makes the object’s surface reflective. Mounted on the sensor opposite the paint-coated face of the rubber block are three colored lights at different angles and a single camera.</p>
<p>Humans gauge hardness by the degree to which the contact area between the object and our fingers changes as we press on it. Softer objects tend to flatten more, increasing the contact area. The MIT researchers used the same approach.</p>
<p>A GelSight sensor, pressed against each object manually, recorded how the contact pattern changed over time, essentially producing a short movie for each object. A <a>neural network</a> was then used to look for correlations between changes in contact patterns and hardness measurements. The resulting system takes frames of video as inputs and produces hardness scores with very high accuracy.</p>
<p>The researchers also designed control algorithms that use a computer vision system to guide the robot’s gripper toward a tool and then turn location estimation over to a GelSight sensor once the robot has the tool in hand.</p>
<p>“I think that the GelSight technology, as well as other high-bandwidth tactile sensors, will make a big impact in robotics,” says Sergey Levine, an assistant professor of electrical engineering and computer science at the University of California at Berkeley. “For humans, our sense of touch is one of the key enabling factors for our amazing manual dexterity. Current robots lack this type of dexterity and are limited in their ability to react to surface features when manipulating objects. If you imagine fumbling for a light switch in the dark, extracting an object from your pocket, or any of the other numerous things that you can do without even thinking — these all rely on touch sensing.”</p>
<p>The researchers presented their work in two papers at the International Conference on Robotics and Automation.</p>
<p><iframe frameborder="0" height="315" src="https://www.youtube.com/embed/QDvXHNtYbBA?rel=0" width="560"></iframe><br />
<em>Wenzhen Yuan | Measuring hardness of fruits with GelSight sensor</em></p>
<hr />
<h4>Abstract of <em>Tracking Objects with Point Clouds from Vision and Touch</em></h4>
<p>We present an object-tracking framework that fuses point cloud information from an RGB-D camera with tactile information from a GelSight contact sensor. GelSight can be treated as a source of dense local geometric information, which we incorporate directly into a conventional point-cloud-based articulated object tracker based on signed-distance functions. Our implementation runs at 12 Hz using an online depth reconstruction algorithm for GelSight and a modified secondorder update for the tracking algorithm. We present data from hardware experiments demonstrating that the addition of contact-based geometric information significantly improves the pose accuracy during contact, and provides robustness to occlusions of small objects by the robot’s end effector.</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:107:"http://www.kurzweilai.net/tactile-sensor-lets-robots-gauge-objects-hardness-and-manipulate-small-tools/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:11;a:6:{s:4:"data";s:56:"
		
		
		
		
		
								
		
				
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:53:"Two drones see through walls in 3D using WiFi signals";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:79:"http://www.kurzweilai.net/two-drones-see-through-walls-in-3d-using-wifi-signals";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:88:"http://www.kurzweilai.net/two-drones-see-through-walls-in-3d-using-wifi-signals#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Wed, 21 Jun 2017 18:34:26 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:2:{i:0;a:5:{s:4:"data";s:11:"Electronics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=302465";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:453:"Researchers at the University of California Santa Barbara have demonstrated the first three-dimensional imaging of objects through walls using an ordinary wireless signal. Applications could include emergency search-and-rescue, archaeological discovery, and structural monitoring, according to the researchers. Other applications could include military and law-enforcement surveillance. Calculating 3D images from WiFi signals In the research, two [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:67:"http://www.kurzweilai.net/images/transmit-receive-drones-140x86.png";s:5:"width";s:3:"140";s:6:"height";s:2:"86";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:7118:"<div id="attachment_302531" class="wp-caption aligncenter" style="width: 587px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-302531" title="transmit &amp; receive drones2" src="http://www.kurzweilai.net/images/transmit-receive-drones2.png" alt="" width="577" height="197" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Transmit and receive drones perform 3D imaging through walls using WiFi (credit: Chitra R. Karanam and Yasamin Mostofi/ACM)</p></div>
<p>Researchers at the <a href="http://www.ucsb.edu/" target="_blank">University of California Santa Barbara</a> have demonstrated the first <a href="http://www.ece.ucsb.edu/~ymostofi/3DThroughWallImaging.html" target="_blank">three-dimensional imaging of objects through walls</a> using an ordinary wireless signal.</p>
<p>Applications could include emergency search-and-rescue, archaeological discovery, and structural monitoring, according to the researchers. Other applications could include military and law-enforcement surveillance.</p>
<p><strong>Calculating 3D images from WiFi signals </strong></p>
<p>In the research, two octo-copters (drones) took off and flew outside an enclosed, four-sided brick structure whose interior was unknown to the drones. One drone continuously transmitted a WiFi signal; the other drone (located on a different side of the structure) received that signal and transmitted the changes in received signal strength (&#8220;RSSI&#8221;) during the flight to a computer, which then calculated 3D high-resolution images of the objects inside (which do not need to move).</p>
<div id="attachment_302539" class="wp-caption aligncenter" style="width: 473px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-302539" title="3D Through-Wall Imaging" src="http://www.kurzweilai.net/images/3D-Through-Wall-Imaging.png" alt="" width="463" height="129" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Structure and resulting 3D image (credit: Chitra R. Karanam and Yasamin Mostofi/ACM)</p></div>
<p>Interestingly, the equipment is all commercially available: two <a href="https://3dr.com/" target="_blank">drones</a> with &#8220;yagi&#8221; antenna, <a href="http://support.dlink.com/ProductInfo.aspx?m=WBR-1310" target="_blank">WiFi router</a>, <a href="https://get.google.com/tango/" target="_blank">Tango tablet</a> (for real-time localization), and <a href="https://www.adafruit.com/category/176" target="_blank">Raspberry Pi computer</a> with network interface to record measurements.</p>
<p>This development builds on previous 2D work by professor <a href="http://www.ece.ucsb.edu/~ymostofi/" target="_blank">Yasamin Mostofi’s</a> lab, which has pioneered sensing and imaging with everyday radio frequency signals such as WiFi. Mostofi says the success of the 3D experiments is due to the drones’ ability to approach the area from several angles, and to new methodology* developed by her lab.</p>
<p>The research is described in an open-access <a href="http://www.ece.ucsb.edu/~ymostofi/papers/IPSN17_KaranamMostofi.pdf" target="_blank">paper</a> published April 2017 in proceedings of the Association for Computing Machinery/Institute of Electrical and Electronics Engineers International Conference on Information Processing in Sensor Networks (IPSN).</p>
<p><em></em>A later <a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.118.183901" target="_blank">paper</a> by <a href="https://nortonsafe.search.ask.com/web?chn=RETAIL&amp;doi=&amp;geo=US&amp;guid=&amp;locale=EN&amp;o=APN11957&amp;p2=%5EEQ%5Esd03us%5E&amp;page=1&amp;prt=NIM&amp;ver=5&amp;q=Technical+University+of+Munich&amp;tpr=5">Technical University of Munich</a> physicists also reported a system intended for 3D imaging with WiFi, but with only simulated (and cruder) images. <em>(</em>An earlier 2009 <a href="http://www.ece.ucsb.edu/%7Eymostofi/papers/ACC09_MostofiSen.pdf" target="_blank">paper</a><em> </em>by Mostofi et al. also reported simulated results for 3D see-through imaging of structures.)</p>
<div id="attachment_302546" class="wp-caption alignleft" style="width: 272px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; float: left;"><img class="wp-image-302546 " title="transmit &amp; receive drones block diagram" src="http://www.kurzweilai.net/images/transmit-receive-drones-block-diagram.png" alt="" width="262" height="276" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Block diagram of the 3D through-wall imaging system (credit: Chitra R. Karanam and Yasamin Mostofi/ACM)</p></div>
<p><em>* The researchers’ approach to enabling 3D through-wall imaging utilizes four tightly integrated key components, according to the paper. </em></p>
<p><em>(1) They proposed robotic paths that can capture the spatial variations in all three dimensions as much as possible, while maintaining the efficiency of the operation. </em><em></em></p>
<p><em>(2)</em> <em>They modeled the three-dimensional unknown area of interest as a Markov Random Field to capture the spatial dependencies, and utilized a graph-based belief propagation approach to update the imaging decision of each voxel (the smallest unit of a 3D image) based on the decisions of the neighboring voxels. </em></p>
<p><em>(3) To approximate the interaction of the transmitted wave with the area of interest, they used a linear wave model. </em></p>
<p><em>(4) They took advantage of the compressibility of the information content to image the area with a very small number of WiFi measurements (less than 4 percent).</em></p>
<p><iframe frameborder="0" height="315" src="https://www.youtube.com/embed/THu3ZvAHI9A?rel=0" width="560"></iframe><br />
<em>Mostofi Lab | X-ray Eyes in the Sky: Drones and WiFi for 3D Through-Wall Imaging</em></p>
<hr />
<h4>Abstract of <em>3D Through-Wall Imaging with Unmanned Aerial Vehicles Using WiFi</em></h4>
<p>In this paper, we are interested in the 3D through-wall imaging of a completely unknown area, using WiFi RSSI and Unmanned Aerial Vehicles (UAVs) that move outside of the area of interest to collect WiFi measurements. It is challenging to estimate a volume represented by an extremely high number of voxels with a small number of measurements. Yet many applications are time-critical and/or limited on resources, precluding extensive measurement collection. In this paper, we then propose an approach based on Markov random field modeling, loopy belief propagation, and sparse signal processing for 3D imaging based on wireless power measurements. Furthermore, we show how to design ecient aerial routes that are informative for 3D imaging. Finally, we design and implement a complete experimental testbed and show high-quality 3D robotic through-wall imaging of unknown areas with less than 4% of measurements.</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:84:"http://www.kurzweilai.net/two-drones-see-through-walls-in-3d-using-wifi-signals/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:2:"10";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:12;a:6:{s:4:"data";s:59:"
		
		
		
		
		
								
		
				
		
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:64:"Crystal ‘domain walls’ may lead to tinier electronic devices";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:84:"http://www.kurzweilai.net/crystal-domain-walls-may-lead-to-tinier-electronic-devices";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:93:"http://www.kurzweilai.net/crystal-domain-walls-may-lead-to-tinier-electronic-devices#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Tue, 20 Jun 2017 03:02:03 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:3:{i:0;a:5:{s:4:"data";s:11:"Electronics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:26:"Nanotech/Materials Science";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=302275";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:413:"Queen&#8217;s University Belfast physicists have discovered a radical new way to modify the conductivity (ease of electron flow) of electronic circuits &#8212; reducing the size of future devices. The two latest KurzweilAI articles on graphene cited faster/lower-power performance and device-compatibility features. This new research takes another approach: Altering the properties of a crystal to eliminate [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:66:"http://www.kurzweilai.net/images/Domain-Walls-research2-140x42.jpg";s:5:"width";s:3:"140";s:6:"height";s:2:"42";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:3856:"<div id="attachment_302278" class="wp-caption aligncenter" style="width: 730px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><a href="http://www.kurzweilai.net/crystal-domain-walls-may-lead-to-tinier-electronic-devices/domain-walls-research2" rel="attachment wp-att-302278"><img class="size-full wp-image-302278" title="Domain Walls research2" src="http://www.kurzweilai.net/images/Domain-Walls-research2.jpg" alt="" width="720" height="217" /></a><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Abstract art? No, nanoscale crystal sheets with moveable conductive &#8220;domain walls&#8221; that can modify a circuit&#8217;s electronic properties (credit: Queen&#8217;s University Belfast)</p></div>
<p>Queen&#8217;s University Belfast physicists have discovered a radical new way to modify the conductivity (ease of electron flow) of electronic circuits &#8212; reducing the size of future devices.</p>
<p>The two latest <em>KurzweilAI</em> articles on graphene cited <a href="http://www.kurzweilai.net/graphene-based-computer-would-be-1000-times-faster-than-silicon-based-use-100th-the-power" target="_blank">faster/lower-power performance</a> and <a href="http://www.kurzweilai.net/new-chemical-method-could-revolutionize-graphene-use-in-electronics" target="_blank">device-compatibility</a> features. This new research takes another approach: Altering the properties of a crystal to eliminate the need for multiple circuits in devices.</p>
<p><strong>Reconfigurable nanocircuitry</strong></p>
<p>To do that, the scientists used &#8220;ferroelectric copper-chlorine boracite&#8221; crystal sheets, which are almost as thin as graphene. The researchers discovered that squeezing the crystal sheets with a sharp needle at a precise location causes a jigsaw-puzzle-like pattern of &#8220;domains walls&#8221; to develop around the contact point.</p>
<p>Then, using external applied electric fields, these writable, erasable domain walls can be repeatedly moved around in the crystal to create a variety of new electronic properties. They can appear, disappear, or move around within the crystal, all without permanently altering the crystal itself.</p>
<p>Eliminating the need for multiple circuits may reduce the size of future computers and other devices, according to the researchers.</p>
<p>The team&#8217;s findings have been published in an <a href="https://www.nature.com/articles/ncomms15105" target="_blank">open-access paper</a> in <em>Nature Communications</em>.</p>
<hr />
<p><strong>Abstract of <em>Injection and controlled motion of conducting domain walls in improper ferroelectric Cu-Cl boracite</em></strong></p>
<p>Ferroelectric domain walls constitute a completely new class of sheet-like functional material. Moreover, since domain walls are generally writable, erasable and mobile, they could be useful in functionally agile devices: for example, creating and moving conducting walls could make or break electrical connections in new forms of reconfigurable nanocircuitry. However, significant challenges exist: site-specific injection and annihilation of planar walls, which show robust conductivity, has not been easy to achieve. Here, we report the observation, mechanical writing and controlled movement of charged conducting domain walls in the improper-ferroelectric Cu<sub>3</sub>B<sub>7</sub>O<sub>13</sub>Cl. Walls are straight, tens of microns long and exist as a consequence of elastic compatibility conditions between specific domain pairs. We show that site-specific injection of conducting walls of up to hundreds of microns in length can be achieved through locally applied point-stress and, once created, that they can be moved and repositioned using applied electric fields.</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:89:"http://www.kurzweilai.net/crystal-domain-walls-may-lead-to-tinier-electronic-devices/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"5";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:13;a:6:{s:4:"data";s:59:"
		
		
		
		
		
								
		
				
		
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:67:"New chemical method could revolutionize graphene use in electronics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:93:"http://www.kurzweilai.net/new-chemical-method-could-revolutionize-graphene-use-in-electronics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:102:"http://www.kurzweilai.net/new-chemical-method-could-revolutionize-graphene-use-in-electronics#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Sat, 17 Jun 2017 03:34:39 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:3:{i:0;a:5:{s:4:"data";s:11:"Electronics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:26:"Nanotech/Materials Science";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=302317";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:378:"University of Illinois at Chicago scientists have solved a fundamental problem that has held back the use of wonder material graphene in a wide variety of electronics applications. When graphene is bonded (attached) to metal atoms (such as molybdenum) in devices such as solar cells, graphene&#8217;s superior conduction properties degrade. The solution: Instead of adding [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:74:"http://www.kurzweilai.net/images/graphene-with-delocalized-bond-140x53.png";s:5:"width";s:3:"140";s:6:"height";s:2:"53";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:3695:"<div id="attachment_302372" class="wp-caption aligncenter" style="width: 631px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-302372" title="graphene with delocalized bond" src="http://www.kurzweilai.net/images/graphene-with-delocalized-bond.png" alt="" width="621" height="239" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Adding a molecular structure containing carbon, chromium, and oxygen atoms retains graphene&#8217;s superior conductive properties. The metal atoms (silver, in this experiment) to be bonded are then added to the oxygen atoms on top. (credit: Songwei Che et al./Nano Letters)</p></div>
<p>University of Illinois at Chicago scientists have solved a fundamental problem that has held back the use of wonder material <a href="https://en.wikipedia.org/wiki/Graphene" target="_blank">graphene</a> in a wide variety of electronics applications.</p>
<p>When graphene is bonded (attached) to metal atoms (such as molybdenum) in devices such as solar cells, graphene&#8217;s superior conduction properties degrade.</p>
<p>The solution: Instead of adding molecules directly to the individual carbon atoms of graphene, the new method first adds a sort of buffer (consisting of chromium, carbon, and oxygen atoms) to the graphene, and then adds the metal atoms to this buffer material instead. That enables the graphene to retain its unique properties of electrical conduction.</p>
<p>In an experiment, the researchers successfully added silver nanoparticles to graphene with this method. That increased the material&#8217;s ability to boost the efficiency of graphene-based solar cells by 11 fold, said Vikas Berry, associate professor and department head of chemical engineering and senior author of a paper on the research, published in <em>Nano Letters</em>.</p>
<p><em>Researchers at Indian Institute of Technology and Clemson University were also involved in the study. The research was funded by the National Science Foundation.</em></p>
<hr />
<p><strong>Abstract of <em>Retained Carrier-Mobility and Enhanced Plasmonic-Photovoltaics of Graphene via ring-centered η<sup>6</sup> Functionalization and Nanointerfacing</em></strong></p>
<p>Binding graphene with auxiliary nanoparticles for plasmonics, photovoltaics, and/or optoelectronics, while retaining the trigonal-planar bonding of sp<sup>2</sup> hybridized carbons to maintain its carrier-mobility, has remained a challenge. The conventional nanoparticle-incorporation route for graphene is to create nucleation/attachment sites via “carbon-centered” covalent functionalization, which changes the local hybridization of carbon atoms from trigonal-planar sp<sup>2</sup>to tetrahedral sp<sup>3</sup>. This disrupts the lattice planarity of graphene, thus dramatically deteriorating its mobility and innate superior properties. Here, we show large-area, vapor-phase, “ring-centered” hexahapto (η<sup>6</sup>) functionalization of graphene to create nucleation-sites for silver nanoparticles (AgNPs) without disrupting its sp<sup>2</sup> character. This is achieved by the grafting of chromium tricarbonyl [Cr(CO)<sub>3</sub>] with all six carbon atoms (sigma-bonding) in the benzenoid ring on graphene to form an (η<sup>6</sup>-graphene)Cr(CO)<sub>3</sub> complex. This nondestructive functionalization preserves the lattice continuum with a retention in charge carrier mobility (9% increase at 10 K); with AgNPs attached on graphene/n-Si solar cells, we report an ∼11-fold plasmonic-enhancement in the power conversion efficiency (1.24%).</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:98:"http://www.kurzweilai.net/new-chemical-method-could-revolutionize-graphene-use-in-electronics/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"1";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:14;a:6:{s:4:"data";s:62:"
		
		
		
		
		
								
		
				
		
		
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:91:"Graphene-based computer would be 1,000 times faster than silicon-based, use 100th the power";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:115:"http://www.kurzweilai.net/graphene-based-computer-would-be-1000-times-faster-than-silicon-based-use-100th-the-power";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:124:"http://www.kurzweilai.net/graphene-based-computer-would-be-1000-times-faster-than-silicon-based-use-100th-the-power#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Fri, 16 Jun 2017 03:02:11 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:4:{i:0;a:5:{s:4:"data";s:21:"Computers/Infotech/UI";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:11:"Electronics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:26:"Nanotech/Materials Science";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=302293";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:381:"A future graphene-based transistor using spintronics could lead to tinier computers that are a thousand times faster and use a hundredth of the power of silicon-based computers. The radical transistor concept, created by a team of researchers at Northwestern University, The University of Texas at Dallas, University of Illinois at Urbana-Champaign, and University of Central [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:68:"http://www.kurzweilai.net/images/Magnetoresistive-GNR-ft-140x107.png";s:5:"width";s:3:"140";s:6:"height";s:3:"107";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:5352:"<div id="attachment_302334" class="wp-caption aligncenter" style="width: 519px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-302334" title="Magnetoresistive GNR" src="http://www.kurzweilai.net/images/Magnetoresistive-GNR.png" alt="" width="509" height="286" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">How a graphene-based transistor would work. A graphene nanoribbon (GNR) is created by unzipping (opening up) a portion of a carbon nanotube (CNT) (the flat area, shown with pink arrows above it). The GRN switching is controlled by two surrounding parallel CNTs. The magnitudes and relative directions of the control current, ICTRL (blue arrows) in the CNTs determine the rotation direction of the magnetic fields, B (green). The magnetic fields then control the GNR magnetization (based on the recent discovery of negative magnetoresistance), which causes the GNR to switch from resistive (no current) to conductive, resulting in current flow, IGNR (pink arrows) &#8212; in other words, causing the GNR to act as a transistor gate. The magnitude of the current flow through the GNR functions as the binary gate output &#8212; with binary 1 representing the current flow of the conductive state and binary 0 representing no current (the resistive state). (credit: Joseph S. Friedman et al./Nature Communications)</p></div>
<p>A future <a href="https://en.wikipedia.org/wiki/Graphene" target="_blank">graphene</a>-based transistor using <a href="https://en.wikipedia.org/wiki/Spintronics" target="_blank">spintronics</a> could lead to tinier computers that are a thousand times faster and use a hundredth of the power of silicon-based computers.</p>
<p>The radical transistor concept, created by a team of researchers at Northwestern University<em>, </em>The University of Texas at Dallas<em>, </em>University of Illinois at Urbana-Champaign, and University of Central Florida, is explained this month in an <a href="https://www.nature.com/articles/ncomms15635" target="_blank">open-access paper</a> in the journal <em>Nature Communications</em>.</p>
<p>Transistors act as on and off switches. A series of transistors in different arrangements act as logic gates, allowing microprocessors to solve complex arithmetic and logic problems. But the speed of computer microprocessors that rely on silicon transistors has been relatively stagnant since around 2005, with clock speeds mostly in the 3 to 4 gigahertz range.</p>
<p><strong>Clock speeds approaching the terahertz range</strong></p>
<p>The researchers discovered that by applying a magnetic field to a graphene ribbon (created by unzipping a carbon nanotube), they could change the resistance of current flowing through the ribbon. The magnetic field &#8212; controlled by increasing or decreasing the current through adjacent carbon nanotubes &#8212; increased or decreased the flow of current.</p>
<p>A cascading series of graphene transistor-based logic circuits could produce a massive jump, with clock speeds approaching the terahertz range &#8212; a thousand times faster.* They would also be smaller and substantially more efficient, allowing device-makers to shrink technology and squeeze in more functionality, according to Ryan M. Gelfand, an assistant professor in The College of Optics &amp; Photonics at the University of Central Florida.</p>
<p>The researchers hope to inspire the fabrication of these cascaded logic circuits to stimulate a future transformative generation of energy-efficient computing.</p>
<p><em>* Unlike other spintronic logic proposals, these new logic gates can be cascaded directly through the carbon materials without requiring intermediate circuits and amplification between gates. That would result in compact circuits with reduced area that are far more efficient than with CMOS switching, which is limited by charge transfer and accumulation </em><em>from RLC (resistance-inductance-capacitance) interconnect delays.</em></p>
<hr />
<p><strong>Abstract of <em>Cascaded spintronic logic with low-dimensional carbon</em></strong></p>
<p>Remarkable breakthroughs have established the functionality of graphene and carbon nanotube transistors as replacements to silicon in conventional computing structures, and numerous spintronic logic gates have been presented. However, an efficient cascaded logic structure that exploits electron spin has not yet been demonstrated. In this work, we introduce and analyse a cascaded spintronic computing system composed solely of low-dimensional carbon materials. We propose a spintronic switch based on the recent discovery of negative magnetoresistance in graphene nanoribbons, and demonstrate its feasibility through tight-binding calculations of the band structure. Covalently connected carbon nanotubes create magnetic fields through graphene nanoribbons, cascading logic gates through incoherent spintronic switching. The exceptional material properties of carbon materials permit Terahertz operation and two orders of magnitude decrease in power-delay product compared to cutting-edge microprocessors. We hope to inspire the fabrication of these cascaded logic circuits to stimulate a transformative generation of energy-efficient computing.</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:120:"http://www.kurzweilai.net/graphene-based-computer-would-be-1000-times-faster-than-silicon-based-use-100th-the-power/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"9";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:15;a:6:{s:4:"data";s:62:"
		
		
		
		
		
								
		
				
		
		
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:104:"High-speed light-based systems could replace supercomputers for certain ‘deep learning’ calculations";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:85:"http://www.kurzweilai.net/learning-with-light-new-system-allows-optical-deep-learning";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:94:"http://www.kurzweilai.net/learning-with-light-new-system-allows-optical-deep-learning#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Wed, 14 Jun 2017 04:48:14 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:4:{i:0;a:5:{s:4:"data";s:11:"AI/Robotics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:21:"Computers/Infotech/UI";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:11:"Electronics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=302226";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:369:"A team of researchers at MIT and elsewhere has developed a new approach to deep learning systems &#8212; using light instead of electricity, which they say could vastly improve the speed and efficiency of certain deep-learning computations. Deep-learning systems are based on artificial neural networks that mimic the way the brain learns from an accumulation of [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:72:"http://www.kurzweilai.net/images/Optical-Interference-Unit-ft-140x34.png";s:5:"width";s:3:"140";s:6:"height";s:2:"34";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:6014:"<div id="attachment_302251" class="wp-caption aligncenter" style="width: 555px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-302251" title="Optical Interference Unit" src="http://www.kurzweilai.net/images/Optical-Interference-Unit.png" alt="" width="545" height="361" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">(a) Optical micrograph of an experimentally fabricated on-chip optical interference unit; the physical region where the optical neural network program exists is highlighted in gray. A programmable nanophotonic processor uses a field-programmable gate array (similar to an FPGA integrated circuit ) &#8212; an array of interconnected waveguides, allowing the light beams to be modified as needed for a specific deep-learning matrix computation. (b) Schematic illustration of the optical neural network program, which performs matrix multiplication and amplification fully optically. (credit: Yichen Shen et al./Nature Photonics)</p></div>
<p>A team of researchers at MIT and elsewhere has developed a new approach to <a href="https://en.wikipedia.org/wiki/Deep_learning" target="_blank">deep learning</a> systems &#8212; using light instead of electricity, which they say could vastly improve the speed and efficiency of certain deep-learning computations.</p>
<p>Deep-learning systems are based on <a href="artificial neural networks" target="_blank">artificial neural networks</a> that mimic the way the brain learns from an accumulation of examples. They can enable technologies such as face- and voice-recognition software, or scour vast amounts of medical data to find patterns that could be useful diagnostically, for example.</p>
<p>But the computations these systems carry out are highly complex and demanding, even for supercomputers. Traditional computer architectures are not very efficient for calculations needed for neural-network tasks that involve repeated multiplications of <a href="https://en.wikipedia.org/wiki/Matrix_(mathematics)" target="_blank">matrices</a> (arrays of numbers). These can be computationally intensive for conventional CPUs or even GPUs.</p>
<p><strong>Programmable nanophotonic processor</strong></p>
<p>Instead, the new approach uses an optical device that the researchers call a &#8220;programmable nanophotonic processor.&#8221; Multiple light beams are directed in such a way that their waves interact with each other, producing <a href="https://en.wikipedia.org/wiki/Interference_(wave_propagation)" target="_blank">interference patterns</a> that &#8220;compute&#8221; the intended operation.</p>
<p>The optical chips using this architecture could, in principle, carry out dense matrix multiplications (the most power-hungry and time-consuming part in AI algorithms) for learning tasks much faster, compared to conventional electronic chips. The researchers expect a computational speed enhancement of at least two orders of magnitude over the state-of-the-art and three orders of magnitude in power efficiency.</p>
<p>&#8220;This chip, once you tune it, can carry out matrix multiplication with, in principle, zero energy, almost instantly,&#8221; says Marin Soljacic, one of the MIT researchers on the team.</p>
<p>To demonstrate the concept, the team set the programmable nanophotonic processor to implement a neural network that recognizes four basic vowel sounds. Even with the prototype system, they were able to achieve a 77 percent accuracy level, compared to about 90 percent for conventional systems. There are &#8220;no substantial obstacles&#8221; to scaling up the system for greater accuracy, according to Soljacic.</p>
<p>The team says is will still take a lot more time and effort to make this system useful. However, once the system is scaled up and fully functioning, the low-power system should find many uses, especially for situations where power is limited, such as in self-driving cars, drones, and mobile consumer devices. Other uses include signal processing for data transmission and computer centers.</p>
<p>The research was published Monday (June 12, 2017) in a <a href="https://www.nature.com/nphoton/journal/vaop/ncurrent/full/nphoton.2017.93.html" target="_blank">paper</a> in the journal <em>Nature Photonics </em>(open-access version available on <em><a href="https://arxiv.org/abs/1610.02365" target="_blank">arXiv</a></em>).<em><br />
</em></p>
<p><em>The team also included researchers at Elenion Technologies of New York and the Université de Sherbrooke in Quebec. The work was supported by the U.S. Army Research Office through the Institute for Soldier Nanotechnologies, the National Science Foundation, and the Air Force Office of Scientific Research.</em></p>
<hr />
<p><strong>Abstract of <em>Deep learning with coherent nanophotonic circuits</em></strong></p>
<p>Artificial neural networks are computational network models inspired by signal processing in the brain. These models have dramatically improved performance for many machine-learning tasks, including speech and image recognition. However, today&#8217;s computing hardware is inefficient at implementing neural networks, in large part because much of it was designed for von Neumann computing schemes. Significant effort has been made towards developing electronic architectures tuned to implement artificial neural networks that exhibit improved computational speed and accuracy. Here, we propose a new architecture for a fully optical neural network that, in principle, could offer an enhancement in computational speed and power efficiency over state-of-the-art electronics for conventional inference tasks. We experimentally demonstrate the essential part of the concept using a programmable nanophotonic processor featuring a cascaded array of 56 programmable Mach–Zehnder interferometers in a silicon photonic integrated circuit and show its utility for vowel recognition.</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:90:"http://www.kurzweilai.net/learning-with-light-new-system-allows-optical-deep-learning/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"3";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:16;a:6:{s:4:"data";s:59:"
		
		
		
		
		
								
		
				
		
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:67:"A noninvasive method for deep-brain stimulation for brain disorders";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:93:"http://www.kurzweilai.net/a-noninvasive-method-for-deep-brain-stimulation-for-brain-disorders";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:102:"http://www.kurzweilai.net/a-noninvasive-method-for-deep-brain-stimulation-for-brain-disorders#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Sun, 11 Jun 2017 21:56:58 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:3:{i:0;a:5:{s:4:"data";s:30:"Cognitive Science/Neuroscience";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:11:"Electronics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=301863";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:395:"MIT researchers and associates have come up with a breakthrough method of remotely stimulating regions deep within the brain, replacing the invasive surgery now required for implanting electrodes for Parkinson&#8217;s and other brain disorders. The new method could make deep-brain stimulation for brain disorders less expensive, more accessible to patients, and less risky (avoiding brain [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:67:"http://www.kurzweilai.net/images/hippocampus-stimulation-140x49.png";s:5:"width";s:3:"140";s:6:"height";s:2:"49";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:7765:"<div id="attachment_302155" class="wp-caption aligncenter" style="width: 585px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-302155" title="hippocampus stimulation" src="http://www.kurzweilai.net/images/hippocampus-stimulation.png" alt="" width="575" height="202" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">External electrical waves excite an area in the mouse hippocampus, shown in bright green. (credit: Nir Grossman, Ph.D., Suhasa B. Kodandaramaiah, Ph.D., and Andrii Rudenko, Ph.D.)</p></div>
<p>MIT researchers and associates have come up with a breakthrough method of remotely stimulating regions deep within the brain, replacing the invasive surgery now required for implanting electrodes for Parkinson&#8217;s and other brain disorders.</p>
<p>The new method could make deep-brain stimulation for brain disorders less expensive, more accessible to patients, and less risky (avoiding brain hemorrhage and infection).</p>
<p>Working with mice, the researchers applied two high-frequency electrical currents at two slightly different frequencies (<em>E1</em> and <em>E2</em> in the diagram below), attaching electrodes (similar those used with an EEG brain machine) to the surface of the skull.</p>
<div id="attachment_302151" class="wp-caption aligncenter" style="width: 378px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-302151" title="deep brain stimulation" src="http://www.kurzweilai.net/images/deep-brain-stimulation.png" alt="" width="368" height="380" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">A new noninvasive method for deep-brain stimulation (credit: Grossman et al./Cell)</p></div>
<p>At these higher brain frequencies, the currents have no effect on brain tissues. But where the currents converge deep in the brain, they interfere with one another in such a way that they generate low-frequency current (corresponding to the red envelope in the diagram) inside neurons, thus stimulating neural electrical activity.</p>
<p>The researchers named this method &#8220;temporal interference stimulation&#8221; (that is, interference between pulses in the two currents at two slightly different times &#8212; generating the difference frequency).* For the experimental setup shown in the diagram above, the <em>E1</em> current was 1kHz (1,000 Hz), which mixed with a 1.04kHz <em>E2</em> current. That generated a current with a 40Hz &#8220;delta f&#8221; difference frequency &#8212; a frequency that can stimulate neural activity in the brain. (The researchers found no harmful effects in any part of the mouse brain.)</p>
<p>“Traditional deep-brain stimulation requires opening the skull and implanting an electrode, which can have complications,” explains Ed Boyden, an associate professor of biological engineering and brain and cognitive sciences at MIT, and the senior author of the study, which appears in the June 1, 2017 issue of the journal <em>Cell</em>. Also, “only a small number of people can do this kind of neurosurgery.”</p>
<h4>Custom-designed, targeted deep-brain stimulation</h4>
<p>If this new method is perfected and clinically tested, neurologists could control the size and location of the exact tissue that receives the electrical stimulation for each patient, by selecting the frequency of the currents and the number and location of the electrodes, according to the researchers.</p>
<p>Neurologists could also steer the location of deep-brain stimulation in real time, without moving the electrodes, by simply altering the currents. In this way, deep targets could be stimulated for conditions such as Parkinson&#8217;s, epilepsy, depression, and obsessive-compulsive disorder &#8212; without affecting surrounding brain structures.</p>
<p>The researchers are also exploring the possibility of using this method to experimentally treat other brain conditions, such as autism, and for basic science investigations.</p>
<p>Co-author Li-Huei Tsai, director of MIT’s Picower Institute for Learning and Memory, and researchers in her lab tested this technique in mice and found that they could stimulate small regions deep within the brain, including the hippocampus. But they were also able to shift the site of stimulation, allowing them to activate different parts of the motor cortex and prompt the mice to move their limbs, ears, or whiskers.</p>
<p>“We showed that we can very precisely target a brain region to elicit not just neuronal activation but behavioral responses,” says Tsai.</p>
<p>Last year, Tsai <a href="http://www.cell.com/neuron/pdf/S0896-6273(03)00627-5.pdf" target="_blank">showed</a> (open access) that using light to visually induce brain waves of a particular frequency could substantially reduce the beta amyloid plaques seen in Alzheimer’s disease, in the brains of mice. She now plans to explore whether this new type of electrical stimulation could offer a new way to generate the same type of beneficial brain waves.</p>
<p>This new method is also an alternative to other brain-stimulation methods.</p>
<p>Transcranial magnetic stimulation (TMS), which is FDA-approved for treating depression and to study the basic science of cognition, emotion, sensation, and movement, can stimulate deep brain structures but can result in surface regions being strongly stimulated, according to the researchers.</p>
<p>Transcranial ultrasound and expression of heat-sensitive receptors and injection of thermomagnetic nanoparticles have been proposed, “but the unknown mechanism of action &#8230; and the need to genetically manipulate the brain, respectively, may limit their immediate use in humans,” the researchers note in the paper.</p>
<p>The MIT researchers collaborated with investigators at Beth Israel Deaconess Medical Center (BIDMC), the IT’IS Foundation, Harvard Medical School, and ETH Zurich.</p>
<p><em>The research was funded in part by the Wellcome Trust, a National Institutes of Health Director’s Pioneer Award, an NIH Director’s Transformative Research Award, the New York Stem Cell Foundation Robertson Investigator Award, the MIT Center for Brains, Minds, and Machines, Jeremy and Joyce Wertheimer, Google, a National Science Foundation Career Award, the MIT Synthetic Intelligence Project, and Harvard Catalyst: The Harvard Clinical and Translational Science Center.</em></p>
<p><em>* Similar to a radio-frequency or audio “beat frequency.”<br />
</em></p>
<hr />
<h4>Abstract of <em>Noninvasive Deep Brain Stimulation via Temporally Interfering Electric Fields</em></h4>
<p>We report a noninvasive strategy for electrically stimulating neurons at depth. By delivering to the brain multiple electric fields at frequencies too high to recruit neural firing, but which differ by a frequency within the dynamic range of neural firing, we can electrically stimulate neurons throughout a region where interference between the multiple fields results in a prominent electric field envelope modulated at the difference frequency. We validated this temporal interference (TI) concept via modeling and physics experiments, and verified that neurons in the living mouse brain could follow the electric field envelope. We demonstrate the utility of TI stimulation by stimulating neurons in the hippocampus of living mice without recruiting neurons of the overlying cortex. Finally, we show that by altering the currents delivered to a set of immobile electrodes, we can steerably evoke different motor patterns in living mice.</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:98:"http://www.kurzweilai.net/a-noninvasive-method-for-deep-brain-stimulation-for-brain-disorders/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:2:"20";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:17;a:6:{s:4:"data";s:56:"
		
		
		
		
		
								
		
				
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:55:"Researchers decipher how faces are encoded in the brain";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:81:"http://www.kurzweilai.net/researchers-decipher-how-faces-are-encoded-in-the-brain";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:90:"http://www.kurzweilai.net/researchers-decipher-how-faces-are-encoded-in-the-brain#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Sat, 10 Jun 2017 03:43:21 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:2:{i:0;a:5:{s:4:"data";s:30:"Cognitive Science/Neuroscience";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=301884";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:368:"In a paper published (open access) June 1 in the journal Cell, researchers report that they have cracked the code for facial identity in the primate brain. &#8220;We&#8217;ve discovered that this code is extremely simple,&#8221; says senior author Doris Tsao, a professor of biology and biological engineering at the California Institute of Technology and senior [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:72:"http://www.kurzweilai.net/images/actual-vs-predicted-face-ft-140x115.png";s:5:"width";s:3:"140";s:6:"height";s:3:"115";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:7258:"<div id="attachment_301885" class="wp-caption aligncenter" style="width: 628px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-301885" title="Facial Reconstruction in the Brain" src="http://www.kurzweilai.net/images/Facial-Reconstruction-in-the-Brain.jpg" alt="" width="618" height="672" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">This figure shows eight different real faces that were presented to a monkey, together with reconstructions made by analyzing electrical activity from 205 neurons recorded while the monkey was viewing the faces. (credit: Doris Tsao)</p></div>
<p>In a paper published (open access) June 1 in the journal <em>Cell</em>, researchers report that they have cracked the code for facial identity in the primate brain.</p>
<p>&#8220;We&#8217;ve discovered that this code is extremely simple,&#8221; says senior author <a href="http://tsaolab.caltech.edu/?q=People_Tsao" target="_blank">Doris Tsao</a>, a professor of biology and biological engineering at the <a href="http://www.caltech.edu/" target="_blank">California Institute of Technology</a> and senior author. &#8220;We can now reconstruct a face that a monkey is seeing by monitoring the electrical activity of only 205 neurons in the monkey&#8217;s brain. One can imagine applications in forensics where one could reconstruct the face of a criminal by analyzing a witness&#8217;s brain activity.&#8221;</p>
<p>The researchers previously identified the six &#8220;face patches&#8221; &#8212; general areas of the primate and human brain that are responsible for identifying faces &#8212; all located in the inferior temporal (IT) cortex. They also found that these areas are packed with specific nerve cells that fire action potentials much more strongly when seeing faces than when seeing other objects. They called these neurons &#8220;face cells.&#8221;</p>
<p>Previously, some experts in the field <a href="https://www.nature.com/nature/journal/v435/n7045/full/nature03687.html" target="_blank">believed</a> that each face cell (a.k.a. &#8220;<a href="https://www.ncbi.nlm.nih.gov/pubmed?Db=pubmed&amp;Cmd=ShowDetailView&amp;TermToSearch=19159155" target="_blank">grandmother cell</a>&#8220;) in the brain represents a specific face, but this presented a paradox, says Tsao, who is also a Howard Hughes Medical Institute investigator. &#8220;You could potentially recognize 6 billion people, but you don&#8217;t have 6 billion face cells in the IT cortex. There had to be some other solution.&#8221;</p>
<p>Instead, they found that rather than representing a specific identity, each face cell represents a specific <em>axis</em> within a multidimensional space, which they call the &#8220;face space.&#8221; These axes can combine in different ways to create every possible face. In other words, there is no <a href="http://www.nature.com/news/2005/050620/full/news050620-7.html" target="_blank">&#8220;Jennifer Aniston&#8221; neuron</a>.</p>
<p>The clinching piece of evidence: the researchers could create a large set of faces that looked extremely different, but which all caused the cell to fire in exactly the same way. &#8220;This was completely shocking to us &#8212; we had always thought face cells were more complex. But it turns out each face cell is just measuring distance along a single axis of face space, and is blind to other features,&#8221; Tsao says.</p>
<p><strong>AI applications</strong></p>
<p>&#8220;The way the brain processes this kind of information doesn&#8217;t have to be a black box,&#8221; Chang explains. &#8220;Although there are many steps of computations between the image we see and the responses of face cells, the code of these face cells turned out to be quite simple once we found the proper axes. This work suggests that other objects could be encoded with similarly simple coordinate systems.&#8221;</p>
<p>The research also has artificial intelligence applications. &#8220;This could inspire new machine learning algorithms for recognizing faces,&#8221; Tsao adds. &#8220;In addition, our approach could be used to figure out how units in deep networks encode other things, such as objects and sentences.&#8221;</p>
<p><em>This research was supported by the National Institutes of Health, the Howard Hughes Medical Institute, the Tianqiao and Chrissy Chen Institute for Neuroscience at Caltech, and the Swartz Foundation.</em></p>
<p><em>* The researchers started by creating a 50-dimensional space that could represent all faces. They assigned 25 dimensions to the shape&#8211;such as the distance between eyes or the width of the hairline&#8211;and 25 dimensions to nonshape-related appearance features, such as skin tone and texture.</em></p>
<p><em>Using macaque monkeys as a model system, the researchers inserted electrodes into the brains that could record individual signals from single face cells within the face patches. They found that each face cell fired in proportion to the projection of a face onto a single axis in the 50-dimensional face space. Knowing these axes, the researchers then developed an algorithm that could decode additional faces from neural responses.</em></p>
<p><em>In other words, they could now show the monkey an arbitrary new face, and recreate the face that the monkey was seeing from electrical activity of face cells in the animal&#8217;s brain. When placed side by side, the photos that the monkeys were shown and the faces that were recreated using the algorithm were nearly identical. Face cells from only two of the face patches&#8211;106 cells in one patch and 99 cells in another&#8211;were enough to reconstruct the faces. &#8220;People always say a picture is worth a thousand words,&#8221; Tsao says. &#8220;But I like to say that a picture of a face is worth about 200 neurons.&#8221;</em></p>
<p><iframe frameborder="0" height="315" src="https://www.youtube.com/embed/cwNj-X-0v5s?rel=0" width="560"></iframe><br />
<em>Caltech | Researchers decipher the enigma of how faces are encoded</em></p>
<hr />
<h4>Abstract of <em>The Code for Facial Identity in the Primate Brain</em></h4>
<p>Primates recognize complex objects such as faces with remarkable speed and reliability. Here, we reveal the brain’s code for facial identity. Experiments in macaques demonstrate an extraordinarily simple transformation between faces and responses of cells in face patches. By formatting faces as points in a high-dimensional linear space, we discovered that each face cell’s firing rate is proportional to the projection of an incoming face stimulus onto a single axis in this space, allowing a face cell ensemble to encode the location of any face in the space. Using this code, we could precisely decode faces from neural population responses and predict neural firing rates to faces. Furthermore, this code disavows the long-standing assumption that face cells encode specific facial identities, confirmed by engineering faces with drastically different appearance that elicited identical responses in single face cells. Our work suggests that other objects could be encoded by analogous metric coordinate systems.</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:86:"http://www.kurzweilai.net/researchers-decipher-how-faces-are-encoded-in-the-brain/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:2:"12";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:18;a:6:{s:4:"data";s:53:"
		
		
		
		
		
								
		
				

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:50:"Technology Driving Transportation Executive Summit";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:76:"http://www.kurzweilai.net/technology-driving-transportation-executive-summit";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:85:"http://www.kurzweilai.net/technology-driving-transportation-executive-summit#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Fri, 09 Jun 2017 21:55:23 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:1:{i:0;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=302093";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:421:"The Technology Driving Transportation Summit is a one-day Executive Summit focused on the development &#38; deployment of the most cutting edge technologies as well as the education of the next generation workforce. Thought leaders from across transportation, artificial intelligence, automation, cyber security, labor, and technology companies turn thoughts and research into action, setting the market conditions [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:51:"http://www.kurzweilai.net/images/pobrane-140x27.png";s:5:"width";s:3:"140";s:6:"height";s:2:"27";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:835:"<p><img style=' display: block; margin-right: auto; margin-left: auto;'  class="size-full wp-image-302094 noshadow aligncenter" title="" src="http://www.kurzweilai.net/images/pobrane.png" alt="" width="273" height="54" /></p>
<p>The Technology Driving Transportation Summit is a one-day Executive Summit focused on the development &amp; deployment of the most cutting edge technologies as well as the education of the next generation workforce. Thought leaders from across transportation, artificial intelligence, automation, cyber security, labor, and technology companies turn thoughts and research into action, setting the market conditions for the success of the rapid adoption of new technologies in transportation and laying the ground work for public acceptance of these technologies.</p>
<p><em>&#8212;Event Producer</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:81:"http://www.kurzweilai.net/technology-driving-transportation-executive-summit/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:19;a:6:{s:4:"data";s:53:"
		
		
		
		
		
								
		
				

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:16:"CogX London 2017";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:42:"http://www.kurzweilai.net/cogx-london-2017";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:51:"http://www.kurzweilai.net/cogx-london-2017#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Fri, 09 Jun 2017 21:46:33 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:1:{i:0;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=302105";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:380:"The emerging world of AI is expected to create incredible opportunities and cause unprecedented disruption across all industries. Healthcare, financial services, education, the future of work and more will be shaped by the proliferation of AI. However, market complexity and fragmentation coupled with the incredible pace of change (1,500 new companies in 2016 alone) brings [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:68:"http://www.kurzweilai.net/images/CogXLondon2017_text_bl-1-140x17.png";s:5:"width";s:3:"140";s:6:"height";s:2:"17";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:1580:"<p><img style=' display: block; margin-right: auto; margin-left: auto;'  class="aligncenter  wp-image-302106 noshadow" title="CogXLondon2017_text_bl-1" src="http://www.kurzweilai.net/images/CogXLondon2017_text_bl-1.png" alt="" width="418" height="51" /></p>
<p>The emerging world of AI is expected to create incredible opportunities and cause unprecedented disruption across all industries. Healthcare, financial services, education, the future of work and more will be shaped by the proliferation of AI.</p>
<p>However, market complexity and fragmentation coupled with the incredible pace of change (1,500 new companies in 2016 alone) brings about great challenges; how should we navigate this complex landscape?</p>
<p>The AI Innovation Exchange and Annual Awards is bringing together thought leaders across more than 20 industries and domains to address the pressing issues and move the conversation forward. In a combination of keynotes, expert panels and results-driven workshops we will agree the open issues and publish papers from the breakout sessions’ findings. An interactive trade expo will showcase the current state of art in the field, and at our gala dinner we will present 10 categories of awards celebrating innovation in AI. We hope that CogX will bring clarity to the marketplace, celebrate innovation and facilitate strategies for the future.</p>
<p>The whole event comprises: 1/2 Day Exec AI Bootcamp, 2 Day Exchange across 18 topics, Awards dinner, AI Expo, Breakout sessions and working groups &amp; VIP events.</p>
<p><em>&#8212;Event Producer</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:47:"http://www.kurzweilai.net/cogx-london-2017/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:20;a:6:{s:4:"data";s:56:"
		
		
		
		
		
								
		
				
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:79:"Playing a musical instrument could help restore brain health, research suggests";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:104:"http://www.kurzweilai.net/playing-a-musical-instrument-could-help-restore-brain-health-research-suggests";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:113:"http://www.kurzweilai.net/playing-a-musical-instrument-could-help-restore-brain-health-research-suggests#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Thu, 08 Jun 2017 05:35:10 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:2:{i:0;a:5:{s:4:"data";s:30:"Cognitive Science/Neuroscience";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=301868";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:404:"A study by neuroscientists at Toronto-based Baycrest Rotman Research Institute and Stanford University involving playing a musical instrument suggests ways to improve brain rehabilitation methods. In the study, published in the Journal of Neuroscience on May 24, 2017, the researchers asked young adults to listen to sounds from an unfamiliar musical instrument (a Tibetan singing bowl). Half of [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:64:"http://www.kurzweilai.net/images/Tibetan-Singing-Bowl-140x61.jpg";s:5:"width";s:3:"140";s:6:"height";s:2:"61";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:6539:"<div id="attachment_301869" class="wp-caption aligncenter" style="width: 634px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class="size-full wp-image-301869" title="Tibetan Singing Bowl" src="http://www.kurzweilai.net/images/Tibetan-Singing-Bowl.jpg" alt="" width="624" height="273" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Tibetan singing bowl (credit: Baycrest Health Sciences)</p></div>
<p>A study by neuroscientists at Toronto-based <a href="http://www.baycrest.org/research/rotman-research-institute/" target="_blank">Baycrest Rotman Research Institute</a> and Stanford University involving playing a musical instrument suggests ways to improve brain rehabilitation methods.</p>
<p>In the study, published in the <a title="Journal of Neuroscience" href="http://www.jneurosci.org/" target="_blank"><em>Journal of Neuroscience</em></a> on May 24, 2017, the researchers asked young adults to listen to sounds from an unfamiliar musical instrument (a Tibetan singing bowl). Half of the subjects (the experimental group) were then asked to recreate the same sounds and rhythm by striking the bowl; the other half (the control group) were instead asked to recreate the sound by simply pressing a key on a computer keypad.</p>
<p>After listening to the sounds they created, subjects in the experimental group showed increased auditory-evoked <a href="https://en.wikipedia.org/wiki/P200" target="_blank">P2 (P200) brain waves</a>. This was significant because the P2 increase &#8220;occurred immediately, while in previous learning-by-listening studies, P2 increases occurred on a later day,&#8221; the researchers explained in the paper. The experimental group also had increased responsiveness of brain beta-wave oscillations and enhanced connectivity between auditory and sensorimotor cortices (areas) in the brain.</p>
<p>The brain changes were measured using <a href="https://en.wikipedia.org/wiki/Magnetoencephalography" target="_blank">magnetoencephalographic</a> (MEG) recording, which is similar to EEG, but uses highly sensitive magnetic sensors.</p>
<p><strong>Immediate beneficial effects on the brain</strong></p>
<p>&#8220;The results &#8230; provide a neurophysiological basis for the application of music making in motor rehabilitation [increasing the ability to move arms and legs] training,&#8221; the authors state in the paper. The findings support Ross’ research in using musical training to help stroke survivors rehabilitate motor movement in their upper bodies. Baycrest scientists also have a history of breakthroughs in understanding how a person’s musical background impacts their <a title="listening abilities" href="http://www.baycrest.org/news/science-finding-is-music-to-the-ears/" target="_blank">listening abilities</a> and <a title="cognitive function as" href="http://www.baycrest.org/news/more-evidence-that-musical-training-protects-the-brain/" target="_blank">cognitive function</a> as they age.</p>
<p>“This study was the first time we saw direct changes in the brain after one session, demonstrating that the action of creating music leads to a strong change in brain activity,&#8221; said <a title="Dr. Bernhard Ross" href="http://research.baycrest.org/bross" target="_blank">Bernhard Ross</a>, PhD., senior scientist at Rotman Research Institute and senior author on the study.</p>
<p>“Music has been known to have beneficial effects on the brain, but there has been limited understanding into what about music makes a difference,” he added. “This is the first study demonstrating that learning the fine movement needed to reproduce a sound on an instrument changes the brain’s perception of sound in a way that is not seen when listening to music.”</p>
<p>The study’s next steps involve analyzing recovery by stroke patients with musical training compared to physiotherapy, and the impact of musical training on the brains of older adults. With additional funding, the study could explore developing musical training rehabilitation programs for other conditions that impact motor function, such as traumatic brain injury, and lead to hearing aids of the future, the researchers say.</p>
<p><em>The study received support from the <a title="Canadian Institutes of Health Research" href="http://www.cihr-irsc.gc.ca/e/193.html" target="_blank">Canadian Institutes of Health Research</a>.</em></p>
<hr />
<h4>Abstract of <em>Sound-making actions lead to immediate plastic changes of neuromagnetic evoked responses and induced beta-band oscillations during perception</em></h4>
<p>Auditory and sensorimotor brain areas interact during the action-perception cycle of sound making. Neurophysiological evidence of a feedforward model of the action and its outcome has been associated with attenuation of the N1 wave of auditory evoked responses elicited by self-generated sounds, such as vocalization or playing a musical instrument. Moreover, neural oscillations at beta-band frequencies have been related to predicting the sound outcome after action initiation. We hypothesized that a newly learned action-perception association would immediately modify interpretation of the sound during subsequent listening. Nineteen healthy young adults (seven female, twelve male) participated in three magnetoencephalography (MEG) recordings while first passively listening to recorded sounds of a bell ringing, then actively playing the bell with a mallet, and then again listening to recorded sounds. Auditory cortex activity showed characteristic P1-N1-P2 waves. The N1 was attenuated during sound making, while P2 responses were unchanged. In contrast, P2 became larger when listening after sound making compared to the initial naïve listening. The P2 increase occurred immediately, while in previous learning-by-listening studies P2 increases occurred on a later day. Also, reactivity of beta-band oscillations as well as theta coherence between auditory and sensorimotor cortices was stronger in the second listening block. These changes were significantly larger than those observed in control participants (eight female, five male), who triggered recorded sounds by a keypress. We propose that P2 characterizes familiarity with sound objects, whereas beta-band oscillation signifies involvement of the action-perception cycle, and both measures objectively indicate functional neuroplasticity in auditory perceptual learning.</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:109:"http://www.kurzweilai.net/playing-a-musical-instrument-could-help-restore-brain-health-research-suggests/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"1";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:21;a:6:{s:4:"data";s:53:"
		
		
		
		
		
								
		
				

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:41:"Weekend Workshop: Intro to AR Development";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:66:"http://www.kurzweilai.net/weekend-workshop-intro-to-ar-development";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:75:"http://www.kurzweilai.net/weekend-workshop-intro-to-ar-development#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Wed, 07 Jun 2017 07:17:51 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:1:{i:0;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=302058";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:328:"The word is out: Augmented Reality is the future. With Apple’s recent release of the ARKit, Google’s growth of Google Tango, and AR content rising in popularity, now is the perfect time to get involved! Companies know they should utilize AR technology, but are not sure how. This is the opportunity for you- the future [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:66:"http://www.kurzweilai.net/images/learn-to-build-ar-apps-140x70.jpg";s:5:"width";s:3:"140";s:6:"height";s:2:"70";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:875:"<p><img style=' display: block; margin-right: auto; margin-left: auto;'  class="aligncenter size-full wp-image-302059" title="learn-to-build-ar-apps" src="http://www.kurzweilai.net/images/learn-to-build-ar-apps.jpg" alt="" width="638" /></p>
<p>The word is out: Augmented Reality is the future. With Apple’s recent release of the ARKit, Google’s growth of Google Tango, and AR content rising in popularity, now is the perfect time to get involved! Companies know they should utilize AR technology, but are not sure how. This is the opportunity for you- the future thinker and avid learner- to dive in, carve out your path, and show them the way.</p>
<p>You will leave with a new knowledge of the the augmented world, the ability to build an AR application, a new network of passionate people and a great start to your AR future!</p>
<p><em>&#8212;Event Producer</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:71:"http://www.kurzweilai.net/weekend-workshop-intro-to-ar-development/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:22;a:6:{s:4:"data";s:56:"
		
		
		
		
		
								
		
				
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:81:"33 blood-cancer patients have dramatic clinical remission with new T-cell therapy";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:107:"http://www.kurzweilai.net/33-blood-cancer-patients-have-dramatic-clinical-remission-with-new-t-cell-therapy";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:116:"http://www.kurzweilai.net/33-blood-cancer-patients-have-dramatic-clinical-remission-with-new-t-cell-therapy#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Wed, 07 Jun 2017 06:42:04 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:2:{i:0;a:5:{s:4:"data";s:7:"Biotech";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=302048";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:420:"Chinese doctors have reported success with a new type of immunotherapy for multiple myeloma*, a blood cancer: 33 out of 35 patients in a clinical trial had clinical remission within two months. The researchers used a type of T cell called “chimeric antigen receptor (CAR) T.”** In a phase I clinical trial in China, the patient’s own T cells were collected, genetically reprogrammed in a lab, and [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:74:"http://www.kurzweilai.net/images/t-cells-surround-cancer-cells-140x107.png";s:5:"width";s:3:"140";s:6:"height";s:3:"107";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:8349:"<div id="attachment_302067" class="wp-caption aligncenter" style="width: 455px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class="size-full wp-image-302067" title="t-cells surround cancer cells" src="http://www.kurzweilai.net/images/t-cells-surround-cancer-cells.png" alt="" width="445" height="341" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Image of a group of killer T cells (green and red) surrounding a cancer cell (blue, center)  (credit: NIH)</p></div>
<p>Chinese doctors have reported success with a new type of immunotherapy for multiple myeloma*, a blood cancer: 33 out of 35 patients in a clinical trial had clinical remission within two months.</p>
<p>The researchers used a type of <a href="https://en.wikipedia.org/wiki/T_cell" target="_blank">T cell</a> called “chimeric antigen receptor (CAR) T.”** In a phase I clinical trial in China, the patient’s own T cells were collected, genetically reprogrammed in a lab, and injected back into the patient. The reprogramming involved inserting an artificially designed gene into the T-cell genome, which helped the genetically reprogrammed cells find and destroy cancer cells throughout the body.</p>
<p>The study was presented Monday (June 5, 2017) at the <a href="http://www.asco.org/AMMRC" target="_blank">American Society of Clinical Oncology</a> (ASCO) conference in Chicago.</p>
<p>“Although recent advances in chemotherapy have prolonged life expectancy in multiple myeloma, this cancer remains incurable,” said study author Wanhong Zhao, MD, PhD, an associate director of hematology at The Second Affiliated Hospital of Xi’an Jiaotong University in Xi’an, China. “It appears that with this novel immunotherapy there may be a chance for cure in multiple myeloma, but we will need to follow patients much longer to confirm that.”***</p>
<p><strong>U.S. clinical trial planned</strong></p>
<p>“While it’s still early, these data are a strong sign that CAR T-cell therapy can send multiple myeloma into remission,” said ASCO expert Michael S. Sabel, MD, FACS. “It’s rare to see such high response rates, especially for a hard-to-treat cancer. This serves as proof that immunotherapy and precision medicine research pays off. We hope that future research builds on this success in multiple myeloma and other cancers.”</p>
<p>The researchers plan to enroll a total of 100 patients in this continuing clinical trial at four participating hospitals in China. “In early 2018 we also plan to launch a similar clinical trial in the United States. Looking ahead, we would also like to explore whether BCMA CAR T-cell therapy benefits patients who are newly diagnosed with multiple myeloma,” said Zhao.</p>
<p><em>This study was funded by Legend Biotech Co.</em></p>
<p><em>* Multiple myeloma is a cancer of plasma cells, which make antibodies to fight infections. Abnormal plasma cells can crowd out or suppress the growth of other cells in the bone marrow. This suppression may result in anemia, excessive bleeding, and a decreased ability to fight infection. Multiple myeloma is a relatively uncommon cancer. This year, an estimated 30,300 people</em><em></em><em> [Ref. 2] in the United States will be diagnosed with multiple myeloma, and 114,250 [Ref. 3] were diagnosed with this cancer worldwide in 2012. In the United States, only about half of patients survive five years after being diagnosed with multiple myeloma. &#8212; </em><em>American Society of Clinical Oncology</em><em></em></p>
<p><em>** Over the past few years, CAR T-cell therapy targeting a B-cell biomarker called CD19 proved very effective in initial trials for acute lymphoblastic leukemia (ALL) and some types of lymphoma, but until now, there has been little success with CAR T-cell therapies targeting other biomarkers in other types of cancer. This is one of the first clinical trials of CAR T cells targeting BCMA, which was discovered to play a role in progression of multiple myeloma in 2004. &#8212;</em> <em>American Society of Clinical Oncology</em></p>
<p><em>*** To date, 19 patients have been followed for more than four months, a pre-set time for full efficacy assessment by the International Myeloma Working Group (IMWG) consensus. Of the 19 patients, 14 have reached stringent complete response (sCR) criteria, one patient has reached partial response, and four patients have achieved very good partial remission (VgPR) criteria in efficacy.  There has been only a single case of disease progression from VgPR; an extramedullary lesion of the VgPR patient reappeared three months after disappearing on CT scans. There has not been a single case of relapse among patients who reached sCR criteria. The five patients who have been followed for over a year (12&#8211;14 months) all remain in sCR status and are free of minimal residual disease as well (have no detectable cancer cells in the bone marrow). Cytokine release syndrome or CRS, a common and potentially dangerous side effect of CAR T-cell therapy, occurred in 85% of patients, but it was only transient. In the majority of patients symptoms were mild and manageable. CRS is associated with symptoms such as fever, low blood pressure, difficulty breathing, and problems with multiple organs. Only two patients on this study experienced severe CRS (grade 3) but recovered upon receiving tocilizumab (Actemra, an inflammation-reducing treatment commonly used to manage CRS in clinical trials of CAR T-cell therapy). No patients experienced neurologic side effects, another common and serious complication from CAR T-cell therapy. </em><em>&#8212;</em> <em>American Society of Clinical Oncology</em></p>
<hr />
<h4>Abstract of <em>Durable remissions with BCMA-specific chimeric antigen receptor (CAR)-modified T cells in patients with refractory/relapsed multiple myeloma.</em></h4>
<p><strong>Background:</strong> Chimeric antigen receptor engineered T cell (CAR-T) is a novel immunotherapeutic approach for cancer treatment and has been clinically validated in the treatment of acute lymphoblastic leukemia (ALL). Here we report an encouraging breakthrough of treating multiple myeloma (MM) using a CAR-T designated LCAR-B38M CAR-T, which targets principally BCMA. <strong>Methods:</strong> A single arm clinical trial was conducted to assess safety and efficacy of this approach. A total of 19 patients with refractory/relapsed multiple myeloma were included in the trial. The median number of infused cells was 4.7 (0.6 ~ 7.0) × 10e6/ kg. The median follow-up times was 208 (62 ~ 321) days. <strong>Results:</strong> Among the 19 patients who completed the infusion, 7 patients were monitored for a period of more than 6 months. Six out of the 7 achieved complete remission (CR) and minimal residual disease (MRD)-negative status. The 12 patients who were followed up for less than 6 months met near CR criteria of modified EBMT criteria for various degrees of positive immunofixation. All these effects were observed with a progressive decrease of M-protein and thus expected to eventually meet CR criteria. In the most recent follow-up examination, all 18 survived patients were determined to be free of myeloma-related biochemical and hematologic abnormalities. One of the most common adverse event of CAR-T therapy is acute cytokine release syndrome (CRS). This was observed in 14 (74%) patients who received treatment. Among these 14 patients there were 9 cases of grade 1, 2 cases of grade 2, 1 case of grade 3, and 1 case of grade 4 patient who recovered after treatments. <strong>Conclusions:</strong> A 100% objective response rate (ORR) to LCAR-B38M CAR-T cells was observed in refractory/relapsed myeloma patients. 18 out of 19 (95%) patients reached CR or near CR status without a single event of relapse in a median follow-up of 6 months. The majority (14) of the patients experienced mild or manageable CRS, and the rest (5) were even free of diagnosable CRS. Based on the encouraging safety and efficacy outcomes, we believe that our LCAR-B38M CAR-T cell therapy is an innovative and highly effective treatment for multiple myeloma.</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:112:"http://www.kurzweilai.net/33-blood-cancer-patients-have-dramatic-clinical-remission-with-new-t-cell-therapy/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"6";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:23;a:6:{s:4:"data";s:59:"
		
		
		
		
		
								
		
				
		
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:38:"How to design and build your own robot";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:64:"http://www.kurzweilai.net/how-to-design-and-build-your-own-robot";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:73:"http://www.kurzweilai.net/how-to-design-and-build-your-own-robot#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Tue, 06 Jun 2017 00:52:24 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:3:{i:0;a:5:{s:4:"data";s:11:"AI/Robotics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:11:"Electronics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=301799";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:402:"Carnegie Mellon University (CMU) Robotics Institute researchers have developed a simplified interactive design tool that lets you design and make your own customized legged or wheeled robot, using a mix of 3D-printed parts and off-the-shelf components. The current process of creating new robotic systems is challenging, time-consuming, and resource-intensive. So the CMU researchers have created [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:57:"http://www.kurzweilai.net/images/DIY-robot-ft-140x106.png";s:5:"width";s:3:"140";s:6:"height";s:3:"106";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:7197:"<div id="attachment_301961" class="wp-caption aligncenter" style="width: 549px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-301961" title="DIY robots" src="http://www.kurzweilai.net/images/DIY-robots.png" alt="" width="539" height="211" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Two robots &#8212; robot calligrapher and puppy &#8212; produced using an interactive display tool and selecting off-the-shelf components and 3D-printed parts (credit: Carnegie Mellon University)</p></div>
<p><a href="http://ri.cmu.edu/" target="_blank">Carnegie Mellon University (CMU) Robotics Institute</a> researchers have developed a simplified interactive design tool that lets you design and make your own customized legged or wheeled robot, using a mix of 3D-printed parts and off-the-shelf components.</p>
<p>The current process of creating new robotic systems is challenging, time-consuming, and resource-intensive. So the CMU researchers have created a visual design tool with a simple drag-and-drop interface that lets you choose from a library of standard building blocks (such as actuators and mounting brackets that are either off-the-shelf/mass-produced or can be 3D-printed) that you can combine to create complex functioning robotic systems.</p>
<div id="attachment_301982" class="wp-caption aligncenter" style="width: 638px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class="size-full wp-image-301982" title="robot visual design interface" src="http://www.kurzweilai.net/images/robot-visual-design-interface.png" alt="" width="628" height="262" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">(a) The design interface consists of two workspaces. The left workspace allows for designing the robot. It displays a list of various modules at the top. The leftmost menu provides various functions that allow users to define preferences for the search process visualization and for physical simulation. The right workspace (showing the robot design on a plane) runs a physics simulation of the robot for testing. (b) When you select a new module from the modules list, the system automatically makes visual suggestions (shown in red) about possible connections for this module that are relevant to the current design. (credit: Carnegie Mellon University)</p></div>
<p>An iterative design process lets you experiment by changing the number and location of actuators and adjusting the physical dimensions of your robot. An auto-completion feature can automatically generate assemblies of components by searching through possible component arrangements. It even suggests components that are compatible with each other, points out where actuators should go, and automatically generates 3D-printable structural components to connect those actuators.</p>
<div id="attachment_301967" class="wp-caption aligncenter" style="width: 649px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-301967" title="automatic robot design process" src="http://www.kurzweilai.net/images/automatic-robot-design-process.png" alt="" width="639" height="125" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Automated design process. (a) Start with a guiding mesh for the robot you want to make and select the orientations of its motors, using the drag and drop interface. (b) The system then searches for possible designs that connect a given pair of motors in user-defined locations, according to user-defined preferences. You can reject the solution and re-do the search with different preferences anytime. A proposed search solution connecting the root motor to the target motor (highlighted in dark red) is shown in light blue. Repeat this process for each pair of motors. (c) Since the legs are symmetric in this case, you would only need to use the search process for two legs. The interface lets you create the other pair of legs by simple editing operations. Finally, attach end-effectors of your choice and create a body plate to complete your awesome robot design. (d) shows the final design (with and without the guiding mesh). The dinosaur head mesh was manually added after this particular design, for aesthetic appeal. (credit: Carnegie Mellon University)</p></div>
<p>The research team, headed by <a href="http://www.cs.cmu.edu/~scoros/" target="_blank">Stelian Coros</a>, CMU Robotics Institute assistant professor of robotics, designed a number of robots with the tool and verified its feasibility by fabricating two test robots (shown above) &#8212; a wheeled robot with a manipulator arm that can hold a pen for drawing, and a four-legged &#8220;puppy&#8221; robot that can walk forward or sideways. &#8220;Our work aims to make robotics more accessible to casual users,&#8221; says Coros.</p>
<p>Robotics Ph.D. student <a href="http://www.cs.cmu.edu/~rutad/" target="_blank">Ruta Desai</a> presented a report on the design tool at the <a href="http://www.icra2017.org/" target="_blank">IEEE International Conference on Robotics and Automation</a> (ICRA 2017) May 29&#8211;June 3 in Singapore. No date for the availability of this tool has been announced.</p>
<p><em>This work was supported by the National Science Foundation.</em></p>
<p><iframe frameborder="0" height="315" src="https://www.youtube.com/embed/PGpTsQtznw4" width="560"></iframe><br />
<em><a href="https://www.youtube.com/channel/UC_em3WopBdoZOuF9JehDong" data-sessionlink="itct=CDYQ4TkiEwj5mvDY3qXUAhXH2pwKHWL5Dbko-B0" data-ytid="UC_em3WopBdoZOuF9JehDong">Ruta Desai</a> | Computational Abstractions for Interactive Design of Robotic Devices (ICRA 2017)</em></p>
<hr />
<h4>Abstract of <em>Computational Abstractions for Interactive Design of Robotic Devices</em></h4>
<p>We present a computational design system that allows novices and experts alike to easily create custom robotic devices using modular electromechanical components. The core of our work consists of a design abstraction that models the way in which these components can be combined to form complex robotic systems. We use this abstraction to develop a visual design environment that enables an intuitive exploration of the space of robots that can be created using a given set of actuators, mounting brackets and 3d-printable components. Our computational system also provides support for design auto-completion operations, which further simplifies the task of creating robotic devices. Once robot designs are finished, they can be tested in physical simulations and iteratively improved until they meet the individual needs of their users. We demonstrate the versatility of our computational design system by creating an assortment of legged and wheeled robotic devices. To test the physical feasibility of our designs, we fabricate a wheeled device equipped with a 5-DOF arm and a quadrupedal robot.</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:69:"http://www.kurzweilai.net/how-to-design-and-build-your-own-robot/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"1";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:24;a:6:{s:4:"data";s:56:"
		
		
		
		
		
								
		
				
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:62:"Are you ready for pop-up, shape-shifting food? Just add water.";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:85:"http://www.kurzweilai.net/are-you-ready-for-pop-up-shape-shifting-food-just-add-water";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:94:"http://www.kurzweilai.net/are-you-ready-for-pop-up-shape-shifting-food-just-add-water#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Sat, 03 Jun 2017 22:14:25 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:2:{i:0;a:5:{s:4:"data";s:27:"Innovation/Entrepreneurship";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=301762";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:359:"Researchers at MIT’s Tangible Media Group are exploring ways to make your dining experience interactive and fun, with food that can transform its shape by just adding water. Think of it as edible origami or culinary performance art &#8212; flat sheets of gelatin and starch that instantly sprout into three-dimensional structures, such as macaroni and [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:63:"http://www.kurzweilai.net/images/Shape-Changing-Food-140x93.jpg";s:5:"width";s:3:"140";s:6:"height";s:2:"93";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:7093:"<div id="attachment_301763" class="wp-caption aligncenter" style="width: 501px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><a href="http://www.kurzweilai.net/images/Shape-Changing-Food.jpg"><img class=" wp-image-301763" title="Shape-Changing Food" src="http://www.kurzweilai.net/images/Shape-Changing-Food.jpg" alt="" width="491" height="324" /></a><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Fun with food: These pasta shapes were generated by immersing a 2D flat gelatin film into water. (credit: Michael Indresano Photography)</p></div>
<p>Researchers at <a href="https://tangible.media.mit.edu/" target="_blank">MIT’s Tangible Media Group</a> are exploring ways to make your dining experience interactive and fun, with food that can transform its shape by just adding water.</p>
<p>Think of it as edible origami or culinary performance art &#8212; flat sheets of gelatin and starch that instantly sprout into three-dimensional structures, such as macaroni and rotini, or the shape of a flower.</p>
<p>But the researchers suggest it&#8217;s also a practical way to reduce food-shipping costs. Edible films could be stacked together, IKEA-style, and shipped to consumers, then morph into their final shape later when immersed in water.</p>
<p>“We did some simple calculations, such as for macaroni pasta, and even if you pack it perfectly, you still will end up with 67 percent of the volume as air,” says <a href="http://tangible.media.mit.edu/person/wen-wang/" target="_blank">Wen Wang</a>, a co-author on the paper and a former graduate student and research scientist in MIT’s Media Lab. “We thought maybe in the future our shape-changing food could be packed flat and save space.”</p>
<p><strong>Programmable pasta, anyone?<br />
</strong></p>
<p>At MIT, Wang and associates had been investigating the response of various materials to moisture. They started playing around with gelatin (as in Jello), a substance that naturally expands when it absorbs water. Gelatin can expand to varying degrees depending on its density &#8212; a characteristic that the team exploited in creating their shape-transforming structures.</p>
<p>They created a flat, two-layer film made from gelatin of two different densities. In theory, the top layer was more densely packed, so it should be able to absorb more water than the bottom layer. Sure enough, when they immersed the entire structure in water, the top layer curled over the bottom layer, forming a slowly rising arch &#8212; creative pasta.*</p>
<div id="attachment_301816" class="wp-caption aligncenter" style="width: 502px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-301816" title="culinary performance art" src="http://www.kurzweilai.net/images/culinary-performance-art.png" alt="" width="492" height="183" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Culinary performance art by MIT  researchers. (left) Phytoplankton pasta salad with heirloom tomatoes and wild Sorrel. (right) Flowering pasta with west-coast foraged mushrooms<br />and fermented burgundy truffle. (credit: Michael Indresano Photography)</p></div>
<p>To see how their designs might be implemented in a professional kitchen, the researchers showed their engineered edibles to Matthew Delisle, the head chef of high-end Boston restaurant L’Espalier. They jointly designed two culinary creations: transparent discs of gelatin flavored with plankton and squid ink, that instantly wrap around small beads of caviar; and long fettuccini-like strips, made from two gelatins that melt at different temperatures, causing the noodles to spontaneously divide when hot broth melts away certain sections. “They had great texture and tasted pretty good,” Yao says.</p>
<p><strong>DIY food </strong></p>
<p>The researchers used a laboratory 3-D printer to pattern cellulose onto films of gelatin. But they suggest users can reproduce similar effects with more common techniques such as &#8220;screen printing&#8221; in an <a href="http://dl.acm.org/citation.cfm?id=3026019" target="_blank">open-access paper</a> presented at the <a href="https://chi2017.acm.org/" target="_blank">Association for Computing Machinery’s 2017 Computer-Human Interaction Conference on Human Factors in Computing Systems (CHI 2017)</a>.</p>
<p>They envision that their &#8220;online software can provide design instructions, and a startup company can ship the materials to your home,” Yao says.</p>
<p><em>This research was funded, in part, by the MIT Media Lab and <a href="https://foodfuture.com/" target="_blank">Food + Future</a>, a startup accelerator sponsored by Target Corporation, IDEO, and Intel.</em></p>
<p><em>* The team recorded the cellulose patterns and the dimensions of all of the structures they were able to produce, and also tested mechanical properties such as toughness, organizing all this data into a database. Co-authors Zhang and Cheng then built computational models of the material’s transformations, which they used to design an online interface for users to design their own edible, shape-transforming structures.“We did many lab tests and collected a database, within which you can pick different shapes, with fabrication instructions,” Wang says. “Reversibly, you can also select a basic pattern from the database and adjust the distribution or thickness, and can see how the final transformation will look.”</em></p>
<p><iframe frameborder="0" height="359" src="https://player.vimeo.com/video/199408741?color=a4bbd8&amp;portrait=0" width="638"></iframe><br />
<em>Tangible Media Group | Transformative Appetite</em></p>
<hr />
<h4>Abstract of <em>Transformative Appetite: Shape-Changing Food Transforms from 2D to 3D by Water Interaction through Cooking</em></h4>
<p>We developed a concept of transformative appetite, where edible 2D films made of common food materials (protein, cellulose or starch) can transform into 3D food during cooking. This transformation process is triggered by water adsorption, and it is strongly compatible with the &#8216;flat packaging&#8217; concept for substantially reducing shipping costs and storage space. To develop these transformable foods, we performed material-based design, established a hybrid fabrication strategy, and conducted performance simulation. Users can customize food shape transformations through a pre-defined simulation platform, and then fabricate these designed patterns using additive manufacturing. Three application techniques are provided &#8211; 2D-to-3D folding, hydration-induced wrapping, and temperature-induced self-fragmentation, to present the shape, texture, and interaction with food materials. Based on this concept, several dishes were created in the kitchen, to demonstrate the futuristic dining experience through materials-based interaction design.</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:90:"http://www.kurzweilai.net/are-you-ready-for-pop-up-shape-shifting-food-just-add-water/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"3";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:25;a:6:{s:4:"data";s:56:"
		
		
		
		
		
								
		
				
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:65:"VR glove powered by soft robotics provides missing sense of touch";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:91:"http://www.kurzweilai.net/vr-glove-powered-by-soft-robotics-provides-missing-sense-of-touch";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:100:"http://www.kurzweilai.net/vr-glove-powered-by-soft-robotics-provides-missing-sense-of-touch#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Sat, 03 Jun 2017 01:20:39 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:2:{i:0;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:38:"VR/Augmented Reality/Computer Graphics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=301796";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:368:"Engineers at UC San Diego have designed a light, flexible glove with soft robotic muscles that provide realistic tactile feedback for virtual reality (VR) experiences. Currently, VR tactile-feedback user interfaces are bulky, uncomfortable to wear and clumsy, and they simply vibrate when a user touches a virtual surface or object. “This is a first prototype, [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:56:"http://www.kurzweilai.net/images/haptic-glove-140x70.png";s:5:"width";s:3:"140";s:6:"height";s:2:"70";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:5906:"<div id="attachment_301898" class="wp-caption aligncenter" style="width: 566px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-301898" title="haptic glove" src="http://www.kurzweilai.net/images/haptic-glove.png" alt="" width="556" height="280" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Prototype of haptic VR glove, using soft robotic “muscles” to provide realistic tactile feedback for VR experiences (credit: Jacobs School of Engineering/UC San Diego)</p></div>
<p>Engineers at <a href="http://ucsd.edu/" target="_blank">UC San Diego</a> have designed a light, flexible glove with soft robotic muscles that provide realistic tactile feedback for virtual reality (VR) experiences.</p>
<p>Currently, VR tactile-feedback user interfaces are bulky, uncomfortable to wear and clumsy, and they simply vibrate when a user touches a virtual surface or object.</p>
<p>“This is a first prototype, but it is surprisingly effective,” said Michael Tolley, a mechanical engineering professor at the Jacobs School of Engineering at UC San Diego and a senior author of a paper presented at the Electronic Imaging, Engineering Reality for Virtual Reality conference in Burlingame, California and published May 31, 2017 in <em>Advanced Engineering Materials</em>.</p>
<p style="text-align: left;">The key soft-robotic component of the new glove is a version of the &#8220;<a href="http://www.iaeng.org/publication/IMECS2009/IMECS2009_pp1726-1730.pdf" target="_blank">McKibben muscle</a>&#8221; (a pneumatic, or air-based, actuator invented in 1950s by the physician Joseph L. McKibben for use in prosthetic limbs), using soft latex chambers covered with braided fibers. To apply tactile feedback when the user moves their fingers, the muscles respond like springs. The board controls the muscles by inflating and deflating them.*</p>
<div id="attachment_301902" class="wp-caption aligncenter" style="width: 564px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-301902" title="haptic VR glove system" src="http://www.kurzweilai.net/images/haptic-VR-glove-system1.png" alt="" width="554" height="270" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Prototype haptic VR glove system. A computer generates an image of a virtual world (in this case, a piano keyboard with a river and trees in the background) that it sends to the VR device (such as an Oculus Rift). A Leap Motion depth-camera (on the table) detects the position and movement of the user’s hands and sends data to a computer. It sends an image of the user&#8217;s hands superimposed over the keyboard (in the demo case) to the VR display and to a custom fluidic control board. The board then feeds back a signal to soft robotic components in the glove to individually inflate or deflate fingers, mimicking the user&#8217;s applied forces.</p></div>
<p>The engineers conducted an informal pilot study of 15 users, including two VR interface experts. The demo allowed them to play the piano in VR. They all agreed that the gloves increased the immersive experience, which they described as “mesmerizing” and “amazing.”</p>
<div id="attachment_301908" class="wp-caption aligncenter" style="width: 333px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-301908" title="VR piano" src="http://www.kurzweilai.net/images/VR-piano.png" alt="" width="323" height="180" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">VR headset image of a piano, showing user&#8217;s finger actions (credit: Jacobs School of Engineering/UC San Diego)</p></div>
<p>The engineers say they&#8217;re working on making the glove cheaper, less bulky, and more portable. They would also like to bypass the Leap Motion device altogether to make the system more self-contained and compact. “Our final goal is to create a device that provides a richer experience in VR,” Tolley said. “But you could imagine it being used for surgery and video games, among other applications.”</p>
<p><em>* The researchers 3D-printed a mold to make the gloves’ soft exoskeleton. This will make the devices easier to manufacture and suitable for mass production, they said. Researchers used silicone rubber for the exoskeleton, with Velcro straps embedded at the joints.</em></p>
<p><iframe frameborder="0" height="315" src="https://www.youtube.com/embed/gCka1qsD4q8?rel=0" width="560"></iframe><br />
<em>JacobsSchoolNews | A glove powered by soft robotics to interact with virtual reality environments</em></p>
<hr />
<h4>Abstract of <em>Soft Robotics: Review of Fluid-Driven Intrinsically Soft Devices; Manufacturing, Sensing, Control, and Applications in Human-Robot Interaction</em></h4>
<p>The emerging field of soft robotics makes use of many classes of materials including metals, low glass transition temperature (Tg) plastics, and high Tg elastomers. Dependent on the specific design, all of these materials may result in extrinsically soft robots. Organic elastomers, however, have elastic moduli ranging from tens of megapascals down to kilopascals; robots composed of such materials are intrinsically soft − they are always compliant independent of their shape. This class of soft machines has been used to reduce control complexity and manufacturing cost of robots, while enabling sophisticated and novel functionalities often in direct contact with humans. This review focuses on a particular type of intrinsically soft, elastomeric robot − those powered via fluidic pressurization.</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:96:"http://www.kurzweilai.net/vr-glove-powered-by-soft-robotics-provides-missing-sense-of-touch/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"4";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:26;a:6:{s:4:"data";s:56:"
		
		
		
		
		
								
		
				
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:61:"Common antioxidant could slow symptoms of aging in human skin";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:87:"http://www.kurzweilai.net/common-antioxidant-could-slow-symptoms-of-aging-in-human-skin";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:96:"http://www.kurzweilai.net/common-antioxidant-could-slow-symptoms-of-aging-in-human-skin#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Wed, 31 May 2017 05:55:27 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:2:{i:0;a:5:{s:4:"data";s:16:"Biomed/Longevity";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=301786";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:366:"University of Maryland (UMD) researchers have found evidence that a common, inexpensive, and safe antioxidant chemical called methylene blue could slow the aging of human skin, based on tests in cultured human skin cells and simulated skin tissue. “The effects we are seeing are not temporary. Methylene blue appears to make fundamental, long-term changes to [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:94:"http://www.kurzweilai.net/images/Methylene-Blue-Thickens-Dermis-Layer-in-Model-Skin-140x60.jpg";s:5:"width";s:3:"140";s:6:"height";s:2:"60";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:7084:"<div id="attachment_301787" class="wp-caption aligncenter" style="width: 543px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><a href="http://www.kurzweilai.net/images/Methylene-Blue-Thickens-Dermis-Layer-in-Model-Skin.jpg"><img class=" wp-image-301787 noshadow" title="Methylene Blue Thickens Dermis Layer in Model Skin" src="http://www.kurzweilai.net/images/Methylene-Blue-Thickens-Dermis-Layer-in-Model-Skin.jpg" alt="" width="533" height="230" /></a><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">These cross-section images show three-dimensional human skin models made of living skin cells. Untreated model skin (left panel) shows a thinner dermis layer (black arrow) compared with model skin treated with the antioxidant methylene blue (right panel). A new study suggests that methylene blue could slow or reverse dermal thinning (a sign of aging) and a number of other symptoms of aging in human skin. (credit: Zheng-Mei Xiong/University of Maryland)</p></div>
<p>University of Maryland (UMD) researchers have found evidence that a common, inexpensive, and safe antioxidant chemical called methylene blue could slow the aging of human skin, based on tests in cultured human skin cells and simulated skin tissue.</p>
<p>“The effects we are seeing are not temporary. Methylene blue appears to make fundamental, long-term changes to skin cells,” said <a href="http://cbmg.umd.edu/faculty/kancao/" target="_blank">Kan Cao</a>, senior author on the study and an associate professor of <a href="http://cbmg.umd.edu/" target="_blank">cell biology and molecular genetics</a> at UMD.</p>
<p>The researchers tested methylene blue for four weeks in skin cells from healthy middle-aged donors, as well as those diagnosed with progeria &#8212; a rare genetic disease that mimics the normal aging process at an accelerated rate. The researchers also tested three other known antioxidants: N-Acetyl-L-Cysteine (NAC), MitoQ and MitoTEMPO (mTEM).</p>
<p>In these experiments, methylene blue outperformed the other three antioxidants, improving several age-related symptoms in cells from both healthy donors and progeria patients. The skin cells (fibroblasts, the cells that produce the structural protein collagen) experienced a decrease in damaging molecules known as reactive oxygen species (ROS), a reduced rate of cell death, and an increase in the rate of cell division throughout the four-week treatment.</p>
<p><strong>Improvements in skin cells from older donors (&gt;80 years old)<br />
</strong></p>
<p>Next, Cao and her colleagues tested methylene blue in fibroblasts from older donors (&gt;80 years old), again for a period of four weeks. At the end of the treatment, the cells from older donors had experienced a range of improvements, including decreased expression of two genes commonly used as indicators of cellular aging: senescence-associated beta-galactosidase and p16.</p>
<div id="attachment_301841" class="wp-caption aligncenter" style="width: 326px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-301841" title="simulated human skin structure" src="http://www.kurzweilai.net/images/simulated-human-skin-structure.png" alt="" width="316" height="192" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Schematic illustrations of top (left panel) and side (right panel) views of the engineered 3D skin tissue cultured on a microporous membrane insert, used for experiments and skin-irritation tests (credit: Zheng-Mei Xiong et al./Scientific Reports)</p></div>
<p>The researchers then used simulated human skin to perform several more experiments. This simulated skin &#8212; a three-dimensional model made of living skin cells &#8212; includes all the major layers and structures of skin tissue, with the exception of hair follicles and sweat glands. The model skin could also be used in skin irritation tests required by the Food and Drug Administration for the approval of new cosmetic products, Cao said.</p>
<p>“This system allowed us to test a range of aging symptoms that we can’t replicate in cultured cells alone,” Cao said. “Most surprisingly, we saw that model skin treated with methylene blue retained more water and increased in thickness—both of which are features typical of younger skin.”</p>
<p><strong>Formulating cosmetics</strong></p>
<p>The researchers also used the model skin to test the safety of cosmetic creams with methylene blue added. The results suggest that methylene blue causes little to no irritation, even at high concentrations. Encouraged by these results, Cao and colleagues hope to develop safe and effective ways for consumers to benefit from the properties of methylene blue.</p>
<p>“We have already begun formulating cosmetics that contain methylene blue. Now we are looking to translate this into marketable products,” Cao said. “Perhaps down the road we can customize the system with bioprinting, such that we might be able to use a patient’s own cells to provide a tailor-made testing platform specific to their needs.”</p>
<p>The <a href="https://www.nature.com/articles/s41598-017-02419-3" target="_blank">study</a> was published online in the Nature journal <a href="https://www.nature.com/srep/"><em>Scientific Reports</em></a> on May 30, 2017.</p>
<p><em>This research was supported by the Maryland Innovation Initiative.</em></p>
<hr />
<h4>Abstract of <em>Anti-Aging Potentials of Methylene Blue for Human Skin Longevity</em></h4>
<p>Oxidative stress is the major cause of skin aging that includes wrinkles, pigmentation, and weakened wound healing ability. Application of antioxidants in skin care is well accepted as an effective approach to delay the skin aging process. Methylene blue (MB), a traditional mitochondrial-targeting antioxidant, showed a potent ROS scavenging efficacy in cultured human skin fibroblasts derived from healthy donors and from patients with progeria, a genetic premature aging disease. In comparison with other widely used general and mitochondrial-targeting antioxidants, we found that MB was more effective in stimulating skin fibroblast proliferation and delaying cellular senescence. The skin irritation test, performed on an <em>in vitro</em> reconstructed 3D human skin model, indicated that MB was safe for long-term use, and did not cause irritation even at high concentrations. Application of MB to this 3D skin model further demonstrated that MB improved skin viability, promoted wound healing and increased skin hydration and dermis thickness. Gene expression analysis showed that MB treatment altered the expression of a subset of extracellular matrix proteins in the skin, including upregulation of elastin and collagen 2A1, two essential components for healthy skin. Altogether, our study suggests that MB has a great potential for skin care.</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:92:"http://www.kurzweilai.net/common-antioxidant-could-slow-symptoms-of-aging-in-human-skin/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"4";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:27;a:6:{s:4:"data";s:56:"
		
		
		
		
		
								
		
				
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:83:"New antibiotic could eliminate the global threat of antibiotic-resistant infections";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:109:"http://www.kurzweilai.net/new-antibiotic-could-eliminate-the-global-threat-of-antibiotic-resistant-infections";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:118:"http://www.kurzweilai.net/new-antibiotic-could-eliminate-the-global-threat-of-antibiotic-resistant-infections#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Wed, 31 May 2017 05:19:19 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:2:{i:0;a:5:{s:4:"data";s:7:"Biotech";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=301755";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:385:"Scientists at The Scripps Research Institute (TSRI) have discovered a way to structurally modify the antibiotic called vancomycin to make an already-powerful version of the antibiotic even more potent &#8212; an advance that could eliminate the threat of antibiotic-resistant infections for years to come. &#8220;Doctors could use this modified form of vancomycin without fear of [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:61:"http://www.kurzweilai.net/images/vancomycin-analog-140x94.png";s:5:"width";s:3:"140";s:6:"height";s:2:"94";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:3819:"<div id="attachment_301830" class="wp-caption aligncenter" style="width: 375px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-301830" title="vancomycin analog" src="http://www.kurzweilai.net/images/vancomycin-analog.png" alt="" width="365" height="246" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Modified vancomycin antibiotic (credit: Akinori Okano et al./PNAS)</p></div>
<p>Scientists at <a href="http://www.scripps.edu" target="_blank">The Scripps Research Institute (TSRI)</a> have discovered a way to structurally modify the antibiotic called vancomycin to make an already-powerful version of the antibiotic even more potent &#8212; an advance that could eliminate the threat of antibiotic-resistant infections for years to come.</p>
<p>&#8220;Doctors could use this modified form of vancomycin without fear of resistance emerging,&#8221; said <a href="https://www.scripps.edu/research/faculty/boger" target="_blank">Dale Boger</a>, co-chair of TSRI&#8217;s Department of Chemistry, whose team announced the finding Monday (May 29, 2016) in the journal <em>Proceedings of the National Academy of Sciences</em>.</p>
<p>&#8220;The death of a hospitalized patient in Reno Nevada for whom no available antibiotics worked highlights what World Health Organization and other public-health experts have been <a href="http://www.kurzweilai.net/serious-worldwide-threat-to-public-health-noted-in-whos-first-global-report-on-antibiotic-resistance" target="_blank">warning</a>: antibiotic resistance is a serious threat and has gone global,&#8221; <em>KurzweilAI</em> <a href="The death of a hospitalized patient in Reno Nevada for whom no available antibiotics worked highlights what World Health Organization and other public-health experts have been warning: antibiotic resistance is a serious threat and has gone global." target="_blank">reported</a> in January 2017. The new finding promises to lead to a solution.</p>
<p><strong>First antibiotic to have three independent mechanisms of action</strong></p>
<p>Vancomycin  has been prescribed by doctors for 60 years, and bacteria are only now developing resistance to it, according to Boger, who called vancomycin &#8220;magical&#8221; for its proven strength against infections. Previous studies by Boger and his colleagues at TSRI had shown that it is possible to add two modifications to vancomycin to make it even more potent. &#8220;With these modifications, you need less of the drug to have the same effect,&#8221; Boger said.</p>
<p>The new study shows that scientists can now make a third modification that interferes with a bacterium&#8217;s cell wall in a new way, with promising results. Combined with the previous modifications, this alteration gives vancomycin a 1,000-fold increase in activity, meaning doctors would need to use less of the antibiotic to fight infection.</p>
<p>The discovery makes this version of vancomycin the first antibiotic to have three independent mechanisms of action. &#8220;This increases the durability of this antibiotic,&#8221; said Boger. &#8220;Organisms just can&#8217;t simultaneously work to find a way around three independent mechanisms of action. Even if they found a solution to one of those, the organisms would still be killed by the other two.&#8221;</p>
<p>Tested against Enterococci bacteria, the new version of vancomycin killed both vancomycin-resistant Enterococci and the original forms of Enterococci. The next step in this research is to design a way to synthesize the modified vancomycin using fewer steps in the lab; the current method takes 30 steps.</p>
<p><em>The study was supported by the National Institutes of Health.</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:114:"http://www.kurzweilai.net/new-antibiotic-could-eliminate-the-global-threat-of-antibiotic-resistant-infections/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"3";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:28;a:6:{s:4:"data";s:53:"
		
		
		
		
		
								
		
				

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:15:"Design Con 2018";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:40:"http://www.kurzweilai.net/designcon-2018";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:49:"http://www.kurzweilai.net/designcon-2018#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Mon, 29 May 2017 03:15:20 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:1:{i:0;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=301396";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:444:"DesignCon, the premier conference for chip, board, and systems design engineers, returns to Silicon Valley for its 22nd year. DesignCon serves the high speed communications and semiconductor communities offering state-of-the-art design methodologies, applications, technologies, and unparalleled networking opportunities. Taking place annually, DesignCon remains the largest gathering of chip, board, and systems designers in the country. [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:63:"http://www.kurzweilai.net/images/designcon-logo-2018-140x26.png";s:5:"width";s:3:"140";s:6:"height";s:2:"26";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:2586:"<p><img style=' display: block; margin-right: auto; margin-left: auto;'  class="aligncenter size-full wp-image-301397 noshadow" title="designcon-logo-2018" src="http://www.kurzweilai.net/images/designcon-logo-2018.png" alt="" width="512" height="97" /></p>
<p>DesignCon, the premier conference for chip, board, and systems design engineers, returns to Silicon Valley for its 22nd year. DesignCon serves the high speed communications and semiconductor communities offering state-of-the-art design methodologies, applications, technologies, and unparalleled networking opportunities.</p>
<p>Taking place annually, DesignCon remains the largest gathering of chip, board, and systems designers in the country. Combining technical paper sessions, tutorials, industry panels, product demos, and exhibits; DesignCon brings engineers the latest theories, methodologies, techniques, applications, and demonstrations on PCB design tools, power and signal integrity, jitter and crosstalk, high-speed serial design, test and measurement tools, parallel and memory interface design, ICs, semiconductor components, and more.</p>
<h4>Technical Conference Program</h4>
<p>With more than 100 sessions spanning 14 tracks, the Technical Conference Program covers all aspects of electronic design; from chips through boards and systems. Get practical solutions to your problems involving:</p>
<ul>
<li>Signal and Power Integrity</li>
<li>Mixed-Signal and High-Speed Serial Design</li>
<li>Test &amp; Measurement and Verification</li>
<li>and more</li>
</ul>
<h4>The Expo</h4>
<p>The DesignCon Expo Hall gives you access to 185 exhibitors offering the latest products and technologies in signal integrity and high-speed design for your current and future projects. On the Expo Floor you can:</p>
<ul>
<li>Discover and compare emerging tools and technologies</li>
<li>Get practical insights and solutions to your design issues</li>
<li>Take part in free education and training in the Chiphead Theater and Vendor Sessions</li>
</ul>
<p>Plus: Engineer of the Year Awards, prizes and giveaways, speed-trainings, product teardowns, happy hour parties, access to the keynotes and technical panels, and more!</p>
<h4>Exhibit at DesignCon</h4>
<p>Get access to 4,800 leading decision-makers in the electronics design community.</p>
<h4>Keynotes</h4>
<p>This year, DesignCon will host three keynotes from industry luminaries. The lineup is aimed to cover the full engineering lifecycle, from concept and creativity to testing, securing and tips for entrepreneurial success.</p>
<p><em>&#8212;Event Producer</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:45:"http://www.kurzweilai.net/designcon-2018/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:29;a:6:{s:4:"data";s:56:"
		
		
		
		
		
								
		
				
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:56:"Alpha Go defeats world’s top Go player. What’s next?";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:74:"http://www.kurzweilai.net/alpha-go-defeats-worlds-top-go-player-whats-next";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:83:"http://www.kurzweilai.net/alpha-go-defeats-worlds-top-go-player-whats-next#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Sun, 28 May 2017 23:33:35 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:2:{i:0;a:5:{s:4:"data";s:11:"AI/Robotics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=301699";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:341:"What does the research team behind AlphaGo do next after winning the three-game match Saturday (May 27) against Ke Jie &#8212; the world’s top Go player &#8212; at the Future of Go Summit in Wuzhen, China? &#8220;Throw their energy into the next set of grand challenges, developing advanced general algorithms that could one day help [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:79:"http://www.kurzweilai.net/images/Game-3-of-The-Ultimate-Go-Challenge-140x69.png";s:5:"width";s:3:"140";s:6:"height";s:2:"69";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:3415:"<p><img style=' display: block; margin-right: auto; margin-left: auto;'  class="aligncenter  wp-image-301710" title="Game 3 of The Ultimate Go Challenge" src="http://www.kurzweilai.net/images/Game-3-of-The-Ultimate-Go-Challenge.png" alt="" width="486" height="242" /></p>
<p>What does the research team behind AlphaGo do next after winning the three-game match Saturday (May 27) against Ke Jie &#8212; the world’s top Go player &#8212; at the <a href="https://deepmind.com/research/alphago/alphago-china/" target="_blank">Future of Go Summit</a> in Wuzhen, China?</p>
<p>&#8220;Throw their energy into the next set of grand challenges, developing advanced general algorithms that could one day help scientists as they tackle some of our most complex problems, such as finding new cures for diseases, dramatically reducing energy consumption, or inventing revolutionary new materials,&#8221; <a href="https://deepmind.com/blog/alphagos-next-move/" target="_blank">says</a> DeepMind Technologies CEO Demis Hassabis.</p>
<p><strong>Academic paper, Go teaching tool</strong></p>
<p>But it&#8217;s &#8220;not the end of our work with the Go community,&#8221; he adds. &#8220;We plan to publish one final academic paper later this year that will detail the extensive set of improvements we made to the algorithms’ efficiency and potential to be generalised across a broader set of problems.&#8221;</p>
<p><a href="https://twitter.com/demishassabis/status/868789280721616896" target="_blank"><img style=' display: block; margin-right: auto; margin-left: auto;'  class="aligncenter  wp-image-301712" title="Alpha Go self-play games" src="http://www.kurzweilai.net/images/Alpha-Go-self-play-games.png" alt="" width="493" height="63" /></a></p>
<p>Already in the works (with Jie&#8217;s collaboration): a teaching tool that &#8220;will show AlphaGo’s analysis of Go positions, providing an insight into how the program thinks, and hopefully giving all players and fans the opportunity to see the game through the lens of AlphaGo.&#8221;</p>
<div id="attachment_301716" class="wp-caption aligncenter" style="width: 495px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-301716" title="Ke Jie - final match" src="http://www.kurzweilai.net/images/Ke-Jie-final-match.png" alt="" width="485" height="225" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Ke Jie plays the final match (credit: DeepMind)</p></div>
<p>DeepMind is also &#8220;publishing a special set of 50 AlphaGo vs AlphaGo games, played at full-length time controls, which we believe contain many new and interesting ideas and strategies.&#8221;</p>
<p><iframe frameborder="0" height="315" src="https://www.youtube.com/embed/ru0E7N0-kFE" width="560"></iframe><br />
<em>Deep Mind | The Future of Go Summit, Match Three: Ke Jie &amp; AlphaGo</em></p>
<p><iframe frameborder="0" height="315" src="https://www.youtube.com/embed/f_r9smp4-0U" width="560"></iframe><br />
<em>Deep Mind | Exploring the mysteries of Go with AlphaGo and China&#8217;s top players</em></p>
<p><iframe frameborder="0" height="315" src="https://www.youtube.com/embed/uvtRWWzuybo" width="560"></iframe><br />
<em>DeepMind | Demis Hassabis on AlphaGo: its legacy and the &#8216;Future of Go Summit&#8217; in Wuzhen, China</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:79:"http://www.kurzweilai.net/alpha-go-defeats-worlds-top-go-player-whats-next/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:30;a:6:{s:4:"data";s:62:"
		
		
		
		
								
		
								
		
				

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:6:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:77:"letter from Ray | Supporting universal basic income as step in world progress";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:101:"http://www.kurzweilai.net/letter-from-ray-supporting-universal-basic-income-as-step-in-world-progress";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:110:"http://www.kurzweilai.net/letter-from-ray-supporting-universal-basic-income-as-step-in-world-progress#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Sun, 28 May 2017 05:00:48 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:1:{i:0;a:5:{s:4:"data";s:4:"Blog";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=301500";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:357:"column: letters from Ray date: May 27, 2017 topic: Adopting a universal basic income for all people can help society think creatively with new ideas, develop new industries &#8212; and free-up people to work on important future projects. This practical social support program can grow as science &#38; technology rapidly evolve, becoming part of world [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:32:"http://purl.org/dc/elements/1.1/";a:1:{s:7:"creator";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:87:"http://www.kurzweilai.net/images/letters-from-Ray-universal-basic-income-H5-140x140.png";s:5:"width";s:3:"140";s:6:"height";s:3:"140";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:11873:"<p><img style=' float: left; padding: 4px; margin: 0 7px 2px 0;'  class="alignleft  wp-image-301529 noshadow" title="letters from Ray - universal basic income - F1" src="http://www.kurzweilai.net/images/letters-from-Ray-universal-basic-income-F1.png" alt="" width="640" height="521" /></p>
<hr class="dotted" />
<p><img style=' float: left; padding: 4px; margin: 0 7px 2px 0;'  class="alignleft  wp-image-301530" title="letters from Ray - universal basic income - F2" src="http://www.kurzweilai.net/images/letters-from-Ray-universal-basic-income-F2.png" alt="" width="282" height="262" /></p>
<p><span style="color: #ff9900;">column<strong>:</strong></span> letters from Ray<br />
<span style="color: #ff9900;">date<strong>:</strong></span> May 27, 2017</p>
<p><span style="color: #ff9900;">topic<strong>:</strong></span> Adopting a universal basic income for all people can help society think creatively with new ideas, develop new industries &#8212; and free-up people to work on important future projects.</p>
<p>This practical social support program can grow as science &amp; technology rapidly evolve, becoming part of world abundance.</p>
<p><span style="color: #ff9900;">story by<strong>:</strong></span> Ray Kurzweil</p>
<hr />
<p>Dear readers,</p>
<p>As you might have seen in the news, entrepreneur and renowned Facebook founder &amp; CEO Mark Zuckerberg gave a commencement speech at Harvard University. He said in his talk:</p>
<p style="padding-left: 30px;"><strong>&#8220;</strong>To keep our society moving forward, we have a generational challenge &#8212; to create new jobs, a renewed sense of purpose, and to take on big meaningful projects.</p>
<p style="padding-left: 30px;">Our generation will have to deal with tens of millions of jobs replaced by automation like self-driving cars &amp; trucks. But we have the potential to do so much more together.</p>
<p style="padding-left: 30px;">More than 300,000 people worked to put a man on the moon &#8212; including that janitor. Millions of volunteers immunized children around the world against polio. Millions of people built the Hoover dam and other great projects.</p>
<p style="padding-left: 30px;">We should have a society that measures progress not just by economic metrics, but by how many of us have a role we find meaningful. We should explore ideas like universal basic income &#8212; to give everyone a cushion to try new things.</p>
<p style="padding-left: 30px;">We&#8217;re going to change jobs many times, so we need affordable child care &#8212; to get to work and health care that aren&#8217;t tied to one company. We&#8217;re all going to make mistakes, so we need a society that focuses less on locking us up or stigmatizing us. And as tech keeps changing, we need to focus more on continuous education throughout our lives.</p>
<p style="padding-left: 30px;">Giving everyone the freedom to pursue purpose isn&#8217;t free. People like me should pay for it. Many of you will do well and you should too. That&#8217;s why my wife Priscilla Chan and I started the Chan Zuckerberg Initiative and committed our wealth to promoting equal opportunity. These are the values of our generation.<strong>&#8220;</strong></p>
<p style="padding-left: 30px;">&#8212; <em>Mark Zuckerberg</em> |  <a href="http://www.cnbc.com/2017/05/26/full-text-of-mark-zuckerbergs-2017-harvard-commencement-speech.html" target="_blank">source</a></p>
<p>A universal basic income is a form of security for a society&#8217;s citizens in which all residents of a country regularly unconditionally receive a sum of money, either from a government or public institution, in addition to any income received from elsewhere.</p>
<p>I support something along these lines. We want to do it in a way that doesn&#8217;t destroy incentives to contribute to society. So the question is how we get there. We already have a muddle approximating UBI * in the form of food stamps, social security, Medicaid, Medicare, emergency rooms and other programs.</p>
<p>You can get most of your needs for basic sustenance from these programs today &#8212; with the important exception of housing. There are shelters but these are grim and dangerous.</p>
<p>We are clearly headed toward a situation where everyone can live very well, with the support that society will provide. The fantastic price-performance gains we&#8217;ve seen in information technology is coming to physical products, food, energy, and other material items as they all become information technologies &#8212; like 3D printing, vertical agriculture, and solar energy.</p>
<p>I plan to talk about these issues, and how they will affect &#8212; and ultimately improve our civilization &#8212; in my next book. I remain positive that people like Mark Zuckerberg are thinking creatively about the future. We will be able to enter an age of abundance, as technology &amp; science progress makes a better world for all of us.</p>
<p>&#8212; <em>Ray Kurzweil</em></p>
<p>* UBI is universal basic income</p>
<hr />
<p><span style="color: #ff9900;">notes</span> | <em>11 reasons to support basic income</em><br />
<span style="color: #ff9900;">source<strong>:</strong></span> <a href="http://www.basicincome.org.uk" target="_blank">Basic Income</a></p>
<p><strong>1.</strong>  <em>Basic Income will help us rethink how &amp; why we work.</em></p>
<p>A basic income can help you do other work and reconsider old choices. It will enable you to re-train, safe in the knowledge that you’ll have enough money to maintain a decent standard of living while you do. So it will help each of us decide what it is we truly want to do.</p>
<p><strong>2.</strong>  <em>Basic Income will contribute to better working conditions.</em></p>
<p>With the insurance of having unconditional basic income as a safety net, workers can challenge their employers if they find their conditions of work unfair or degrading.</p>
<p><strong>3.</strong>  <em>Basic Income will down-size bureaucracy.</em></p>
<p>Because a basic income scheme is one of the most simple tax / benefits models, it will reduce all the bureaucracy surrounding the welfare state thus making it less complex and costly, while being fairer and more emancipatory.</p>
<p><strong>4.</strong>  <em>Basic income will make benefit fraud obsolete.</em></p>
<p>Benefit fraud will vanish as a possibility because no one needs to commit fraud to get a basic income: it is granted automatically. Moreover, an unconditional basic income will fix threshold and poverty trap effects.</p>
<p><strong>5.</strong>  <em>Basic income will help reducing inequalities.</em></p>
<p>A basic income is a means for sharing the wealth produced by a society to all people, reducing growing inequalities across the world.</p>
<p><strong>6.</strong>  <em>It will provide a more secure and substantial safety net for all people.</em></p>
<p>Most existing tested anti-poverty programs exclude people because of their complexity, or because people don’t know how to apply or if they qualify. With a basic income, people currently excluded will automatically have their rights guaranteed.</p>
<p><strong>7.</strong>   <em>Basic Income will contribute to less working hours, better distribution of jobs.</em></p>
<p>With a basic income, people will have the option to reduce their working hours without sacrificing their income. So they&#8217;ll be able to spend more time doing other things they find meaningful. At the macro-economic level, this will induce a better distribution of jobs &#8212; because people reducing their hours will increase job opportunities for those currently excluded from the labor market.</p>
<p><strong>8.</strong>  <em>Basic Income will reward unpaid contributions.</em></p>
<p>A huge number of unpaid activities are currently not recognized as economic contributions. Yet our economy increasingly relies on these free contributions &#8212; think about <em>Wikipedia, </em>or the work parents do. A basic income would recognize and reward theses activities.</p>
<p><strong>9.</strong>  <em>Basic Income will strengthen our democracy.</em></p>
<p>With a minimum level of security guaranteed to all citizens &#8212; and less time in work or worrying about work &#8212; innovation in political, social, economic &amp; technological terms would become a lively part of everyday life and its concerns.</p>
<p><strong>10.</strong>  <em>Basic Income is a fair redistribution of technological advancement.</em></p>
<p>Thanks to massive advancements in our technological and productive capacities, the world of work is changing. But most of our wealth and technology comes from standing on the shoulders of giants. We&#8217;re wealthier because of our ancestors. Basic income is a way to civilize and re-distribute the advantages of that ongoing advancement.</p>
<p><strong>11.</strong>  <em>Basic Income will end extreme financial poverty.</em></p>
<p>Because we live in a world where we have the means and the will to end the kinds of suffering we see as a supposedly constant feature of our surroundings. Basic income is a way to join together the means and the will.</p>
<hr />
<p><img style=' float: left; padding: 4px; margin: 0 7px 2px 0;'  class="alignleft size-full wp-image-301691 noshadow" title="letters from Ray - universal basic income - H5" src="http://www.kurzweilai.net/images/letters-from-Ray-universal-basic-income-H5.png" alt="" width="640" height="640" /></p>
<hr class="dotted" />
<p><span style="color: #ff9900;">on the web</span> | <em>background</em></p>
<p>Harvard University | <a href="https://www.youtube.com/user/Harvard" target="_blank">YouTube channel</a><br />
Harvard University | Facebook founder Mark Zuckerberg commencement address 2017 • <a href="https://www.youtube.com/watch?v=BmYv8XGl-YU" target="_blank">video</a></p>
<p>Chan + Zuckerberg Initiative | <a href="https://chanzuckerberg.com/" target="_blank">main</a></p>
<hr class="dotted" />
<p><span style="color: #ff9900;">on the web</span> | <em>essentials</em></p>
<p><em>Wikipedia</em> | <a href="https://en.wikipedia.org/wiki/Basic_income" target="_blank">universal basic income</a><br />
<em>Wikipedia</em> | <a href="https://en.wikipedia.org/wiki/Mark_Zuckerberg" target="_blank">Mark Zuckerberg</a></p>
<p><em>Futurism</em> | universal basic income: the answer to automation? • <a href="https://futurism.com/images/universal-basic-income-answer-automation/" target="_blank">infographic</a></p>
<p><em>Vice</em> | <a href="https://www.vice.com/en_us/article/what-would-happen-if-we-gave-everyone-a-chunk-of-free-money" target="_blank">What would happen if we gave everyone free money<strong>:</strong> new experiments in universal basic income</a></p>
<p>Basic Income | <a href="http://www.basicincome.org.uk" target="_blank">main</a><br />
Basic Income | <a href="http://www.basicincome.org.uk/what_is_basic_income" target="_blank">What is basic income?</a><br />
Basic Income | <a href="http://www.basicincome.org.uk/reasons-support-basic-income" target="_blank">10 reasons to support basic income</a></p>
<hr />
<p><span style="color: #ff9900;">book</span> | <em>on topic</em></p>
<p>&nbsp;</p>
<p><span style="color: #ff9900;">book title<strong>:</strong></span> <a href="http://basicincome.org/news/2017/03/new-book-basic-income-radical-proposal-philippe-van-parijs-yannick-vanderborght/" target="_blank">Basic Income: a radical proposal for a free society &amp; a sane economy</a><br />
<span style="color: #ff9900;">authors<strong>:</strong></span> by Philippe Van Parijs + Yannick Vanderborght</p>
<hr class="dotted" />
<p><img style=' float: left; padding: 4px; margin: 0 7px 2px 0;'  class="alignleft size-full wp-image-301694 noshadow" title="letters from Ray - universal basic income - H6" src="http://www.kurzweilai.net/images/letters-from-Ray-universal-basic-income-H6.png" alt="" width="400" height="428" /></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:106:"http://www.kurzweilai.net/letter-from-ray-supporting-universal-basic-income-as-step-in-world-progress/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:31;a:6:{s:4:"data";s:53:"
		
		
		
		
		
								
		
				

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:72:"International Conference on Machine Learning and Data Mining (MLDM 2017)";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:96:"http://www.kurzweilai.net/international-conference-on-machine-learning-and-data-mining-mldm-2017";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:105:"http://www.kurzweilai.net/international-conference-on-machine-learning-and-data-mining-mldm-2017#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Sat, 27 May 2017 01:25:37 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:1:{i:0;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=299766";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:326:"The Aim of the Conference The aim of the conference is to bring together researchers from all over the world who deal with machine learning and data mining in order to discuss the recent status of the research and to direct further developments. Basic research papers as well as application papers are welcome. All kinds [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:60:"http://www.kurzweilai.net/images/mldm_titelgrafik-140x23.gif";s:5:"width";s:3:"140";s:6:"height";s:2:"23";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:3878:"<h4><img style=' display: block; margin-right: auto; margin-left: auto;'  class="aligncenter size-full wp-image-299768" title="mldm_titelgrafik" src="http://www.kurzweilai.net/images/mldm_titelgrafik.gif" alt="" width="489" height="81" /></h4>
<h4>The Aim of the Conference</h4>
<p align="justify">The aim of the conference is to bring together researchers from all over the world who deal with machine learning and data mining in order to discuss the recent status of the research and to direct further developments. Basic research papers as well as application papers are welcome.</p>
<p align="justify">All kinds of applications are welcome but special preference will be given to multimedia related applications, biomedical applications, and webmining. Paper submissions should be related but not limited to any of the following topics:</p>
<ul type="square">
<li>association rules</li>
<li>Audio Mining</li>
<li>case-based reasoning and learning</li>
<li>classification and interpretation of images, text, video</li>
<li>conceptional learning and clustering</li>
<li>Goodness measures and evaluaion (e.g. false discovery rates)</li>
<li>inductive learning including decision tree and rule induction learning</li>
<li>knowledge extraction from text, video, signals and images</li>
<li>mining gene data bases and biological data bases</li>
<li>mining images, temporal-spatial data, images from remote sensing</li>
<li>mining structural representations such as log files, text documents and HTML documents</li>
<li>mining text documents</li>
<li>organisational learning and evolutional learning</li>
<li>probabilistic information retrieval</li>
<li>Selection bias</li>
<li>Sampling methods</li>
<li>Selection with small samples</li>
<li>similarity measures and learning of similarity</li>
<li>statistical learning and neural net based learning</li>
<li>video mining</li>
<li>visualization and data mining</li>
<li>Applications of Clustering</li>
<li>Aspects of Data Mining</li>
<li>Applications in Medicine</li>
<li>Autoamtic Semantic Annotation of Media Content</li>
<li>Bayesian Models and Methods</li>
<li>Case-Based Reasoning and Associative Memory</li>
<li>Classification and Model Estimation</li>
<li>Content-Based Image Retrieval</li>
<li>Decision Trees</li>
<li>Deviation and Novelty Detection</li>
<li>Feature Grouping, Discretization, Selection and Transformation</li>
<li>Feature Learning</li>
<li>Frequent Pattern Mining</li>
<li>High-Content Analysis of Microscopic Images in Medicine, Biotechnology and Chemistry</li>
<li>Learning and adaptive control</li>
<li>Learning/adaption of recognition and perception</li>
<li>Learning for Handwriting Recognition</li>
<li>Learning in Image Pre-Processing and Segmentation</li>
<li>Learning in process automation</li>
<li>Learning of internal representations and models</li>
<li>Learning of appropriate behaviour</li>
<li>Learning of action patterns</li>
<li>Learning of Ontologies</li>
<li>Learning of Semantic Inferencing Rules</li>
<li>Learning of Visual Ontologies</li>
<li>Learning robots</li>
<li>Mining Financial or Stockmarket Data</li>
<li>Mining Images in Computer Vision</li>
<li>Mining Images and Texture</li>
<li>Mining Motion from Sequence</li>
<li>Neural Methods</li>
<li>Network Analysis and Intrusion Detection</li>
<li>Nonlinear Function Learning and Neural Net Based Learning</li>
<li>Real-Time Event Learning and Detection</li>
<li>Retrieval Methods</li>
<li>Rule Induction and Grammars</li>
<li>Speech Analysis</li>
<li>Statistical and Conceptual Clustering Methods: Basics</li>
<li>Statistical and Evolutionary Learning</li>
<li>Subspace Methods</li>
<li>Support Vector Machines</li>
<li>Symbolic Learning and Neural Networks in Document Processing</li>
<li>Text Mining</li>
<li>Time Series and Sequential Pattern Mining</li>
<li>Mining Social Media</li>
</ul>
<p><em>&#8212;Event Producer</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:101:"http://www.kurzweilai.net/international-conference-on-machine-learning-and-data-mining-mldm-2017/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:32;a:6:{s:4:"data";s:53:"
		
		
		
		
		
								
		
				

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:65:"International Joint Conference on Artificial Intelligence (IJCAI)";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:89:"http://www.kurzweilai.net/international-joint-conference-on-artificial-intelligence-ijcai";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:98:"http://www.kurzweilai.net/international-joint-conference-on-artificial-intelligence-ijcai#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Sat, 27 May 2017 01:24:59 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:1:{i:0;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=299770";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:376:"IJCAI is the International Joint Conference on Artificial Intelligence, the main international gathering of researchers in AI. IJCAI were held biennially in odd-numbered years since 1969. Starting with 2016, IJCAI will be held annually. IJCAI is sponsored jointly by IJCAI and the national AI societie(s) of the host nation(s). The 26th International Joint Conference on [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:59:"http://www.kurzweilai.net/images/logo3-ijcai2017-140x52.png";s:5:"width";s:3:"140";s:6:"height";s:2:"52";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:762:"<p style="text-align: center;"><img style=' display: block; margin-right: auto; margin-left: auto;'  class="aligncenter  wp-image-299771 noshadow" title="logo3-ijcai2017" src="http://www.kurzweilai.net/images/logo3-ijcai2017.png" alt="" width="492" height="185" /></p>
<p>IJCAI is the International Joint Conference on Artificial Intelligence, the main international gathering of researchers in AI. IJCAI were held biennially in odd-numbered years since 1969. Starting with 2016, IJCAI will be held annually. IJCAI is sponsored jointly by IJCAI and the national AI societie(s) of the host nation(s). The 26th International Joint Conference on Artificial Intelligence will be held in Melbourne, Australia in August 2017.</p>
<p><em>&#8212;Event Producer</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:94:"http://www.kurzweilai.net/international-joint-conference-on-artificial-intelligence-ijcai/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:33;a:6:{s:4:"data";s:44:"
		
		
		
		
		
		
				

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:4:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:53:"Intelligent Systems Conference 2017 (IntelliSys 2017)";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:77:"http://www.kurzweilai.net/intelligent-systems-conference-2017-intellisys-2017";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:86:"http://www.kurzweilai.net/intelligent-systems-conference-2017-intellisys-2017#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Sat, 27 May 2017 01:24:35 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:1:{i:0;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=299774";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:400:"Intelligent Systems Conference (IntelliSys) 2017 will focus on areas of intelligent systems and artificial intelligence (AI) and how it applies to the real world. IntelliSys is one of the best respected Artificial Intelligence (AI) Conference. IntelliSys provides a leading international forum that brings together researchers and practitioners from diverse fields with the purpose of exploring [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:839:"<p><img style=' float: left; padding: 4px; margin: 0 7px 2px 0;'  class="alignleft size-full wp-image-299775 noshadow" title="intellisys-logo" src="http://www.kurzweilai.net/images/intellisys-logo.png" alt="" width="300" height="148" /></p>
<p>Intelligent Systems Conference (IntelliSys) 2017 will focus on areas of intelligent systems and artificial intelligence (AI) and how it applies to the real world. IntelliSys is one of the best respected Artificial Intelligence (AI) Conference.</p>
<p>IntelliSys provides a leading international forum that brings together researchers and practitioners from diverse fields with the purpose of exploring the fundamental roles, interactions as well as practical impacts of Artificial Intelligence (AI). It is part of the conference series started in 2013.</p>
<p><em>&#8212;Event Producer</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:82:"http://www.kurzweilai.net/intelligent-systems-conference-2017-intellisys-2017/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:34;a:6:{s:4:"data";s:53:"
		
		
		
		
		
								
		
				

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:24:"World of Watson – 2017";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:46:"http://www.kurzweilai.net/world-of-watson-2017";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:55:"http://www.kurzweilai.net/world-of-watson-2017#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Sat, 27 May 2017 01:24:16 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:1:{i:0;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=299778";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:398:"The largest cognitive technology and AI conference in the U.S., World of Watson hosted by IBM includes a “Cognitive Concourse,” multiple keynotes, innovation talks and spotlight sessions by industry experts and business leaders. There will also be 200+ hands-on labs and developer certifications. See for yourself how to differentiate your business and transform customers’ lives. From [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:55:"http://www.kurzweilai.net/images/ibmpos_blue-140x51.jpg";s:5:"width";s:3:"140";s:6:"height";s:2:"51";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:1188:"<p style="text-align: center;"><img style=' display: block; margin-right: auto; margin-left: auto;'  class="aligncenter  wp-image-299779 noshadow" title="ibmpos_blue" src="http://www.kurzweilai.net/images/ibmpos_blue.jpg" alt="" width="505" height="185" /></p>
<p>The largest cognitive technology and AI conference in the U.S., World of Watson hosted by IBM includes a “Cognitive Concourse,” multiple keynotes, innovation talks and spotlight sessions by industry experts and business leaders. There will also be 200+ hands-on labs and developer certifications. See for yourself how to differentiate your business and transform customers’ lives. From photo-journalistic storytelling to the immersion of virtual reality, to cognitive autonomous vehicles to next-gen drone photography, you will be inspired to accelerate their own cognitive journeys, transforming your industries and our society. A chance to experience these new technologies, hands-on.</p>
<p><iframe frameborder="0" height="315" src="https://www.youtube.com/embed/zmKHzUI7jSY?rel=0" width="560"></iframe><br />
<em>IBM Analytics | Exploring IBM World of Watson Day 2</em></p>
<p><em>&#8212;Event Producer</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:51:"http://www.kurzweilai.net/world-of-watson-2017/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:35;a:6:{s:4:"data";s:53:"
		
		
		
		
		
								
		
				

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:68:"International Joint Conference on Computational Intelligence (IJCCI)";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:92:"http://www.kurzweilai.net/international-joint-conference-on-computational-intelligence-ijcci";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:101:"http://www.kurzweilai.net/international-joint-conference-on-computational-intelligence-ijcci#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Sat, 27 May 2017 01:23:51 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:1:{i:0;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=299784";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:455:"The purpose of the International Joint Conference on Computational Intelligence – IJCCI &#8211; is to bring together researchers, engineers and practitioners interested on the field of Computational Intelligence both from theoretical and application perspectives. Four simultaneous tracks will be held covering different aspects of Computational Intelligence, including evolutionary computation, fuzzy computation, neural computation and cognitive [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:54:"http://www.kurzweilai.net/images/ijcci-logo-140x23.png";s:5:"width";s:3:"140";s:6:"height";s:2:"23";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:927:"<p style="text-align: center;"><img style=' display: block; margin-right: auto; margin-left: auto;'  class="aligncenter  wp-image-299785" title="ijcci-logo" src="http://www.kurzweilai.net/images/ijcci-logo.png" alt="" width="568" height="97" /></p>
<p>The purpose of the International Joint Conference on Computational Intelligence – IJCCI &#8211; is to bring together researchers, engineers and practitioners interested on the field of Computational Intelligence both from theoretical and application perspectives.<br />
Four simultaneous tracks will be held covering different aspects of Computational Intelligence, including evolutionary computation, fuzzy computation, neural computation and cognitive and hybrid systems. The connection of these areas in all their wide range of approaches and applications forms the International Joint Conference on Computational Intelligence.</p>
<p><em>&#8212;Event Producer</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:97:"http://www.kurzweilai.net/international-joint-conference-on-computational-intelligence-ijcci/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:36;a:6:{s:4:"data";s:53:"
		
		
		
		
		
								
		
				

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:9:"Synaptech";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/synaptech";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:44:"http://www.kurzweilai.net/synaptech#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Sat, 27 May 2017 01:20:27 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:1:{i:0;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=300895";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:354:"2017 is shaping up to be the year that AI finally moves from being the province of university labs to being a critical part of the software developer’s toolkit and a focus for mainstream companies. AI is currently driving an explosion in real-world intelligent software— bots, agents, voice and IoT interfaces, even self-driving cars. And this [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:60:"http://www.kurzweilai.net/images/logo-synaptecg-2-140x43.png";s:5:"width";s:3:"140";s:6:"height";s:2:"43";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:1521:"<p><img style=' display: block; margin-right: auto; margin-left: auto;'  class="aligncenter  wp-image-300897 noshadow" title="logo-synaptecg-2" src="http://www.kurzweilai.net/images/logo-synaptecg-2.png" alt="" width="405" height="126" /></p>
<p>2017 is shaping up to be the year that AI finally moves from being the province of university labs to being a critical part of the software developer’s toolkit and a focus for mainstream companies. AI is currently driving an explosion in real-world intelligent software— bots, agents, voice and IoT interfaces, even self-driving cars. And this is just the beginning&#8230;</p>
<h4>Event Structure</h4>
<ul>
<li>The most recent developments in the AI field, featuring leaders from thriving industries</li>
<li>An international competition for startups with disruptive products focused on AI and connected technologies</li>
<li>Education and hands-on approach on the newest Machine Learning practices</li>
</ul>
<h4>Why Did We Launch Synaptech?</h4>
<div>
<p>When we’re starting an event, we’re not just following the hype. We’re following trends we’re passionate about and we’re committed to creating a community. A community focused on connecting industries, business opportunities and domain leaders to stimulate the creation of revolutionary AI related products.</p>
<p>We’ve created Synaptech because we believe that AI is finally becoming a reality and the opportunities are as infinite as deep learning.</p>
<p><em>&#8212;Event Producer</em></p>
</div>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:40:"http://www.kurzweilai.net/synaptech/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"1";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:37;a:6:{s:4:"data";s:53:"
		
		
		
		
		
								
		
				

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:17:"ARM Tech Con 2017";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:42:"http://www.kurzweilai.net/arm-techcon-2017";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:51:"http://www.kurzweilai.net/arm-techcon-2017#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Sat, 27 May 2017 01:19:50 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:1:{i:0;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=301393";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:424:"ARM® TechCon offers the world’s largest conference dedicated to ARM technologies. 100+ speakers strong and 60 hours deep, the eight-track program covers a diverse range of real-world challenges facing software developers, hardware engineers, and executive managers. Track sessions are tailored to both novice and expert experience levels. Exclusive to all-access pass holders. More Than a Leading Conference Your [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:60:"http://www.kurzweilai.net/images/arm-techcon-logo-140x48.png";s:5:"width";s:3:"140";s:6:"height";s:2:"48";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:2031:"<p><img style=' float: left; padding: 4px; margin: 0 7px 2px 0;'  class="alignleft size-full wp-image-260387 noshadow" title="arm-techcon-logo" src="http://www.kurzweilai.net/images/arm-techcon-logo.png" alt="" width="223" height="77" />ARM® TechCon offers the world’s largest conference dedicated to ARM technologies. <strong>100+ speakers strong and 60 hours deep</strong>, the eight-track program covers a diverse range of real-world challenges facing software developers, hardware engineers, and executive managers. Track sessions are tailored to both novice and expert experience levels. Exclusive to <a href="http://www.armtechcon.com/passes-pricing/" target="_blank">all-access pass</a> holders.</p>
<h4>More Than a Leading Conference</h4>
<p>Your all-access pass includes the following ARM TechCon features:</p>
<p><strong>Keynotes</strong> – Take actionable insights back to the office from embedded systems’ top minds. Keep an eye out: Big names will be announced in the coming weeks.</p>
<p><strong>Networking Drinks</strong> – Cheers to easy connections! Swap insights over free drinks and food at the cocktail reception and meet top ARM partners for beers during the booth crawl.</p>
<p><strong>Expo Floor</strong> – Reduce time to market or get inspiration for your next project with bleeding-edge products from more than one hundred leading ARM partners on the expo floor.</p>
<p><strong>Training</strong> – Attend two-hour sessions on a host of ARM ecosystem challenges, building valuable, actionable skills under the direction of expert engineers and developers.</p>
<p><strong>ARM mbed™ Connect</strong> – Discover the power of the mbed IoT platform through hands-on coding sessions, tutorials, and live demos led by developers who know it back to front.</p>
<p><strong>Sponsored Sessions</strong> – Hear from leading companies as they showcase new products and services helping to make faster, cheaper, and more competitive embedded systems.</p>
<p><em>&#8212;Event Producer</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:47:"http://www.kurzweilai.net/arm-techcon-2017/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:38;a:6:{s:4:"data";s:53:"
		
		
		
		
		
								
		
				

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:5:"SB7.0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:31:"http://www.kurzweilai.net/sb7-0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:40:"http://www.kurzweilai.net/sb7-0#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Sat, 27 May 2017 01:19:10 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:1:{i:0;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=301400";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:353:"The goal of SB7.0 is to unite again the international synthetic biology communities to take a fresh look at the key topics and challenges that our field faces. Synthetic biology cannot advance without exploring and embracing the changes that it brings. As practitioners, scholars, and citizens we need to work together to explore the possibilities [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:60:"http://www.kurzweilai.net/images/SB70-black-small-140x54.png";s:5:"width";s:3:"140";s:6:"height";s:2:"54";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:3415:"<p><img style=' float: left; padding: 4px; margin: 0 7px 2px 0;'  class="alignleft size-full wp-image-301401 noshadow" title="SB70-black-small" src="http://www.kurzweilai.net/images/SB70-black-small.png" alt="" width="150" height="58" />The goal of SB7.0 is to unite again the international synthetic biology communities to take a fresh look at the key topics and challenges that our field faces. Synthetic biology cannot advance without exploring and embracing the changes that it brings. As practitioners, scholars, and citizens we need to work together to explore the possibilities and plan strategically for collective growth of our science, its beneficial applications, and responsible practices.</p>
<p>Synthetic biology can be used to advance so many facets of the world today, from agriculture and biomanufacturing, to groundbreaking cancer treatments and medicines, to even fashion and information technology. As the science continues to evolve, the scientists, engineers, and designers themselves need to focus our efforts on creating local biological solutions to meet global needs. But what we can’t forget is to take a step back and look at the world as a whole. Not just how does any one latest advancements better human life, but what are the footprints we are leaving behind? How does what we develop ultimately affect the world, from insects and plants to animals and aquatic life? While the full potential of synthetic biology continues to develop, we as a community must join together to make sure we don’t lose focus on the global impacts of our collective capacities.  How can we best help not only humans but also the rest of the planet?</p>
<p>Singapore, a country that is rich in cultural diversity and strategic capacities, affords us the perfect venue in which to refocus on the diversity and goals of synthetic biology as a field. As a community, how can we make the education, science, and business opportunities more available to all people regardless of race, gender, or socio-economic background? It’s only with continuous diversification and expansion that the synthetic biology industry will be able to realize it’s full potential.  Please join us to learn about the latest and best work from all over the world, and to help develop the most important next steps for our still-emerging field.</p>
<p>On Saturday June 17, 2017, the <a href="http://syntheticyeast.org/sc2-0/" rel="nofollow noopener noreferrer" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=http://syntheticyeast.org/sc2-0/&amp;source=gmail&amp;ust=1493238430569000&amp;usg=AFQjCNHRLFPV1sb0wkU06zymb8GdP8-CtA">Synthetic Yeast Genome Project (Sc2.0)</a> will be held in Singapore and is the world’s first synthetic eukaryotic genome project that aims to create a novel, rationalized version of the genome of the yeast species <em>Saccharomyces cerevisiae</em>. In a truly global collaborative effort, research teams across the world have embarked on the challenging but exciting task of building 16 designer synthetic chromosomes encompassing ~ 12 million base pairs of DNA. The Sc2.0 consortium will be participating in SB7.0. Register for the <a href="https://www.eventbrite.sg/e/6th-annual-sc20-meeting-singapore-tickets-32810369699" target="_blank">6th Annual Synthetic Yeast Genome Project (Sc2.0) Meeting</a> in Singapore.</p>
<p><em>&#8212;Event Producer</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:36:"http://www.kurzweilai.net/sb7-0/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:39;a:6:{s:4:"data";s:53:"
		
		
		
		
		
								
		
				

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:26:"DEF CON Biohacking Village";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:52:"http://www.kurzweilai.net/def-con-biohacking-village";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:61:"http://www.kurzweilai.net/def-con-biohacking-village#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Fri, 26 May 2017 21:39:22 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:1:{i:0;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=301404";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:409:"The DEF CON Biohacking Village is a multi-day biotechnology conference focused on breakthrough DIY, grinder, transhumanist, medical technology, and information security along with its related communities in the open source ecosystem. There have been multiple instances of DIYBio overcoming conventional science. We want to celebrate the biohacker movement with a compendium of talks, demonstrations, and [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:48:"http://www.kurzweilai.net/images/bhv-140x126.png";s:5:"width";s:3:"140";s:6:"height";s:3:"126";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:2572:"<p><img style=' display: block; margin-right: auto; margin-left: auto;'  class="aligncenter  wp-image-301405 noshadow" title="bhv" src="http://www.kurzweilai.net/images/bhv.png" alt="" width="251" height="226" /></p>
<p>The DEF CON Biohacking Village is a multi-day biotechnology conference focused on breakthrough DIY, grinder, transhumanist, medical technology, and information security along with its related communities in the open source ecosystem. There have been multiple instances of DIYBio overcoming conventional science. We want to celebrate the biohacker movement with a compendium of talks, demonstrations, and a medical device hackathon.</p>
<p>The 2017 BioHacking Village theme is Medical Industry Disrupt. The Medical Industry is one of the last to be touched by technology. We have placed doctors and the study of medicine on an alter for years; the time of ivory towers, pedestals, and information isolation has come to an end. Biohackers are working on projects that have traditionally been kept in the labs of the medical institutions. We are moving science forward by working on DIY projects that matter and use citizen science to solve the economic problems that are caused by privatizing medicine and the resources for research.</p>
<p>Our goal is to extend beyond the scope of mission driven technology. This event and the community behind it place a strong emphasis on diversity, inclusiveness, education, collaboration, and contribution. The BioHacking Village is also focused on helping developers learn the skills and other factors associated with successful careers in biotechnology and software development. The event aims to provide opportunities to interact with like-minded scientists and developers, to learn from one another, as well as help each other see opportunities that may be available.</p>
<p>We welcome anyone interested in do-it-yourself biology. Biohackers reject the idea that all medical, biological, and genetic advancements must come from a large institutions, university, or corporation. We reject the idea that modifications to biology must only be in response to disease or dysfunction. We reject the natural order given to us by evolution… or perhaps we have evolved to the point where we can take evolution into our own hands. We dare to ask the questions: How can we use technology to enhance our raw abilities, specific skills, overall health, or well-being? How can we usher in an age where we not only fix what’s broken, but we make ourselves, and our world, better?</p>
<p><em>&#8212;Event Producer</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:57:"http://www.kurzweilai.net/def-con-biohacking-village/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"1";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:40;a:6:{s:4:"data";s:44:"
		
		
		
		
		
		
				

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:4:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:42:"Wearable Tech + Digital Health + Neurotech";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:64:"http://www.kurzweilai.net/wearable-tech-digital-health-neurotech";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:73:"http://www.kurzweilai.net/wearable-tech-digital-health-neurotech#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Fri, 26 May 2017 21:38:07 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:1:{i:0;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=301408";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:434:"Digital tools and data analysis have already transformed the way health is monitored, diagnosed, predicted, and improved. On September 19, 2017, at the MIT Media Lab, provocative scientists and technologists will lead discussions on AI for diagnosis and predictive health, adaptive medicine, novel sensors, digital pharma companions, brain computer interfaces, robotics, VR/AR/mixed reality, machine learning, computer vision, [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:2022:"<p>Digital tools and data analysis have already transformed the way health is monitored, diagnosed, predicted, and improved.</p>
<p>On September 19, 2017, at the MIT Media Lab, provocative scientists and technologists will lead discussions on AI for diagnosis and predictive health, adaptive medicine, novel sensors, digital pharma companions, brain computer interfaces, robotics, VR/AR/mixed reality, machine learning, computer vision, text analysis and crowd intelligence in healthcare, breakthrough surgical and diagnostic techniques, data analysis for optimized treatment – and other topics driving the “health sensor revolution.”</p>
<p>We will not re-hash corporate slogans and traditional thinking.  <strong>Pure innovation is our rule</strong>.  This conference was created for visionary investors, innovators, payers and providers, to focus on what’s next.</p>
<p>The result will be multidisciplinary solutions to save and enhance lives.  Putting disruptive digital health tools into practice. Using them to benefit all, irrespective of wealth or location. Replacing the stigmas of mental illness with compassionate solutions. Managing chronic disease for a prolonged, active existence . Making medical treatment more humane, efficient and effective — and cheaper. Enabling healthier pregnancies, and the safe monitoring of babies and children. Allowing seniors to age in place with dignity. And creating elite athletes through body and brain feedback, monitoring and stimulation.</p>
<p>Following six events over two years in <a href="http://digitalhealthsf.com/" target="_blank">San Francisco</a>, <a href="http://wearabletech.nyc/">New York</a>, and most recently at <a href="http://stanford.applysci.com/" target="_blank">Stanford University</a>, the editors of <a href="http://blog.applysci.com/" target="_blank">ApplySci</a> looks forward to welcoming you to the 7th Wearable Tech + Digital Health + NeuroTech conference this September.</p>
<p><em>&#8212;Event Producer</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:69:"http://www.kurzweilai.net/wearable-tech-digital-health-neurotech/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:41;a:6:{s:4:"data";s:62:"
		
		
		
		
		
								
		
				
		
		
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:81:"3D-printed ‘bionic skin’ could give robots and prosthetics the sense of touch";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:101:"http://www.kurzweilai.net/3d-printed-bionic-skin-could-give-robots-and-prosthetics-the-sense-of-touch";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:110:"http://www.kurzweilai.net/3d-printed-bionic-skin-could-give-robots-and-prosthetics-the-sense-of-touch#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Fri, 26 May 2017 18:53:49 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:4:{i:0;a:5:{s:4:"data";s:11:"AI/Robotics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:16:"Biomed/Longevity";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:11:"Electronics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=300597";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:381:"Engineering researchers at the University of Minnesota have developed a process for 3D-printing stretchable, flexible, and sensitive electronic sensory devices that could give robots or prosthetic hands &#8212; or even real skin &#8212; the ability to mechanically sense their environment. One major use would be to give surgeons the ability to feel during minimally invasive [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:60:"http://www.kurzweilai.net/images/3d-printedsensor-140x93.jpg";s:5:"width";s:3:"140";s:6:"height";s:2:"93";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:6270:"<div id="attachment_300598" class="wp-caption aligncenter" style="width: 435px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><a href="http://www.kurzweilai.net/images/3d-printedsensor.jpg"><img class=" wp-image-300598" title="3d-printedsensor" src="http://www.kurzweilai.net/images/3d-printedsensor.jpg" alt="" width="425" height="283" /></a><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Schematic of a new kind of 3D printer that can print touch sensors directly on a model hand. (credit: Shuang-Zhuang Guo and Michael McAlpine/Advanced Materials )</p></div>
<p>Engineering researchers at the <a href="http://www.umn.edu" target="_blank">University of Minnesota</a> have developed a process for 3D-printing stretchable, flexible, and sensitive electronic sensory devices that could give robots or prosthetic hands &#8212; or even real skin &#8212; the ability to mechanically sense their environment.</p>
<p>One major use would be to give surgeons the ability to feel during minimally invasive surgeries instead of using cameras, or to increase the sensitivity of surgical robots. The process could also make it easier for robots to walk and interact with their environment.</p>
<p>Printing electronics directly on human skin could be used for pulse monitoring, energy harvesting (of movements), detection of finger motions (on a keyboard or other devices), or chemical sensing (for example, by soldiers in the field to detect dangerous chemicals or explosives). Or imagine a future computer mouse built into your fingertip, with haptic touch on any surface.</p>
<p>“While we haven’t printed on human skin yet, we were able to print on the curved surface of a model hand using our technique,” said <a href="http://www.me.umn.edu/people/mcalpine.shtml" target="_blank">Michael McAlpine</a>, a University of Minnesota mechanical engineering associate professor and lead researcher on the study.* “We also interfaced a printed device with the skin and were surprised that the device was so sensitive that it could detect your pulse in real time.”</p>
<p>The researchers also visualize use in &#8220;bionic organs.&#8221;</p>
<p><strong>A unique skin-compatible 3D-printing process</strong></p>
<div id="attachment_301417" class="wp-caption aligncenter" style="width: 609px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><img class=" wp-image-301417" title="tactile sensor" src="http://www.kurzweilai.net/images/tactile-sensor.png" alt="" width="599" height="159" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">(left) Schematic of the tactile sensor. (center) Top view. (right) Optical image showing the conformally printed 3D tactile sensor on a fingertip. Scale bar = 4 mm. (credit: Shuang-Zhuang Guo et al./Advanced Materials)</p></div>
<p>McAlpine and his team made the sensing fabric with a one-of-a kind 3D printer they built in the lab. The multifunctional printer has four nozzles to print the various specialized “inks” that make up the layers of the device &#8212; a base layer of silicone**, top and bottom electrodes made of a silver-based <a href="https://en.wikipedia.org/wiki/Piezoresistive_effect" target="_blank">piezoresistive</a> conducting ink, a coil-shaped pressure sensor, and a supporting layer that holds the top layer in place while it sets (later washed away in the final manufacturing process).</p>
<p>Surprisingly, all of the layers of “inks” used in the flexible sensors can set at room temperature. Conventional 3D printing using liquid plastic is too hot and too rigid to use on the skin. The sensors can stretch up to three times their original size.</p>
<p>The researchers say the next step is to move toward semiconductor inks and printing on a real surface. “The manufacturing is built right into the process, so it is ready to go now,” McAlpine said.</p>
<p><em>The research was published online in the journal </em>Advanced Materials<em>. It was funded by the National Institute of Biomedical Imaging and Bioengineering of the National Institutes of Health.</em></p>
<p><em>* McAlpine integrated electronics and novel 3D-printed nanomaterials to create a “<a href="http://www.kurzweilai.net/3d-printed-bionic-ear-melds-electronics-and-biology" target="_blank">bionic ear</a>” in 2013.</em></p>
<p><em>** The silicone rubber has a low <a href="https://en.wikipedia.org/wiki/Elastic_modulus" target="_blank">modulus of elasticity</a> of 150 kPa, similar to that of skin, and lower hardness (Shore A 10) than that of human skin, according to the </em>Advanced Materials<em> paper.</em></p>
<p><iframe frameborder="0" height="315" src="https://www.youtube.com/embed/GCT0KwFw-pM?rel=0" width="560"></iframe><br />
<em>College of Science and Engineering, UMN | 3D Printed Stretchable Tactile Sensors</em></p>
<hr />
<h4>Abstract of <em>3D Printed Stretchable Tactile Sensors</em></h4>
<p>The development of methods for the 3D printing of multifunctional devices could impact areas ranging from wearable electronics and energy harvesting devices to smart prosthetics and human–machine interfaces. Recently, the development of stretchable electronic devices has accelerated, concomitant with advances in functional materials and fabrication processes. In particular, novel strategies have been developed to enable the intimate biointegration of wearable electronic devices with human skin in ways that bypass the mechanical and thermal restrictions of traditional microfabrication technologies. Here, a multimaterial, multiscale, and multifunctional 3D printing approach is employed to fabricate 3D tactile sensors under ambient conditions conformally onto freeform surfaces. The customized sensor is demonstrated with the capabilities of detecting and differentiating human movements, including pulse monitoring and finger motions. The custom 3D printing of functional materials and devices opens new routes for the biointegration of various sensors in wearable electronics systems, and toward advanced bionic skin applications.</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:106:"http://www.kurzweilai.net/3d-printed-bionic-skin-could-give-robots-and-prosthetics-the-sense-of-touch/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"2";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:42;a:6:{s:4:"data";s:56:"
		
		
		
		
		
								
		
				
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:24:"Do robots creep you out?";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:49:"http://www.kurzweilai.net/do-robots-creep-you-out";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:58:"http://www.kurzweilai.net/do-robots-creep-you-out#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Fri, 26 May 2017 04:45:13 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:2:{i:0;a:5:{s:4:"data";s:11:"AI/Robotics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=300609";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:354:"How do you make humanoid robots look least creepy? With increasing use of industrial (and soon, service robots), it&#8217;s a good question. Researchers at the University of Koblenz-Landau, University of Wurzburg, and Arts Electronica Futurelab decided to find out with an experiment. They created a skit with a human actor and the Roboy robot, and [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:53:"http://www.kurzweilai.net/images/robot-vr-140x112.png";s:5:"width";s:3:"140";s:6:"height";s:3:"112";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:2265:"<div id="attachment_300854" class="wp-caption aligncenter" style="width: 648px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; display: block; margin-right: auto; margin-left: auto;"><a href="http://www.kurzweilai.net/images/robot-reality-check.png"><img class=" wp-image-300854 " title="robot reality check" src="http://www.kurzweilai.net/images/robot-reality-check.png" alt="" width="638" height="125" /></a><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">Which of these presentation methods make the robot look most real: live, VR, 3D TV, or 2D TV? (credit: Constanze Schreiner/University of Koblenz-Landau, Martina Mara/Ars Electronica Futuerlab, and Markus Appel/ University of Wurzburg)</p></div>
<p>How do you make humanoid robots look least creepy? With increasing use of industrial (and soon, service robots), it&#8217;s a good question.</p>
<p>Researchers at the <a href="https://www.uni-koblenz-landau.de/en/university-of-koblenz-landau" target="_blank">University of Koblenz-Landau</a>, <a href="https://www.uni-wuerzburg.de/en/ueber/university/" target="_blank">University of Wurzburg</a>, and <a href="https://www.aec.at/futurelab/en/" target="_blank">Arts Electronica Futurelab</a> decided to find out with an experiment. They created a skit with a human actor and the <a href="https://en.wikipedia.org/wiki/Roboy" target="_blank">Roboy robot</a>, and presented scripted human-robot interactions (HRIs), using four types of presentations: live, virtual reality (VR), 3D TV, and 2D TV. Participants saw Roboy assisting the human in organizing appointments, conducting web searches, and finding a birthday present for the human&#8217;s mother.</p>
<p>People who watched <em>live</em> interactions with the robot were most likely to consider the robot as real, followed by viewing the same interaction via <em>VR</em>. Robots presented in VR also scored high in human likeness, but lower than in the live presentation.</p>
<p>The researchers will present their findings at the <a href="http://www.icahdq.org/page/Conference" target="_blank">67th Annual Conference of the International Communication Association</a> in San Diego, CA, May 25&#8211;29, 2017.</p>
<p>&nbsp;</p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:54:"http://www.kurzweilai.net/do-robots-creep-you-out/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"3";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:43;a:6:{s:4:"data";s:53:"
		
		
		
		
		
								
		
				

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:18:"Black Hat USA 2017";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:44:"http://www.kurzweilai.net/black-hat-usa-2017";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:53:"http://www.kurzweilai.net/black-hat-usa-2017#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Fri, 26 May 2017 01:52:24 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:1:{i:0;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=301161";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:373:"Now in its 20th year, Black Hat is the world’s leading information security event, providing attendees with the very latest in research, development and trends. Black Hat USA 2017 kicks off with four days of technical Trainings (July 22-25) followed by the two-day main conference (July 26-27) featuring Briefings, Arsenal, Business Hall, and more. &#8212;Event Producer";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:67:"http://www.kurzweilai.net/images/black-hat-usa-2017-logo-140x56.png";s:5:"width";s:3:"140";s:6:"height";s:2:"56";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:665:"<p><img style=' display: block; margin-right: auto; margin-left: auto;'  class="aligncenter  wp-image-301162 noshadow" title="black-hat-usa-2017-logo" src="http://www.kurzweilai.net/images/black-hat-usa-2017-logo.png" alt="" width="468" height="189" /></p>
<p>Now in its 20<sup>th</sup> year, Black Hat is the world’s leading information security event, providing attendees with the very latest in research, development and trends. Black Hat USA 2017 kicks off with four days of technical Trainings (July 22-25) followed by the two-day main conference (July 26-27) featuring Briefings, Arsenal, Business Hall, and more.</p>
<p><em>&#8212;Event Producer</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:49:"http://www.kurzweilai.net/black-hat-usa-2017/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:44;a:6:{s:4:"data";s:53:"
		
		
		
		
		
								
		
				

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:51:"MD&amp;M East 2017 — medical device manufacturing";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:39:"http://www.kurzweilai.net/mdm-east-2017";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:48:"http://www.kurzweilai.net/mdm-east-2017#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Thu, 25 May 2017 05:00:39 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:1:{i:0;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=301375";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:355:"Explore the Medtech Trends Redefining the Industry MD&#38;M East – now in its 34th year – is the largest medtech event on the east coast, connecting you with thousands of engineers and executives, as well as hundreds of leading suppliers. Find the medtech solutions, innovations, and inspiration you need to solve your toughest challenges, while [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:62:"http://www.kurzweilai.net/images/MDM_East_logo_225w-140x44.png";s:5:"width";s:3:"140";s:6:"height";s:2:"44";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:2874:"<h4><img style=' display: block; margin-right: auto; margin-left: auto;'  class="aligncenter size-full wp-image-301376 noshadow" title="MDM_East_logo_225w" src="http://www.kurzweilai.net/images/MDM_East_logo_225w.png" alt="" width="225" height="72" /></h4>
<h4>Explore the Medtech Trends Redefining the Industry</h4>
<p>MD&amp;M East – now in its 34th year – is the largest medtech event on the east coast, connecting you with thousands of engineers and executives, as well as hundreds of leading suppliers. Find the medtech solutions, innovations, and inspiration you need to solve your toughest challenges, while staying on top of the latest advancements across the industry. This year the show floor spotlights two industry mega-trends — <a href="http://mdmeast.mddionline.com/3D-printing-focus-mdme" target="_blank"><strong>3D printing</strong></a> and <a href="http://mdmeast.mddionline.com/smart-mfg-focus-mdme" target="_blank"><strong>smart manufacturing</strong></a> — with a dedicated 3D Printing Zone, plus the latest in collaborative robots and robotics on display from the world&#8217;s top suppliers.</p>
<h4>Find Solutions</h4>
<p>Be the first to see the technologies yet to hit the market. Find your answers from hundreds of leading suppliers including Qosina, Zeus, DuPont Medical Packaging, Nordson Medical, and draw daily insights from presentations and activities focused on R&amp;D, improving patient outcomes, value engineering, design thinking, speed to market, 3D printing, and IoT.</p>
<h4>Deepen Your Knowledge</h4>
<p>Access 60 hours of education with one pass. The MD&amp;M East Medtech Conference features two tracks – <em><strong>Design</strong></em> and <em><strong>Product Development</strong></em> – that drill into topics like value-based care, usability, and cost reduction. Your pass also unlocks the 3D Printing and Smart Manufacturing Innovation Summits. Mix and match sessions across all tracks to build the schedule that’s right for you.</p>
<h4>Connect With Your Industry</h4>
<p>In today&#8217;s digital world face-to-face connections are more important than ever. Building your network is easy at MD&amp;M through a variety of fun and engaging networking activities. From a robot build-and-battle, to geek trivia game, and fast-paced speed networking sessions, you&#8217;ll meet the contacts who can advance your projects – and your career.</p>
<h4>Six Industry Shows. One Expo Floor.</h4>
<p>MD&amp;M East runs alongside five additional advanced design and manufacturing trade events, giving you access to a full spectrum of solutions in one end-to-end experience. Meet more than 900 of today&#8217;s top suppliers in packaging, automation, plastics, design, and quality while exploring cutting-edge technologies that can deliver greater efficiency at lower cost.</p>
<p><em>&#8212; event producer</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:44:"http://www.kurzweilai.net/mdm-east-2017/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:45;a:6:{s:4:"data";s:53:"
		
		
		
		
		
								
		
				

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:51:"MD&amp;M West 2018 — medical device manufacturing";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:39:"http://www.kurzweilai.net/mdm-west-2018";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:48:"http://www.kurzweilai.net/mdm-west-2018#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Thu, 25 May 2017 05:00:27 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:1:{i:0;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=301371";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:382:"Join the World&#8217;s Largest Annual Medtech Event Medtech moves fast. For 32 years, MD&#38;M West has helped take medical devices from concept to market by uniting cutting-edge technology with the industry&#8217;s foremost minds. Source from the world&#8217;s largest collection of suppliers on one show floor. Connect with over 20,000 engineers and executives who are ready [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:65:"http://www.kurzweilai.net/images/Web_logo_MDMW_312x100-140x44.png";s:5:"width";s:3:"140";s:6:"height";s:2:"44";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:2890:"<h4><img style=' display: block; margin-right: auto; margin-left: auto;'  class="aligncenter size-full wp-image-301372 noshadow" title="Web_logo_MDMW_312x100" src="http://www.kurzweilai.net/images/Web_logo_MDMW_312x100.png" alt="" width="312" height="100" /></h4>
<h4>Join the World&#8217;s Largest Annual Medtech Event</h4>
<p>Medtech moves fast. For 32 years, MD&amp;M West has helped take medical devices from concept to market by uniting cutting-edge technology with the industry&#8217;s foremost minds.</p>
<p>Source from the world&#8217;s largest collection of suppliers on one show floor. Connect with over 20,000 engineers and executives who are ready to forge business partnerships. Learn from industry luminaries presenting their insights. It&#8217;s three days of industry immersion that medtech professionals simply can&#8217;t afford to miss.</p>
<h4>Find Your Solutions</h4>
<p>Get answers from hundreds of leading medtech suppliers, be the first to witness demos of technology yet to hit the market, and draw daily insight from keynotes and activities focused on business development, improving patient outcomes, value engineering, design thinking, speed to market, 3D printing, and the IoT.</p>
<h4>Deepen Your Knowledge</h4>
<p>The MD&amp;M West conference program is your top resource for accessing the ever-shifting medtech marketplace. In its 32nd year, it will deliver three days and three tracks of product development strategy, design technique, and in-depth workshop learning. With unlimited track hopping and access to the Smart Factory Innovation Summit taking place over all three days, this conference provides you with every tool you need to tackle your company&#8217;s next step.</p>
<h4>Connect With Your Industry</h4>
<p>Engage with over 20,000 industry professionals from leading companies such as Boston Scientific, St. Jude Medical, 3M, and Medtronic. In an increasingly digital world, face-to-face connections matter, and our networking activities help you build partnerships you simply can’t forge on the phone.</p>
<h4>Explore the Smart Manufacturing Revolution</h4>
<p>Smart manufacturing is redefining your industry — and it&#8217;s here to stay. Cobots are becoming smarter and complex systems are connecting to provide unprecedented flexibility, insight, and efficiency on the factory floor. It’s not an option of if to adopt, it&#8217;s when. And you can see it all in perspective at MD&amp;M West.</p>
<p>Explore collaborative robots and robotics accessories on display from the world&#8217;s top suppliers. Attend free activities that connect you with the leading technologies and professionals building the factories of the future. Immerse yourself in the three-day, expert-led Smart Manufacturing Innovation Summit. It&#8217;s time to come face-to-face with your industry&#8217;s game-changer.</p>
<p><em>&#8212; event producer</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:44:"http://www.kurzweilai.net/mdm-west-2018/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:46;a:6:{s:4:"data";s:56:"
		
		
		
		
		
								
		
				
		

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:51:"How Google’s ‘smart reply’ is getting smarter";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:68:"http://www.kurzweilai.net/how-googles-smart-reply-is-getting-smarter";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:77:"http://www.kurzweilai.net/how-googles-smart-reply-is-getting-smarter#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Wed, 24 May 2017 23:44:59 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:2:{i:0;a:5:{s:4:"data";s:11:"AI/Robotics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=301313";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:362:"Last week, KurzweilAI reported that Google is rolling out an enhanced version of its “smart reply” machine-learning email software to “over 1 billion Android and iOS users of Gmail” &#8212; quoting Google CEO Sundar Pichai. We noted that the new smart-reply version is now able to handle challenging sentences like “That interesting person at the [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:57:"http://www.kurzweilai.net/images/Cant-make-it-140x271.png";s:5:"width";s:3:"140";s:6:"height";s:3:"271";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:4742:"<div id="attachment_301344" class="wp-caption alignleft" style="width: 151px;  border: 1px solid #dddddd; background-color: #f3f3f3; padding-top: 4px; margin: 10px; text-align:center; float: left;"><img class="size-full wp-image-301344" title="Can't make it" src="http://www.kurzweilai.net/images/Cant-make-it.png" alt="" width="141" height="274" /><p style=' padding: 0 4px 5px; margin: 0;'  class="wp-caption-text">(credit: Google Research)</p></div>
<p>Last week, <em>KurzweilAI</em> <a href="http://www.kurzweilai.net/google-rolls-out-new-smart-reply-machine-learning-email-software-to-more-than-1-billion-gmail-mobile-users" target="_blank">reported</a> that Google is rolling out an enhanced version of its “<a href="https://blog.google/products/gmail/save-time-with-smart-reply-in-gmail/" target="_blank">smart reply</a>” machine-learning email software to “over 1 billion Android and iOS users of Gmail” &#8212; quoting Google CEO Sundar Pichai.</p>
<p>We noted that the new smart-reply version is now able to handle challenging sentences like “That interesting person at the cafe we like gave me a glance,” as Google research scientist Brian Strope and engineering director Ray Kurzweil noted in a <a href="https://research.googleblog.com/2017/05/efficient-smart-reply-now-for-gmail.html" target="_blank">Google Research blog post</a>.</p>
<p>But “given enough examples of language, a machine learning approach can discover many of these subtle distinctions,” they wrote.</p>
<p>How does it work? &#8220;The content of language is deeply hierarchical, reflected in the structure of language itself, going from letters to words to phrases to sentences to paragraphs to sections to chapters to books to authors to libraries, etc.,&#8221; they explained.</p>
<p>So a hierarchical approach to learning &#8220;is well suited to the hierarchical nature of language. We have found that this approach works well for suggesting possible responses to emails. We use a hierarchy of modules, each of which considers features that correspond to sequences at different temporal scales, similar to how we understand speech and language.&#8221;*</p>
<p><strong>Simplfying communication</strong></p>
<p>“With Smart Reply, Google is assuming users want to offload the burdensome task of communicating with one another to our more efficient counterparts,” <a href="https://www.wired.com/2017/05/google-just-made-email-heckuva-lot-easier-deal/" target="_blank">says</a><em> Wired</em> writer Liz Stinson.</p>
<p>“It’s not wrong. The company says the machine-generated replies already account for 12 percent of emails sent; expect that number to boom once everyone with the Gmail app can send one-tap responses.</p>
<p>“In the short term, that might mean more stilted conversations in your inbox. In the long term, the growing number of people who use these canned responses is only going to benefit Google, whose AI grows smarter with every email sent.”</p>
<p>Another challenge is that our emails, particularly from mobile devices, “tend to be riddled with idioms [such as urban lingo] that make no actual sense,” <a href="https://www.washingtonpost.com/news/the-switch/wp/2017/05/19/do-you-say-thanks-or-thanks-google-will-tailor-suggested-email-replies-to-your-preferences" target="_blank">suggests</a> <em>Washington Post</em> writer Hayley Tsukayama. “Things change depending on context: Something &#8216;wicked&#8217; could be good or very bad, for example. Not to mention, sarcasm is a thing.</p>
<p>“Which is all to warn you that you may still get a wildly random and even potentially inappropriate suggestion &#8212; I once got an &#8216;Oh no!&#8217; suggestion to a friend’s self-deprecating pregnancy announcement, for example. If the email only calls for a one- or two-sentence response, you’ll probably find Smart Reply useful. If it requires any nuance, though, it’s still best to use your own human judgment.”</p>
<p><em>* The initial release of Smart Reply encoded input emails word-by-word with a <a href="https://en.wikipedia.org/wiki/Long_short-term_memory" target="_blank">long-short-term-memory</a> (LSTM) recurrent neural network, and then decoded potential replies with yet another word-level LSTM. While this type of modeling is very effective in many contexts, even with Google infrastructure, it’s an approach that requires substantial computation resources. Instead of working word-by-word, we found an effective and highly efficient path by processing the problem more all-at-once, by comparing a simple hierarchy of vector representations of multiple features corresponding to longer time spans. &#8212; Brian Strope and Ray Kurzweil, </em>Google Research Blog<em>.</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:73:"http://www.kurzweilai.net/how-googles-smart-reply-is-getting-smarter/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:47;a:6:{s:4:"data";s:53:"
		
		
		
		
		
								
		
				

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:10:"Web Summit";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:38:"http://www.kurzweilai.net/web-summit-2";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:47:"http://www.kurzweilai.net/web-summit-2#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Wed, 24 May 2017 21:03:35 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:1:{i:0;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=301278";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:331:"Web Summit started as a simple idea in 2010: Let’s connect the technology community with all industries, both old and new. It seemed to resonate. Web Summit has grown to become the “largest technology conference in the world”. No conference has ever grown so large so fast. But we also pride ourselves in organising the [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:59:"http://www.kurzweilai.net/images/web-summit-logo-140x73.png";s:5:"width";s:3:"140";s:6:"height";s:2:"73";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:1003:"<p><img style=' float: left; padding: 4px; margin: 0 7px 2px 0;'  class="alignleft size-full wp-image-287396 noshadow" title="web-summit-logo" src="http://www.kurzweilai.net/images/web-summit-logo.png" alt="" width="197" height="104" />Web Summit started as a simple idea in 2010: Let’s connect the technology community with all industries, both old and new. It seemed to resonate. Web Summit has grown to become the “largest technology conference in the world”.</p>
<p>No conference has ever grown so large so fast. But we also pride ourselves in organising the “best technology conference on the planet”.</p>
<h4>Meet the first 200 speakers at Web Summit.</h4>
<p>You’ll see the leaders from Intel, Google, Amazon, Facebook, Uber, Tinder and more that you might expect, but also the European Commissioner for Competition, the US&#8217; Senior Advisor for Innovation and some key decision makers from the public, private and civil society sectors.</p>
<p><em>&#8212;Event Producer</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:43:"http://www.kurzweilai.net/web-summit-2/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:48;a:6:{s:4:"data";s:53:"
		
		
		
		
		
								
		
				

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:45:"International Roadmap for Devices and Systems";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:76:"http://www.kurzweilai.net/international-roadmap-for-devices-and-systems-irds";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:85:"http://www.kurzweilai.net/international-roadmap-for-devices-and-systems-irds#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Wed, 24 May 2017 06:22:31 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:1:{i:0;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=301282";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:368:"This initiative focuses on an International Roadmap for Devices and Systems (IRDS) through the work of roadmap teams closely aligned with the advancement of the devices and systems industries. Led by an international roadmap committee (IRC), International Focus Teams (IFTs) will collaborate in the development of a roadmap, and engage with other segments of the [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:53:"http://www.kurzweilai.net/images/irds_logo-140x68.png";s:5:"width";s:3:"140";s:6:"height";s:2:"68";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:6917:"<p><img style=' float: left; padding: 4px; margin: 0 7px 2px 0;'  class="alignleft size-full wp-image-301283 noshadow" title="irds_logo" src="http://www.kurzweilai.net/images/irds_logo.png" alt="" width="267" height="130" />This initiative focuses on an International Roadmap for Devices and Systems (IRDS) through the work of roadmap teams closely aligned with the advancement of the devices and systems industries.</p>
<p>Led by an international roadmap committee (IRC), International Focus Teams (IFTs) will collaborate in the development of a roadmap, and engage with other segments of the IEEE, such as Rebooting Computing, and related industry communities, in complementary activities to help ensure alignment and consensus across a range of stakeholders, such as</p>
<ul>
<li>Academia</li>
<li>Consortia</li>
<li>Industry</li>
<li>National laboratories</li>
</ul>
<p>IEEE, the world&#8217;s largest technical professional organization dedicated to advancing technology for humanity, through the IEEE Standards Association (IEEE-SA) Industry Connections (IC) program, supports the IRDS to ensure alignment and consensus across a range of stakeholders to identify trends and develop the roadmap for all of the related technologies in the computer industry.</p>
<p>The IRDS is sponsored by the <a href="http://rebootingcomputing.ieee.org/" target="_blank">IEEE Rebooting Computing (IEEE RC) Initiative</a> in consultation and support from many IEEE Operating Units and Partner organizations including:<br />
CASS - <a href="http://ieee-cas.org/" target="_blank">Circuits and Systems Society<br />
</a>CEDA - <a href="http://ieee-ceda.org/" target="_blank">Council on Electronic Design Automation<br />
</a>CPMT - <a href="http://cpmt.ieee.org/" target="_blank">Components, Packaging and Manufacturing Society<br />
</a>CS - <a href="http://www.computer.org/" target="_blank">Computer Society<br />
</a>CSC - <a href="http://www.ewh.ieee.org/tc/csc/" target="_blank">Council on Superconductivity<br />
</a>EDS - <a href="http://eds.ieee.org/" target="_blank">Electron Devices Society<br />
</a>MAG - <a href="http://www.ieeemagnetics.org/" target="_blank">Magnetics Society<br />
</a>NTC - <a href="http://sites.ieee.org/nanotech/" target="_blank">Nanotechnology Council<br />
</a>RS - <a href="http://rs.ieee.org/" target="_blank">Reliability Society<br />
</a>SSCS - <a href="http://sscs.ieee.org/" target="_blank">Solid State Circuits Society</a><br />
SRC - <a href="https://www.src.org/" target="_blank">Semiconductor Research Corporation</a></p>
<p><a href="https://standards.ieee.org/" target="_blank">IEEE Standards Association</a></p>
<p>Institute quote from IEEE president.</p>
<p><em>“A major new initiative, the </em><a href="http://theinstitute.ieee.org/ieee-roundup/blogs/blog/plotting-the-course-for-semiconductor-development"><em>International Roadmap for Devices and Systems</em></a><em> </em><em>will ensure alignment and consensus across a range of stakeholders to identify trends and develop the road map for all related technologies in the computer industry. With the launch of the IRDS program, IEEE is taking the lead in building a comprehensive, end-to-end view of the computing ecosystem, including devices, components, systems, architecture, and software.” – Barry Shoop, 2 December 2016, The Institute</em></p>
<h4>IRDS Mission</h4>
<p>Identify the roadmap of electronic industry from devices to systems and from systems to devices</p>
<p>Who We Are<br />
Our roadmap executive committee is comprised of leaders from five regions of the world: Europe, Korea, Japan, Taiwan, and the U.S.A.</p>
<p>The IRDS roadmap IFTs are Application Benchmarking, System and Architecture, More Moore, Beyond CMOS, Heterogeneous Integration (including Systems, Devices, and Packaging), Outside System Connectivity, Factory Integration, Lithography, Metrology, Emerging Research Materials, Environment, Health, and Safety, Yield, Test and Test Equipment, and RF and AMS.</p>
<p>International roadmap efforts directly aligned with the IRDS:</p>
<ul>
<li>NanoElectronics Roadmap for Europe: Identification and Dissemination” (NEREID) <a href="https://www.nereid-h2020.eu/" target="_blank">https://www.nereid-h2020.eu</a></li>
<li>The System Device Roadmap Committee of Japan (SDRJ)</li>
<li>ITRS2.0, <a href="http://www.itrs2.net/" target="_blank">www.itrs2.net</a></li>
<li>the International Electronics Manufacturing Initiative (iNEMI) <a href="http://www.inemi.org/" target="_blank">www.inemi.org</a></li>
<li>Sandia National Labs, <a href="http://www.sandia.gov/" target="_blank">www.sandia.gov</a></li>
</ul>
<p>Our Subject Matter Experts include industry leaders from these communities:</p>
<ul>
<li>Device and Systems Manufacturers</li>
<li>Researchers</li>
<li>Suppliers</li>
<li>Vendors</li>
<li>Computer Manufacturers</li>
<li>Process and Device Modeling Companies</li>
<li>MEMs and NEMs Manufacturers</li>
<li>Semiconductor Process Equipment Manufacturers</li>
<li>Integrated Circuit CAD Vendors</li>
</ul>
<h4>Method</h4>
<ul>
<li>Each of the IFTs will assess present status and future evolution of the ecosystem in their specific field of expertise and produce a 15 year roadmap</li>
<li>This includes: evolution, key challenges, major roadblocks and possible solutions</li>
<li>Integration of all the IFTs roadmaps will produce a “big picture overview”</li>
<li>This IRDS, in cooperation with RCI, will
<ul>
<li>Identify the technology needs and the key enablers, potential solutions, and areas of innovations in order to resolve challenges and meet the 15-year targets for the industries enabled by the IRDS.</li>
<li>Identify any potential cooperation with organizations interested to demonstrating possible solutions</li>
</ul>
</li>
</ul>
<h4>Deliverables</h4>
<p>Exploration of this activity include:</p>
<ul>
<li>Identifying key trends related to devices, systems, and all related technologies by generating a roadmap with a 15-year horizon</li>
<li>Determining generic devices and systems needs, challenges, potential solutions, and opportunities for innovation.</li>
<li>Encouraging related activities world-wide through collaborative events such as related IEEE conferences and roadmap workshops</li>
</ul>
<ul>
<li>Visit our <a href="http://irds.ieee.org/reports" target="_blank">Reports</a> page for 2016 white papers.</li>
</ul>
<p><a href="http://irds.ieee.org/images/files/pdf/IC16-006_IRDS_Entity_PNP.pdf" target="_blank">Policy and Procedures</a></p>
<p>Interested in participating on one of the Focus Teams?  Please contact <a href="mailto:irds_info@ieee.org">irds_info@ieee.org</a>.</p>
<p>IRDS Contact: <a href="mailto:irds_info@ieee.org">irds_info@ieee.org</a>.</p>
<p>Join our <a href="https://ieee-collabratec.ieee.org/app/community/109" target="_blank">IRDS COLLABRATEC Community</a>!</p>
<p><em>&#8212; event producer</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:81:"http://www.kurzweilai.net/international-roadmap-for-devices-and-systems-irds/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:49;a:6:{s:4:"data";s:53:"
		
		
		
		
		
								
		
				

		
		
			
			
		
		";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:5:{s:0:"";a:7:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:52:"IEEE International Conference on Rebooting Computing";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:83:"http://www.kurzweilai.net/ieee-international-conference-on-rebooting-computing-icrc";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:92:"http://www.kurzweilai.net/ieee-international-conference-on-rebooting-computing-icrc#comments";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"pubDate";a:1:{i:0;a:5:{s:4:"data";s:31:"Wed, 24 May 2017 06:21:44 +0000";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:1:{i:0;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"guid";a:1:{i:0;a:5:{s:4:"data";s:35:"http://www.kurzweilai.net/?p=301286";s:7:"attribs";a:1:{s:0:"";a:1:{s:11:"isPermaLink";s:5:"false";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:369:"Rebooting Computing week which begins with a meeting of the International Roadmap for Devices and Systems (IRDS, Nov. 6-7, 2017), then ICRC 2017 (Nov. 8-9, 2017), and ends with the first Industry Summit on the Future of Computing (Nov. 10, 2017). Register now! The goal of the 2nd IEEE International Conference on Rebooting Computing is to discover and foster [...]";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:29:"http://search.yahoo.com/mrss/";a:1:{s:9:"thumbnail";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:3:"url";s:68:"http://www.kurzweilai.net/images/ieee-rebooting-computing-140x88.png";s:5:"width";s:3:"140";s:6:"height";s:2:"88";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:40:"http://purl.org/rss/1.0/modules/content/";a:1:{s:7:"encoded";a:1:{i:0;a:5:{s:4:"data";s:1267:"<p><img style=' float: left; padding: 4px; margin: 0 7px 2px 0;'  class="alignleft size-full wp-image-301287 noshadow" title="ieee-rebooting-computing" src="http://www.kurzweilai.net/images/ieee-rebooting-computing.png" alt="" width="275" height="174" /></p>
<p><a href="http://rebootingcomputing.ieee.org/rebooting-computing-week" target="_blank">Rebooting Computing week</a> which begins with a meeting of the International Roadmap for Devices and Systems (<a href="http://irds.ieee.org/">IRDS</a>, Nov. 6-7, 2017), then ICRC 2017 (Nov. 8-9, 2017), and ends with the first <a href="http://rebootingcomputing.ieee.org/rebooting-computing-week/industrycomputingsummit" target="_blank">Industry Summit on the Future of Computing</a> (Nov. 10, 2017). <a href="http://icrc.ieee.org/register/" target="_blank">Register now!</a></p>
<p>The goal of the 2nd IEEE International Conference on Rebooting Computing is to discover and foster novel methodologies to reinvent computing technology, including new materials and physics, devices and circuits, system and network architectures, and algorithms and software. The conference seeks input from a broad technical community, with emphasis on all aspects of the computing stack.</p>
<p><em>&#8212; event producer</em></p>
";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:36:"http://wellformedweb.org/CommentAPI/";a:1:{s:10:"commentRss";a:1:{i:0;a:5:{s:4:"data";s:88:"http://www.kurzweilai.net/ieee-international-conference-on-rebooting-computing-icrc/feed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:38:"http://purl.org/rss/1.0/modules/slash/";a:1:{s:8:"comments";a:1:{i:0;a:5:{s:4:"data";s:1:"0";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}}s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:30:"http://www.kurzweilai.net/feed";s:3:"rel";s:4:"self";s:4:"type";s:19:"application/rss+xml";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}s:44:"http://purl.org/rss/1.0/modules/syndication/";a:2:{s:12:"updatePeriod";a:1:{i:0;a:5:{s:4:"data";s:6:"hourly";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:15:"updateFrequency";a:1:{i:0;a:5:{s:4:"data";s:1:"1";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}}}}}}}s:4:"type";i:128;s:7:"headers";a:10:{s:4:"date";s:29:"Tue, 11 Jul 2017 11:51:41 GMT";s:6:"server";s:22:"Apache/2.2.15 (CentOS)";s:12:"x-powered-by";s:9:"PHP/5.3.3";s:10:"x-pingback";s:36:"http://www.kurzweilai.net/xmlrpc.php";s:13:"last-modified";s:29:"Tue, 11 Jul 2017 06:15:41 GMT";s:4:"etag";s:34:""ddaa8177d85583ca8162f836f3e8e9d8"";s:4:"vary";s:15:"Accept-Encoding";s:16:"content-encoding";s:4:"gzip";s:10:"connection";s:5:"close";s:12:"content-type";s:23:"text/xml; charset=UTF-8";}s:5:"build";s:14:"20170417072931";}